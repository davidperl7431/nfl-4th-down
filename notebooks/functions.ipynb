{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9600ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import optuna\n",
    "\n",
    "# modeling\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.special import logit, expit\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# PyTorch for conversion model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# nfl pbp loader\n",
    "import nfl_data_py as nfl\n",
    "\n",
    "from datetime import datetime\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91daa130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_weather(weather_str):\n",
    "    \"\"\"\n",
    "    Parses a weather string into structured features:\n",
    "        - temp_F: float\n",
    "        - humidity: float (percentage)\n",
    "        - wind_mph: float\n",
    "        - wind_dir: str\n",
    "        - conditions: str (general description, e.g., 'sunny', 'cloudy', etc.)\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        \"temp_F\": None,\n",
    "        \"humidity\": None,\n",
    "        \"wind_mph\": None,\n",
    "        \"wind_dir\": None,\n",
    "        \"conditions\": None\n",
    "    }\n",
    "    \n",
    "    if not isinstance(weather_str, str):\n",
    "        return result\n",
    "    \n",
    "    lower_str = weather_str.lower()\n",
    "    \n",
    "    # Extract temperature\n",
    "    temp_match = re.search(r'(\\d+)\\s*°?\\s*f', lower_str)\n",
    "    if temp_match:\n",
    "        result['temp_F'] = float(temp_match.group(1))\n",
    "    \n",
    "    # Extract humidity\n",
    "    hum_match = re.search(r'humidity[:\\s]*(\\d+)%', lower_str)\n",
    "    if hum_match:\n",
    "        result['humidity'] = float(hum_match.group(1))\n",
    "    \n",
    "    # Extract wind speed and direction\n",
    "    wind_match = re.search(r'wind[:\\s]*([nesw]+)\\s*(\\d+)\\s*mph', lower_str)\n",
    "    if wind_match:\n",
    "        result['wind_dir'] = wind_match.group(1).upper()\n",
    "        result['wind_mph'] = float(wind_match.group(2))\n",
    "    \n",
    "    # Extract general conditions\n",
    "    conditions = []\n",
    "    for cond in ['sunny', 'cloudy', 'clear', 'rain', 'snow', 'fog', 'drizzle', 'storm', 'windy']:\n",
    "        if cond in lower_str:\n",
    "            conditions.append(cond)\n",
    "    if conditions:\n",
    "        result['conditions'] = ','.join(conditions)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f96bd457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconstruct_weather(df, weather_col='weather'):\n",
    "    \"\"\"\n",
    "    Adds structured weather columns to a DataFrame based on a weather string column.\n",
    "    \n",
    "    New columns added:\n",
    "      - temp_F\n",
    "      - humidity\n",
    "      - wind_mph\n",
    "      - wind_dir\n",
    "      - conditions\n",
    "    \"\"\"\n",
    "    weather_data = df[weather_col].apply(parse_weather)\n",
    "    weather_df = pd.DataFrame(weather_data.tolist())\n",
    "    df = pd.concat([df.reset_index(drop=True), weather_df], axis=1)\n",
    "    \n",
    "    # Fill missing wind speeds with 0\n",
    "    df['wind_mph'] = df['wind_mph'].fillna(0)\n",
    "\n",
    "    # Fill missing temperatures with 60°F\n",
    "    df['temp_F'] = df['temp_F'].fillna(60)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf87a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Safely adds derived football features.\n",
    "    Only creates features when required base columns exist.\n",
    "    Missing dependencies -> feature is created as NaN or 0.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    if \"yardline_100\" in df.columns:\n",
    "        df[\"is_redzone\"] = (df[\"yardline_100\"] <= 20).astype(int)\n",
    "    else:\n",
    "        df[\"is_redzone\"] = 0\n",
    "\n",
    "    if {\"ydstogo\", \"yardline_100\"}.issubset(df.columns):\n",
    "        df[\"is_goal_to_go\"] = (df[\"ydstogo\"] >= df[\"yardline_100\"]).astype(int)\n",
    "    else:\n",
    "        df[\"is_goal_to_go\"] = 0\n",
    "\n",
    "    if \"ydstogo\" in df.columns:\n",
    "        df[\"log_ydstogo\"] = np.log1p(df[\"ydstogo\"].clip(lower=0))\n",
    "    else:\n",
    "        df[\"log_ydstogo\"] = np.nan\n",
    "\n",
    "    if \"game_seconds_remaining\" in df.columns:\n",
    "        df[\"log_game_seconds_remaining\"] = np.log1p(df[\"game_seconds_remaining\"].clip(lower=0))\n",
    "    else:\n",
    "        df[\"log_game_seconds_remaining\"] = np.nan\n",
    "\n",
    "    if \"score_differential\" in df.columns:\n",
    "        df[\"abs_score_differential\"] = df[\"score_differential\"].abs()\n",
    "    else:\n",
    "        df[\"abs_score_differential\"] = np.nan\n",
    "\n",
    "    if {\"score_differential\", \"game_seconds_remaining\"}.issubset(df.columns):\n",
    "        df[\"score_time_ratio\"] = (df[\"score_differential\"].abs() / (df[\"game_seconds_remaining\"] + 1))\n",
    "    else:\n",
    "        df[\"score_time_ratio\"] = np.nan\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d22eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_temporal_folds(df, season_col=\"season\", min_train_seasons=3):\n",
    "    \"\"\"\n",
    "    Expanding-window CV folds by season.\n",
    "    Returns list of (train_idx, val_idx).\n",
    "    \"\"\"\n",
    "    seasons = np.sort(df[season_col].unique())\n",
    "    folds = []\n",
    "\n",
    "    for i in range(min_train_seasons, len(seasons)):\n",
    "        train_seasons = seasons[:i]\n",
    "        val_season = seasons[i]\n",
    "\n",
    "        train_idx = df[df[season_col].isin(train_seasons)].index\n",
    "        val_idx = df[df[season_col] == val_season].index\n",
    "\n",
    "        folds.append((train_idx, val_idx))\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f233f30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wp_objective(trial, wp_fixed_params, X_wp, y_wp_clipped, wp_folds, mono_tuple):\n",
    "\n",
    "    tuned_params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.02, 0.08, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 6),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 0.9),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.7, 0.9),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1.0, 100, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-2, 50.0, log=True),\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        **wp_fixed_params,\n",
    "        **tuned_params,\n",
    "        \"monotone_constraints\": mono_tuple,\n",
    "    }   \n",
    "    \n",
    "    rmses = []\n",
    "    for train_idx, val_idx in wp_folds:\n",
    "        X_train = X_wp.iloc[train_idx].to_numpy(dtype=np.float32, copy=False)\n",
    "        X_val   = X_wp.iloc[val_idx].to_numpy(dtype=np.float32, copy=False)\n",
    "        y_train = y_wp_clipped.iloc[train_idx].to_numpy(dtype=np.float32, copy=False)\n",
    "        y_val   = y_wp_clipped.iloc[val_idx].to_numpy(dtype=np.float32, copy=False)\n",
    "\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        preds = model.predict(X_val)\n",
    "        rmses.append(mean_squared_error(y_val, preds, squared=False))\n",
    "\n",
    "    return float(np.mean(rmses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49cec550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wp(state_df, wp_model, wp_features):\n",
    "    \"\"\"\n",
    "    Returns win probability for the team with possession in state_df.\n",
    "    \"\"\"\n",
    "    \n",
    "    preds = wp_model.predict(state_df[wp_features])\n",
    "    \n",
    "    return np.clip(preds, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f86dcee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wp_symmetric_adjust(state_df, predict_wp, wp_model, wp_features):\n",
    "\n",
    "    # Ensure engineered features exist for the \"original\" prediction too\n",
    "    state_df_feat = create_features(state_df.copy())\n",
    "    wp = predict_wp(state_df_feat, wp_model, wp_features)\n",
    "\n",
    "    state_flipped = state_df.copy()\n",
    "\n",
    "    if \"score_differential\" in state_flipped.columns:\n",
    "        state_flipped[\"score_differential\"] *= -1\n",
    "    if \"possession_spread_line\" in state_flipped.columns:\n",
    "        state_flipped[\"possession_spread_line\"] *= -1\n",
    "\n",
    "    if {\"posteam_timeouts_remaining\", \"defteam_timeouts_remaining\"}.issubset(state_flipped.columns):\n",
    "        state_flipped[[\"posteam_timeouts_remaining\", \"defteam_timeouts_remaining\"]] = (\n",
    "            state_flipped[[\"defteam_timeouts_remaining\", \"posteam_timeouts_remaining\"]].values\n",
    "        )\n",
    "\n",
    "    if \"yardline_100\" in state_flipped.columns:\n",
    "        state_flipped[\"yardline_100\"] = 100 - state_flipped[\"yardline_100\"]\n",
    "\n",
    "    state_flipped_feat = create_features(state_flipped)\n",
    "    wp_flipped = predict_wp(state_flipped_feat, wp_model, wp_features)\n",
    "\n",
    "    wp_sym = 0.5 * (wp + (1 - wp_flipped))\n",
    "    sym_weighting = 0.2\n",
    "    return (1 - sym_weighting) * wp + sym_weighting * wp_sym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b2cd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punt_objective(trial, X_punt, y_punt, punt_folds):\n",
    "\n",
    "    tuned_params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 6),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.15, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 0.95),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 0.95),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1.0, 50.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-3, 50.0, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-6, 5.0, log=True),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "    }\n",
    "\n",
    "    fixed_params = {\n",
    "        \"n_estimators\": 5000,\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"max_bin\": 256,\n",
    "        \"early_stopping_rounds\": 100,\n",
    "        \"verbosity\": 0,\n",
    "        \"n_jobs\": 14,\n",
    "    }\n",
    "\n",
    "    params = {**fixed_params, **tuned_params}\n",
    "\n",
    "    rmses = []\n",
    "    for train_idx, val_idx in punt_folds:\n",
    "        X_train = X_punt[train_idx].astype(np.float32, copy=False)\n",
    "        X_val   = X_punt[val_idx].astype(np.float32, copy=False)\n",
    "        y_train = y_punt[train_idx].astype(np.float32, copy=False)\n",
    "        y_val   = y_punt[val_idx].astype(np.float32, copy=False)\n",
    "\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "        best_it = getattr(model, \"best_iteration\", None)\n",
    "        if best_it is None:\n",
    "            preds = model.predict(X_val)\n",
    "        else:\n",
    "            preds = model.predict(X_val, iteration_range=(0, best_it + 1))\n",
    "\n",
    "        rmses.append(mean_squared_error(y_val, preds, squared=False))\n",
    "\n",
    "    return float(np.mean(rmses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "872bde58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_objective(trial, go_fixed_params, X_go, y_go, go_folds, mono_tuple_go):\n",
    "    \n",
    "    # Suggest hyperparameters\n",
    "    tuned_params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 4),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.02, 0.08, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 0.9),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.7, 0.9),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1.0, 50.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.01, 50.0, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-6, 1.0, log=True),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 2.0),\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        **go_fixed_params,\n",
    "        **tuned_params,\n",
    "        \"monotone_constraints\": mono_tuple_go,\n",
    "    }   \n",
    "\n",
    "    log_losses = []\n",
    "\n",
    "    for train_idx, val_idx in go_folds:\n",
    "        X_train, X_val = X_go[train_idx], X_go[val_idx]\n",
    "        y_train, y_val = y_go[train_idx], y_go[val_idx]\n",
    "\n",
    "        model = XGBClassifier(**params)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "        best_it = getattr(model, \"best_iteration\", None)\n",
    "        if best_it is None:\n",
    "            preds = model.predict_proba(X_val)[:, 1]\n",
    "        else:\n",
    "            preds = model.predict_proba(X_val, iteration_range=(0, best_it + 1))[:, 1]\n",
    "\n",
    "        preds = np.clip(preds, 1e-15, 1 - 1e-15)\n",
    "        log_losses.append(log_loss(y_val, preds))\n",
    "\n",
    "    return float(np.mean(log_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3976294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plays_df(df):\n",
    "    \n",
    "    # Compute final scores and win from offensive team perspective\n",
    "    final_scores = (\n",
    "        df.groupby(\"game_id\")\n",
    "           .tail(1)[[\"game_id\",\"home_team\",\"away_team\",\"home_score\",\"away_score\"]]\n",
    "           .copy()\n",
    "    )\n",
    "    final_scores[\"home_win\"] = (final_scores[\"home_score\"] > final_scores[\"away_score\"]).astype(int)\n",
    "\n",
    "    df = df.merge(final_scores[[\"game_id\",\"home_win\"]], on=\"game_id\", how=\"left\")\n",
    "    df[\"win_actual\"] = np.where(\n",
    "        df[\"posteam\"] == df[\"home_team\"],\n",
    "        df[\"home_win\"],\n",
    "        1 - df[\"home_win\"]\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab6ef4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_next_fg_conv_states(df):\n",
    "    \n",
    "    # Next state if successful field goal attempt\n",
    "    df['fg_success_yardline_100'] = 75\n",
    "    df['fg_success_down'] = 1\n",
    "    df['fg_success_ydstogo'] = 10\n",
    "    df['fg_success_game_seconds_remaining'] = np.maximum(0, df['game_seconds_remaining'] - 5)\n",
    "    df['fg_success_half_seconds_remaining'] = np.maximum(0, df['half_seconds_remaining'] - 5)\n",
    "    df['fg_success_score_differential'] = -(df['score_differential'] + 3)\n",
    "    df['fg_success_posteam_timeouts_remaining'] = df['defteam_timeouts_remaining']\n",
    "    df['fg_success_defteam_timeouts_remaining'] = df['posteam_timeouts_remaining']\n",
    "    df['fg_success_temp_F'] = df['temp_F']\n",
    "    df['fg_success_wind_mph'] = df['wind_mph']\n",
    "    df['fg_success_possession_spread_line'] = -df['possession_spread_line']\n",
    "    df['fg_success_total_line'] = df['total_line']\n",
    "    \n",
    "    # Next state if failed field goal attempt\n",
    "    df['fg_fail_yardline_100'] = np.minimum(80, 100 - (df['yardline_100'] + 7)) # Account for inside 20-yardline edge case\n",
    "    df['fg_fail_down'] = 1\n",
    "    df['fg_fail_ydstogo'] = 10\n",
    "    df['fg_fail_game_seconds_remaining'] = np.maximum(0, df['game_seconds_remaining'] - 5)\n",
    "    df['fg_fail_half_seconds_remaining'] = np.maximum(0, df['half_seconds_remaining'] - 5)\n",
    "    df['fg_fail_score_differential'] = -df['score_differential']\n",
    "    df['fg_fail_posteam_timeouts_remaining'] = df['defteam_timeouts_remaining']\n",
    "    df['fg_fail_defteam_timeouts_remaining'] = df['posteam_timeouts_remaining']\n",
    "    df['fg_fail_temp_F'] = df['temp_F']\n",
    "    df['fg_fail_wind_mph'] = df['wind_mph']\n",
    "    df['fg_fail_possession_spread_line'] = -df['possession_spread_line']\n",
    "    df['fg_fail_total_line'] = df['total_line']\n",
    "    \n",
    "    # Next state if successful conversion attempt\n",
    "    # Note that possession flips only if successful conversio attempt results in a touchdown\n",
    "    # If successful, assume advancement to 1 yd beyond line to gain\n",
    "    go_new_yline = df[\"yardline_100\"] - df[\"ydstogo\"] - 1\n",
    "    go_td = go_new_yline <= 0\n",
    "    df[\"go_success_flip\"] = go_td.astype(int)  # 1 if TD (possession flips), else 0\n",
    "    df[\"go_success_yardline_100\"] = np.where(go_td, 75, np.maximum(1, go_new_yline))\n",
    "    df[\"go_success_down\"] = 1\n",
    "    df[\"go_success_ydstogo\"] = np.where(go_td, 10, np.minimum(10, df[\"go_success_yardline_100\"]))\n",
    "    df[\"go_success_game_seconds_remaining\"] = np.maximum(0, df[\"game_seconds_remaining\"] - 5)\n",
    "    df[\"go_success_half_seconds_remaining\"] = np.maximum(0, df[\"half_seconds_remaining\"] - 5)\n",
    "    df[\"go_success_score_differential\"] = np.where(go_td, -(df[\"score_differential\"] + 7), df[\"score_differential\"])\n",
    "    df[\"go_success_posteam_timeouts_remaining\"] = np.where(go_td, df[\"defteam_timeouts_remaining\"], df[\"posteam_timeouts_remaining\"])\n",
    "    df[\"go_success_defteam_timeouts_remaining\"] = np.where(go_td, df[\"posteam_timeouts_remaining\"], df[\"defteam_timeouts_remaining\"])\n",
    "    df[\"go_success_temp_F\"] = df[\"temp_F\"]\n",
    "    df[\"go_success_wind_mph\"] = df[\"wind_mph\"]\n",
    "    df[\"go_success_possession_spread_line\"] = np.where(go_td, -df[\"possession_spread_line\"], df[\"possession_spread_line\"])\n",
    "    df[\"go_success_total_line\"] = df[\"total_line\"]\n",
    "    \n",
    "    # Next state if failed conversion attempt\n",
    "    df['go_fail_yardline_100'] = 100 - df['yardline_100']\n",
    "    df['go_fail_down'] = 1\n",
    "    df['go_fail_ydstogo'] = 10\n",
    "    df['go_fail_game_seconds_remaining'] = np.maximum(0, df['game_seconds_remaining'] - 5)\n",
    "    df['go_fail_half_seconds_remaining'] = np.maximum(0, df['half_seconds_remaining'] - 5)\n",
    "    df['go_fail_score_differential'] = -df['score_differential']\n",
    "    df['go_fail_posteam_timeouts_remaining'] = df['defteam_timeouts_remaining']\n",
    "    df['go_fail_defteam_timeouts_remaining'] = df['posteam_timeouts_remaining']\n",
    "    df['go_fail_temp_F'] = df['temp_F']\n",
    "    df['go_fail_wind_mph'] = df['wind_mph']\n",
    "    df['go_fail_possession_spread_line'] = -df['possession_spread_line']\n",
    "    df['go_fail_total_line'] = df['total_line']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb83ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ewp_fg(df, wp_model, fg_model, wp_features, wp_base_features, fg_features):\n",
    "    max_fg = 65\n",
    "    fg_decay_threshold = 60\n",
    "\n",
    "    if \"down\" in df.columns:\n",
    "        fourth_down_mask = df[\"down\"] == 4\n",
    "    else:\n",
    "        fourth_down_mask = pd.Series(True, index=df.index)\n",
    "\n",
    "    # --- build success/fail WP frames from prefixed base columns\n",
    "    success_base_cols = [f\"fg_success_{f}\" for f in wp_base_features]\n",
    "    fail_base_cols = [f\"fg_fail_{f}\"    for f in wp_base_features]\n",
    "\n",
    "    X_fg_success = df.loc[fourth_down_mask, success_base_cols].copy()\n",
    "    X_fg_success.columns = wp_base_features\n",
    "    X_fg_success = create_features(X_fg_success)\n",
    "\n",
    "    X_fg_fail = df.loc[fourth_down_mask, fail_base_cols].copy()\n",
    "    X_fg_fail.columns = wp_base_features\n",
    "    X_fg_fail = create_features(X_fg_fail)\n",
    "\n",
    "    wp_fg_success = 1 - wp_symmetric_adjust(X_fg_success, predict_wp, wp_model, wp_features)\n",
    "    wp_fg_fail    = 1 - wp_symmetric_adjust(X_fg_fail,    predict_wp, wp_model, wp_features)\n",
    "\n",
    "    # --- FG make probability uses current state\n",
    "    X_fg_current = df.loc[fourth_down_mask, fg_features].copy()\n",
    "    p_make = fg_model.predict_proba(X_fg_current)[:, 1]\n",
    "    yardlines = X_fg_current[\"yardline_100\"].to_numpy()\n",
    "\n",
    "    p_make_decayed = np.where(\n",
    "        yardlines >= (fg_decay_threshold - 17),\n",
    "        p_make * np.maximum(0.0, (max_fg - 17 - yardlines) / (max_fg - fg_decay_threshold)),\n",
    "        p_make,\n",
    "    )\n",
    "\n",
    "    # --- EWP (only defined on 4th downs)\n",
    "    ewp_fg_4th = np.clip(\n",
    "        p_make_decayed * wp_fg_success + (1.0 - p_make_decayed) * wp_fg_fail,\n",
    "        0.0, 1.0\n",
    "    )\n",
    "\n",
    "    # --- write back safely (no broadcasting issues)\n",
    "    df[\"ewp_fg\"] = np.nan\n",
    "    df[\"wp_fg_success\"] = np.nan\n",
    "    df[\"wp_fg_fail\"] = np.nan\n",
    "    df[\"p_make_fg\"] = np.nan\n",
    "\n",
    "    df.loc[fourth_down_mask, \"ewp_fg\"] = ewp_fg_4th\n",
    "    df.loc[fourth_down_mask, \"wp_fg_success\"] = wp_fg_success\n",
    "    df.loc[fourth_down_mask, \"wp_fg_fail\"] = wp_fg_fail\n",
    "    df.loc[fourth_down_mask, \"p_make_fg\"] = p_make_decayed\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6932ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ewp_go(df, wp_model, go_model, wp_features, wp_base_features, go_features):\n",
    "    \n",
    "    if \"down\" in df.columns:\n",
    "        fourth_down_mask = df[\"down\"] == 4\n",
    "    else:\n",
    "        fourth_down_mask = pd.Series(True, index=df.index)\n",
    "\n",
    "    # Build success/fail WP feature frames\n",
    "    success_cols = [f\"go_success_{f}\" for f in wp_base_features]\n",
    "    fail_cols = [f\"go_fail_{f}\"    for f in wp_base_features]\n",
    "\n",
    "    X_go_success = df.loc[fourth_down_mask, success_cols].copy()\n",
    "    X_go_success.columns = wp_base_features\n",
    "    X_go_success = create_features(X_go_success)\n",
    "\n",
    "    X_go_fail = df.loc[fourth_down_mask, fail_cols].copy()\n",
    "    X_go_fail.columns = wp_base_features\n",
    "    X_go_fail = create_features(X_go_fail)    \n",
    "    \n",
    "    # If TD happened on success, that next-state row is from new offense perspective; invert it\n",
    "    wp_go_success_raw = wp_symmetric_adjust(X_go_success, predict_wp, wp_model, wp_features)\n",
    "    flip_success = df.loc[fourth_down_mask, \"go_success_flip\"].to_numpy(dtype=int)\n",
    "    wp_go_success = np.where(flip_success == 1, 1.0 - wp_go_success_raw, wp_go_success_raw)\n",
    "    wp_go_fail = 1 - wp_symmetric_adjust(X_go_fail, predict_wp, wp_model, wp_features)\n",
    "\n",
    "    # Conversion probabilities\n",
    "    X_go_current = df.loc[fourth_down_mask, go_features].copy()\n",
    "    p_convert = go_model.predict_proba(X_go_current)[:, 1]\n",
    "\n",
    "    # Raw EWP\n",
    "    ewp_go = np.clip(p_convert * wp_go_success + (1.0 - p_convert) * wp_go_fail, 0.0, 1.0)\n",
    "\n",
    "    # Write back\n",
    "    df.loc[fourth_down_mask, \"p_convert\"] = p_convert\n",
    "    df.loc[fourth_down_mask, \"ewp_go\"] = ewp_go\n",
    "    df.loc[fourth_down_mask, \"wp_go_success\"] = wp_go_success\n",
    "    df.loc[fourth_down_mask, \"wp_go_fail\"] = wp_go_fail\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b85f9f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_punt_next_state(df, punt_model, punt_features):\n",
    "    \n",
    "    if \"down\" in df.columns:\n",
    "        fourth_down_mask = df[\"down\"] == 4\n",
    "    else:\n",
    "        fourth_down_mask = pd.Series(True, index=df.index)\n",
    "\n",
    "    # Initialize outputs as NaN so non-4th rows don't get junk\n",
    "    df[\"punt_pred_yards\"] = np.nan\n",
    "    df[\"post_punt_yardline_100\"] = np.nan\n",
    "    df[\"post_punt_down\"] = np.nan\n",
    "    df[\"post_punt_ydstogo\"] = np.nan\n",
    "    df[\"post_punt_game_seconds_remaining\"] = np.nan\n",
    "    df[\"post_punt_half_seconds_remaining\"] = np.nan\n",
    "    df[\"post_punt_score_differential\"] = np.nan\n",
    "    df[\"post_punt_posteam_timeouts_remaining\"] = np.nan\n",
    "    df[\"post_punt_defteam_timeouts_remaining\"] = np.nan\n",
    "    df[\"post_punt_temp_F\"] = np.nan\n",
    "    df[\"post_punt_wind_mph\"] = np.nan\n",
    "    df[\"post_punt_possession_spread_line\"] = np.nan\n",
    "    df[\"post_punt_total_line\"] = np.nan\n",
    "\n",
    "    # --- Predict punt yards (4th-down rows only)\n",
    "    X_punt_current = df.loc[fourth_down_mask, punt_features].to_numpy(dtype=np.float32, copy=False)\n",
    "    punt_pred_yards = punt_model.predict(X_punt_current)\n",
    "    df.loc[fourth_down_mask, \"punt_pred_yards\"] = punt_pred_yards\n",
    "\n",
    "    # --- Next state (base features only)\n",
    "    yardline = df.loc[fourth_down_mask, \"yardline_100\"].to_numpy(dtype=np.float32, copy=False)\n",
    "    landing_kicking = yardline - punt_pred_yards\n",
    "    landing_kicking = np.where(landing_kicking <= 0, 20, landing_kicking)  # touchback if beyond endzone\n",
    "\n",
    "    df.loc[fourth_down_mask, \"post_punt_yardline_100\"] = 100 - landing_kicking  # flip field\n",
    "    df.loc[fourth_down_mask, \"post_punt_down\"] = 1\n",
    "    df.loc[fourth_down_mask, \"post_punt_ydstogo\"] = 10\n",
    "    df.loc[fourth_down_mask, \"post_punt_game_seconds_remaining\"] = np.maximum(\n",
    "        0, df.loc[fourth_down_mask, \"game_seconds_remaining\"] - 8\n",
    "    )\n",
    "    df.loc[fourth_down_mask, \"post_punt_half_seconds_remaining\"] = np.maximum(\n",
    "        0, df.loc[fourth_down_mask, \"half_seconds_remaining\"] - 8\n",
    "    )\n",
    "    df.loc[fourth_down_mask, \"post_punt_score_differential\"] = -df.loc[fourth_down_mask, \"score_differential\"]\n",
    "    df.loc[fourth_down_mask, \"post_punt_posteam_timeouts_remaining\"] = df.loc[fourth_down_mask, \"defteam_timeouts_remaining\"]\n",
    "    df.loc[fourth_down_mask, \"post_punt_defteam_timeouts_remaining\"] = df.loc[fourth_down_mask, \"posteam_timeouts_remaining\"]\n",
    "    df.loc[fourth_down_mask, \"post_punt_temp_F\"] = df.loc[fourth_down_mask, \"temp_F\"]\n",
    "    df.loc[fourth_down_mask, \"post_punt_wind_mph\"] = df.loc[fourth_down_mask, \"wind_mph\"]\n",
    "    df.loc[fourth_down_mask, \"post_punt_possession_spread_line\"] = -df.loc[fourth_down_mask, \"possession_spread_line\"]\n",
    "    df.loc[fourth_down_mask, \"post_punt_total_line\"] = df.loc[fourth_down_mask, \"total_line\"]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5d41597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ewp_punt(df, wp_model, wp_features, wp_base_features):\n",
    "    \n",
    "    if \"down\" in df.columns:\n",
    "        fourth_down_mask = df[\"down\"] == 4\n",
    "    else:\n",
    "        fourth_down_mask = pd.Series(True, index=df.index)\n",
    "\n",
    "    # Build from base post-punt columns, then derive engineered features\n",
    "    post_base_cols = [f\"post_punt_{f}\" for f in wp_base_features]\n",
    "\n",
    "    X_post_punt = df.loc[fourth_down_mask, post_base_cols].copy()\n",
    "    X_post_punt.columns = wp_base_features\n",
    "    X_post_punt = create_features(X_post_punt)\n",
    "\n",
    "    wp_post_punt = 1 - wp_symmetric_adjust(X_post_punt, predict_wp, wp_model, wp_features)\n",
    "\n",
    "    df[\"ewp_punt\"] = np.nan\n",
    "    df.loc[fourth_down_mask, \"ewp_punt\"] = wp_post_punt\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65869b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recommendations(df, test=False):\n",
    "    \n",
    "    ewp_cols = [\"ewp_punt\", \"ewp_fg\", \"ewp_go\"]\n",
    "    \n",
    "    if not test:\n",
    "\n",
    "        # Compute actual EWP for each row (using actual_ewp_col)\n",
    "        bad = set(df[\"actual_ewp_col\"].dropna().unique()) - set(df.columns)\n",
    "        if bad:\n",
    "            raise KeyError(f\"actual_ewp_col points to missing columns: {bad}\")\n",
    "\n",
    "        col_idx = df[[\"actual_ewp_col\"]].apply(\n",
    "            lambda x: df.columns.get_loc(x[0]),\n",
    "            axis=1\n",
    "        ).to_numpy()\n",
    "\n",
    "        row_idx = np.arange(len(df))\n",
    "        df[\"ewp_actual\"] = df.to_numpy()[row_idx, col_idx]\n",
    "\n",
    "    # Compute best EWP\n",
    "    df[\"ewp_best\"] = df[ewp_cols].max(axis=1)\n",
    "\n",
    "    # Mask\n",
    "    valid = (df[\"down\"] == 4) & df[ewp_cols].notna().all(axis=1)\n",
    "\n",
    "    # decision margin only for valid rows (avoids weird NaNs)\n",
    "    df[\"decision_margin\"] = np.nan\n",
    "    ewp_sorted = np.sort(df.loc[valid, ewp_cols].values, axis=1)\n",
    "    df.loc[valid, \"decision_margin\"] = ewp_sorted[:, -1] - ewp_sorted[:, -2]\n",
    "    \n",
    "    # go_margin: go vs best alternative\n",
    "    df[\"go_margin\"] = np.nan\n",
    "    df.loc[valid, \"go_margin\"] = (\n",
    "        df.loc[valid, \"ewp_go\"]\n",
    "        - df.loc[valid, [\"ewp_punt\", \"ewp_fg\"]].max(axis=1)\n",
    "    )\n",
    "    \n",
    "    col_to_action = {\n",
    "        \"ewp_punt\": \"punt\",\n",
    "        \"ewp_fg\": \"field_goal\",\n",
    "        \"ewp_go\": \"go\"\n",
    "    }\n",
    "\n",
    "    # determine best_col and recommended_play only for valid rows\n",
    "    df[\"best_col\"] = np.nan\n",
    "    df.loc[valid, \"best_col\"] = df.loc[valid, ewp_cols].idxmax(axis=1)\n",
    "    df[\"recommended_play\"] = np.nan\n",
    "    if valid.any():\n",
    "        df.loc[valid, \"recommended_play\"] = (\n",
    "            df.loc[valid, ewp_cols].idxmax(axis=1).map(col_to_action)\n",
    "        )\n",
    "    \n",
    "    # For cases where we know play_type_actual\n",
    "    if not test:\n",
    "        df[\"regret_actual\"] = pd.to_numeric(df[\"ewp_best\"] - df[\"ewp_actual\"], errors=\"coerce\")\n",
    "        \n",
    "        # Identify disagreement (only meaningful when recommendation exists)\n",
    "        df[\"disagreed\"] = np.nan\n",
    "        df.loc[valid, \"disagreed\"] = ~(\n",
    "            ((df.play_type_actual == \"punt\") & (df.recommended_play == \"punt\")) |\n",
    "            ((df.play_type_actual == \"field_goal\") & (df.recommended_play == \"field_goal\")) |\n",
    "            ((df.play_type_actual == \"go\") & (df.recommended_play == \"go\"))\n",
    "        )\n",
    "\n",
    "        df[\"follow_model\"] = np.nan\n",
    "        df.loc[valid, \"follow_model\"] = (df.loc[valid, \"actual_ewp_col\"] == df.loc[valid, \"best_col\"]).astype(int)\n",
    "       \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38ed64eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_state(pbp_fourth, nd=4):\n",
    "    r = pbp_fourth.iloc[0]\n",
    "\n",
    "    # --- Core quantities\n",
    "    wp_current = float(r.wp_current)\n",
    "    p_convert  = float(r.p_convert)\n",
    "\n",
    "    wp_succ = float(r.wp_go_success)\n",
    "    wp_fail = float(r.wp_go_fail)\n",
    "\n",
    "    # --- Deltas vs current\n",
    "    go_delta = float(r.ewp_go - wp_current)\n",
    "    fg_delta     = float(r.ewp_fg     - wp_current)\n",
    "    punt_delta   = float(r.ewp_punt   - wp_current)\n",
    "\n",
    "    # =========================\n",
    "    print(\"\\nTOPLINE\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"wp_current                    : {wp_current:.{nd}f}\")\n",
    "    print(f\"recommended_play              : {r.recommended_play}\")\n",
    "    print(f\"decision_margin               : {float(r.decision_margin):.{nd}f}\")\n",
    "\n",
    "    print(\"\\nEXPECTED WIN PROBABILITIES\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"go                            : {float(r.ewp_go):.{nd}f}   (Δ: {go_delta:+.{nd}f})\")\n",
    "    print(f\"field goal                    : {float(r.ewp_fg):.{nd}f}   (Δ: {fg_delta:+.{nd}f})\")\n",
    "    print(f\"punt                          : {float(r.ewp_punt):.{nd}f}   (Δ: {punt_delta:+.{nd}f})\")\n",
    "\n",
    "    print(\"\\nGO DETAILS\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"p_convert                     : {p_convert:.{nd}f}\")\n",
    "    print(f\"wp_success                    : {wp_succ:.{nd}f}\")\n",
    "    print(f\"wp_fail                       : {wp_fail:.{nd}f}\")\n",
    "\n",
    "    print(\"\\nFG DETAILS\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"p_make_fg                     : {float(r.p_make_fg):.{nd}f}\")\n",
    "    print(f\"wp_success                    : {float(r.wp_fg_success):.{nd}f}\")\n",
    "    print(f\"wp_fail                       : {float(r.wp_fg_fail):.{nd}f}\")\n",
    "\n",
    "    print(\"\\nPUNT CONTEXT\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"predicted net punt yds        : {float(r.punt_pred_yards):.{nd}f}\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dada1089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_with_ewp(df,\n",
    "                       wp_model=None,\n",
    "                       go_model=None,\n",
    "                       fg_model=None,\n",
    "                       punt_model=None,\n",
    "                       wp_features=None,\n",
    "                       wp_base_features=None,\n",
    "                       go_features=None,\n",
    "                       fg_features=None,\n",
    "                       punt_features=None,\n",
    "                       test=False\n",
    "                      ):\n",
    "\n",
    "    pbp_pre_computed = df.copy()\n",
    "    pbp_pre_computed = create_features(pbp_pre_computed)\n",
    "\n",
    "    # Predict WP on the full current-state df\n",
    "    pbp_pre_computed[\"wp_pred\"] = wp_symmetric_adjust(\n",
    "        pbp_pre_computed, predict_wp, wp_model, wp_features\n",
    "    )\n",
    "\n",
    "    # Outcomes only exist for real data\n",
    "    if not test:\n",
    "        pbp_pre_computed = create_plays_df(pbp_pre_computed)\n",
    "\n",
    "    # current-state WP\n",
    "    pbp_pre_computed[\"wp_current\"] = wp_symmetric_adjust(\n",
    "        pbp_pre_computed, predict_wp, wp_model, wp_features\n",
    "    )\n",
    "\n",
    "    # EWP components (each handles its own 4th-down mask)\n",
    "    pbp_pre_computed = create_next_fg_conv_states(pbp_pre_computed)\n",
    "    pbp_pre_computed = calculate_ewp_fg(pbp_pre_computed, wp_model, fg_model, wp_features, wp_base_features, fg_features)\n",
    "    pbp_pre_computed = calculate_ewp_go(pbp_pre_computed, wp_model, go_model, wp_features, wp_base_features, go_features)\n",
    "    pbp_pre_computed = create_punt_next_state(pbp_pre_computed, punt_model, punt_features)\n",
    "    pbp_pre_computed = calculate_ewp_punt(pbp_pre_computed, wp_model, wp_features, wp_base_features)\n",
    "\n",
    "    pbp_pre_computed = make_recommendations(pbp_pre_computed, test=test)\n",
    "    pbp_fourth = pbp_pre_computed[pbp_pre_computed.down == 4].copy()\n",
    "\n",
    "    if test:\n",
    "        report_state(pbp_fourth)\n",
    "\n",
    "    return pbp_pre_computed, pbp_fourth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02082fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34864"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import nbformat\n",
    "\n",
    "# Path to this notebook file\n",
    "NB_PATH = Path(\"functions.ipynb\")  # because both inside notebooks/\n",
    "OUT_PATH = Path(\"..\") / \"project_code\" / \"functions.py\"\n",
    "\n",
    "nb = nbformat.read(NB_PATH, as_version=4)\n",
    "\n",
    "lines = []\n",
    "lines.append(\"# AUTO-GENERATED FROM notebooks/functions.ipynb\")\n",
    "lines.append(\"# DO NOT EDIT DIRECTLY\\n\")\n",
    "\n",
    "for cell in nb.cells:\n",
    "    if cell.cell_type != \"code\":\n",
    "        continue\n",
    "    src = cell.source.strip()\n",
    "    if not src:\n",
    "        continue\n",
    "\n",
    "    # Heuristic: export cells that look like they define functions/classes/imports\n",
    "    if (\"def \" in src) or (\"class \" in src) or src.startswith(\"import \") or src.startswith(\"from \"):\n",
    "        lines.append(src)\n",
    "        lines.append(\"\")  # blank line between cells\n",
    "\n",
    "OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "OUT_PATH.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "\n",
    "#print(f\"Wrote: {OUT_PATH.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53668c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
