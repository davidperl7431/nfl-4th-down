{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a449ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x28671376bd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import optuna\n",
    "\n",
    "# modeling\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.special import logit, expit\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# PyTorch for conversion model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# nfl pbp loader\n",
    "import nfl_data_py as nfl\n",
    "\n",
    "# reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f038186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading play-by-play for seasons: [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2024]\n",
      "2015 done.\n",
      "2016 done.\n",
      "2017 done.\n",
      "2018 done.\n",
      "2019 done.\n",
      "2020 done.\n",
      "2021 done.\n",
      "2022 done.\n",
      "2024 done.\n",
      "Rows loaded: 433940\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>play_id</th>\n",
       "      <th>game_id</th>\n",
       "      <th>old_game_id</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>season_type</th>\n",
       "      <th>week</th>\n",
       "      <th>posteam</th>\n",
       "      <th>posteam_type</th>\n",
       "      <th>defteam</th>\n",
       "      <th>...</th>\n",
       "      <th>was_pressure</th>\n",
       "      <th>route</th>\n",
       "      <th>defense_man_zone_type</th>\n",
       "      <th>defense_coverage_type</th>\n",
       "      <th>offense_names</th>\n",
       "      <th>defense_names</th>\n",
       "      <th>offense_positions</th>\n",
       "      <th>defense_positions</th>\n",
       "      <th>offense_numbers</th>\n",
       "      <th>defense_numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2015_01_BAL_DEN</td>\n",
       "      <td>2015091309</td>\n",
       "      <td>DEN</td>\n",
       "      <td>BAL</td>\n",
       "      <td>REG</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>2015_01_BAL_DEN</td>\n",
       "      <td>2015091309</td>\n",
       "      <td>DEN</td>\n",
       "      <td>BAL</td>\n",
       "      <td>REG</td>\n",
       "      <td>1</td>\n",
       "      <td>BAL</td>\n",
       "      <td>away</td>\n",
       "      <td>DEN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.0</td>\n",
       "      <td>2015_01_BAL_DEN</td>\n",
       "      <td>2015091309</td>\n",
       "      <td>DEN</td>\n",
       "      <td>BAL</td>\n",
       "      <td>REG</td>\n",
       "      <td>1</td>\n",
       "      <td>BAL</td>\n",
       "      <td>away</td>\n",
       "      <td>DEN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.0</td>\n",
       "      <td>2015_01_BAL_DEN</td>\n",
       "      <td>2015091309</td>\n",
       "      <td>DEN</td>\n",
       "      <td>BAL</td>\n",
       "      <td>REG</td>\n",
       "      <td>1</td>\n",
       "      <td>BAL</td>\n",
       "      <td>away</td>\n",
       "      <td>DEN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96.0</td>\n",
       "      <td>2015_01_BAL_DEN</td>\n",
       "      <td>2015091309</td>\n",
       "      <td>DEN</td>\n",
       "      <td>BAL</td>\n",
       "      <td>REG</td>\n",
       "      <td>1</td>\n",
       "      <td>BAL</td>\n",
       "      <td>away</td>\n",
       "      <td>DEN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 398 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   play_id          game_id old_game_id home_team away_team season_type  week  \\\n",
       "0      1.0  2015_01_BAL_DEN  2015091309       DEN       BAL         REG     1   \n",
       "1     36.0  2015_01_BAL_DEN  2015091309       DEN       BAL         REG     1   \n",
       "2     51.0  2015_01_BAL_DEN  2015091309       DEN       BAL         REG     1   \n",
       "3     75.0  2015_01_BAL_DEN  2015091309       DEN       BAL         REG     1   \n",
       "4     96.0  2015_01_BAL_DEN  2015091309       DEN       BAL         REG     1   \n",
       "\n",
       "  posteam posteam_type defteam  ... was_pressure  route defense_man_zone_type  \\\n",
       "0    None         None    None  ...          NaN    NaN                   NaN   \n",
       "1     BAL         away     DEN  ...          NaN    NaN                   NaN   \n",
       "2     BAL         away     DEN  ...          NaN    NaN                   NaN   \n",
       "3     BAL         away     DEN  ...          NaN    NaN                   NaN   \n",
       "4     BAL         away     DEN  ...          NaN    NaN                   NaN   \n",
       "\n",
       "   defense_coverage_type  offense_names  defense_names offense_positions  \\\n",
       "0                    NaN            NaN            NaN               NaN   \n",
       "1                    NaN            NaN            NaN               NaN   \n",
       "2                    NaN            NaN            NaN               NaN   \n",
       "3                    NaN            NaN            NaN               NaN   \n",
       "4                    NaN            NaN            NaN               NaN   \n",
       "\n",
       "   defense_positions  offense_numbers  defense_numbers  \n",
       "0                NaN              NaN              NaN  \n",
       "1                NaN              NaN              NaN  \n",
       "2                NaN              NaN              NaN  \n",
       "3                NaN              NaN              NaN  \n",
       "4                NaN              NaN              NaN  \n",
       "\n",
       "[5 rows x 398 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2a. Download PBP (this can take a few minutes)\n",
    "seasons = [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2024]\n",
    "print(\"Loading play-by-play for seasons:\", seasons)\n",
    "raw_pbp = nfl.import_pbp_data(seasons, downcast=False)  # returns a DataFrame (may be large)\n",
    "\n",
    "print(\"Rows loaded:\", raw_pbp.shape[0])\n",
    "raw_pbp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02287f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_weather(weather_str):\n",
    "    \"\"\"\n",
    "    Parses a weather string into structured features:\n",
    "        - temp_F: float\n",
    "        - humidity: float (percentage)\n",
    "        - wind_mph: float\n",
    "        - wind_dir: str\n",
    "        - conditions: str (general description, e.g., 'sunny', 'cloudy', etc.)\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        \"temp_F\": None,\n",
    "        \"humidity\": None,\n",
    "        \"wind_mph\": None,\n",
    "        \"wind_dir\": None,\n",
    "        \"conditions\": None\n",
    "    }\n",
    "    \n",
    "    if not isinstance(weather_str, str):\n",
    "        return result\n",
    "    \n",
    "    lower_str = weather_str.lower()\n",
    "    \n",
    "    # Extract temperature\n",
    "    temp_match = re.search(r'(\\d+)\\s*°?\\s*f', lower_str)\n",
    "    if temp_match:\n",
    "        result['temp_F'] = float(temp_match.group(1))\n",
    "    \n",
    "    # Extract humidity\n",
    "    hum_match = re.search(r'humidity[:\\s]*(\\d+)%', lower_str)\n",
    "    if hum_match:\n",
    "        result['humidity'] = float(hum_match.group(1))\n",
    "    \n",
    "    # Extract wind speed and direction\n",
    "    wind_match = re.search(r'wind[:\\s]*([nesw]+)\\s*(\\d+)\\s*mph', lower_str)\n",
    "    if wind_match:\n",
    "        result['wind_dir'] = wind_match.group(1).upper()\n",
    "        result['wind_mph'] = float(wind_match.group(2))\n",
    "    \n",
    "    # Extract general conditions\n",
    "    conditions = []\n",
    "    for cond in ['sunny', 'cloudy', 'clear', 'rain', 'snow', 'fog', 'drizzle', 'storm', 'windy']:\n",
    "        if cond in lower_str:\n",
    "            conditions.append(cond)\n",
    "    if conditions:\n",
    "        result['conditions'] = ','.join(conditions)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def deconstruct_weather(df, weather_col='weather'):\n",
    "    \"\"\"\n",
    "    Adds structured weather columns to a DataFrame based on a weather string column.\n",
    "    \n",
    "    New columns added:\n",
    "      - temp_F\n",
    "      - humidity\n",
    "      - wind_mph\n",
    "      - wind_dir\n",
    "      - conditions\n",
    "    \"\"\"\n",
    "    weather_data = df[weather_col].apply(parse_weather)\n",
    "    weather_df = pd.DataFrame(weather_data.tolist())\n",
    "    df = pd.concat([df.reset_index(drop=True), weather_df], axis=1)\n",
    "    \n",
    "    # Fill missing wind speeds with 0\n",
    "    df['wind_mph'] = df['wind_mph'].fillna(0)\n",
    "\n",
    "    # Fill missing temperatures with 60°F\n",
    "    df['temp_F'] = df['temp_F'].fillna(60)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6062feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = ['play_type', 'play_type_actual', 'season', 'home_wp_post', 'away_wp_post', 'weather', 'yardline_100', 'ydstogo',\n",
    "               'game_seconds_remaining', 'half_seconds_remaining', 'posteam', 'defteam',\n",
    "               'posteam_timeouts_remaining', 'defteam_timeouts_remaining', 'kick_distance', 'touchback',\n",
    "                'return_yards', 'first_down', 'touchdown', 'temp_F', 'wind_mph', 'game_id', 'score_differential',\n",
    "                'home_team', 'away_team', 'home_score', 'away_score', 'down', 'field_goal_result', 'penalty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3da8c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp = raw_pbp.copy()\n",
    "\n",
    "action_to_col = {\n",
    "    \"punt\": \"punt\",\n",
    "    \"field_goal\": \"field_goal\",\n",
    "    \"run\": \"go\",\n",
    "    \"pass\": \"go\"\n",
    "}\n",
    "\n",
    "pbp[\"play_type_actual\"] = pbp[\"play_type\"].map(action_to_col)\n",
    "pbp = pbp[pbp.play_type_actual.isin(['punt', 'go', 'field_goal'])]\n",
    "pbp = deconstruct_weather(pbp)\n",
    "pbp = pbp[cols_to_keep].copy()\n",
    "pbp = pbp[pbp.penalty == 0]\n",
    "pbp['fg_made'] = (pbp[\"field_goal_result\"] == \"made\").astype(int)\n",
    "\n",
    "action_to_ewp_col = {\n",
    "    \"punt\": \"ewp_punt\",\n",
    "    \"field_goal\": \"ewp_fg\",\n",
    "    \"go\": \"ewp_go_adj\"\n",
    "}\n",
    "pbp[\"actual_ewp_col\"] = pbp[\"play_type_actual\"].map(action_to_ewp_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e7bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = pbp.season.unique() # seasons\n",
    "test_season = seasons.max()\n",
    "\n",
    "pbp_train = pbp[pbp.season != test_season]\n",
    "pbp_test = pbp[pbp.season == test_season]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5683fcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_temporal_folds(df, season_col=\"season\", min_train_seasons=3):\n",
    "    \"\"\"\n",
    "    Expanding-window CV folds by season.\n",
    "    Returns list of (train_idx, val_idx).\n",
    "    \"\"\"\n",
    "    seasons = np.sort(df[season_col].unique())\n",
    "    folds = []\n",
    "\n",
    "    for i in range(min_train_seasons, len(seasons)):\n",
    "        train_seasons = seasons[:i]\n",
    "        val_season = seasons[i]\n",
    "\n",
    "        train_idx = df[df[season_col].isin(train_seasons)].index\n",
    "        val_idx = df[df[season_col] == val_season].index\n",
    "\n",
    "        folds.append((train_idx, val_idx))\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3a81eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Drop rows missing home/away WP\n",
    "wp_df = pbp_train.dropna(subset=[\"home_wp_post\", \"away_wp_post\"]).copy()\n",
    "\n",
    "# --- Define features\n",
    "wp_df[\"score_time_ratio\"] = wp_df[\"score_differential\"].abs() / (wp_df[\"game_seconds_remaining\"] + 1)\n",
    "wp_features = [\n",
    "    \"yardline_100\",\n",
    "    \"down\",\n",
    "    \"ydstogo\",\n",
    "    \"game_seconds_remaining\",\n",
    "    \"half_seconds_remaining\",\n",
    "    \"score_differential\",\n",
    "    \"posteam_timeouts_remaining\",\n",
    "    \"defteam_timeouts_remaining\",\n",
    "    \"temp_F\",\n",
    "    \"wind_mph\"\n",
    "]\n",
    "\n",
    "# --- Define posteam WP target\n",
    "wp_df[\"wp_target\"] = np.where(\n",
    "    wp_df[\"posteam\"] == wp_df[\"home_team\"],\n",
    "    wp_df[\"home_wp_post\"],\n",
    "    wp_df[\"away_wp_post\"]\n",
    ")\n",
    "\n",
    "wp_df = wp_df.reset_index(drop=True)\n",
    "\n",
    "X_wp = wp_df[wp_features]\n",
    "y_wp = wp_df[\"wp_target\"]\n",
    "\n",
    "# --- Clip target to avoid exact 0/1 ---\n",
    "epsilon = 1e-6\n",
    "y_wp_clipped = y_wp.clip(epsilon, 1 - epsilon).reset_index(drop=True)\n",
    "\n",
    "# --- Monotone constraints\n",
    "monotone_constraints_dict = {\n",
    "    \"yardline_100\": -1,               # closer to opponent endzone → WP ↑\n",
    "    \"down\": -1,                       # higher down (worse) → WP ↓\n",
    "    \"ydstogo\": -1,                    # more yards to go → WP ↓\n",
    "    \"score_differential\": 1,          # lead → WP ↑\n",
    "    \"posteam_timeouts_remaining\": 1,  # more TOs → WP ↑\n",
    "    \"defteam_timeouts_remaining\": -1  # opponent TOs → WP ↓\n",
    "}\n",
    "\n",
    "wp_folds = make_temporal_folds(wp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04c09fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wp_objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 5),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.02, 0.08),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 400),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 0.9),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 20, 100),\n",
    "        \"verbosity\": 0,\n",
    "        \"monotone_constraints\": monotone_constraints_dict,\n",
    "        \"early_stopping_rounds\": 10,\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"tree_method\": \"hist\",\n",
    "    }\n",
    "\n",
    "    rmses = []\n",
    "\n",
    "    for train_idx, val_idx in wp_folds:\n",
    "        X_train, X_val = X_wp.iloc[train_idx], X_wp.iloc[val_idx]\n",
    "        y_train, y_val = y_wp_clipped.iloc[train_idx], y_wp_clipped.iloc[val_idx]\n",
    "\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        preds = model.predict(X_val)\n",
    "        rmse = mean_squared_error(y_val, preds, squared=False)\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    return np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "969f41ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-07 22:43:39,483]\u001b[0m A new study created in memory with name: no-name-524c8b35-5614-4789-ad0e-e4549ee6f7f3\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:43:55,655]\u001b[0m Trial 0 finished with value: 0.061726054838356595 and parameters: {'max_depth': 4, 'learning_rate': 0.04064756267260708, 'n_estimators': 214, 'subsample': 0.8717285534215473, 'min_child_weight': 34}. Best is trial 0 with value: 0.061726054838356595.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:44:12,459]\u001b[0m Trial 1 finished with value: 0.060847583615567066 and parameters: {'max_depth': 5, 'learning_rate': 0.07218182775470823, 'n_estimators': 258, 'subsample': 0.8900180029802648, 'min_child_weight': 30}. Best is trial 1 with value: 0.060847583615567066.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:44:27,435]\u001b[0m Trial 2 finished with value: 0.0625398323587335 and parameters: {'max_depth': 3, 'learning_rate': 0.07526718650483864, 'n_estimators': 242, 'subsample': 0.7789712044849184, 'min_child_weight': 98}. Best is trial 1 with value: 0.060847583615567066.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:44:53,621]\u001b[0m Trial 3 finished with value: 0.061184155657847426 and parameters: {'max_depth': 5, 'learning_rate': 0.02552483637371178, 'n_estimators': 300, 'subsample': 0.783766757459126, 'min_child_weight': 61}. Best is trial 1 with value: 0.060847583615567066.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:45:16,327]\u001b[0m Trial 4 finished with value: 0.06263804656856078 and parameters: {'max_depth': 3, 'learning_rate': 0.04193411341770137, 'n_estimators': 369, 'subsample': 0.7275029710698194, 'min_child_weight': 69}. Best is trial 1 with value: 0.060847583615567066.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:45:42,220]\u001b[0m Trial 5 finished with value: 0.06136313729324218 and parameters: {'max_depth': 5, 'learning_rate': 0.02319480340192505, 'n_estimators': 296, 'subsample': 0.8655585384187532, 'min_child_weight': 70}. Best is trial 1 with value: 0.060847583615567066.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:46:02,732]\u001b[0m Trial 6 finished with value: 0.06120784082640378 and parameters: {'max_depth': 4, 'learning_rate': 0.061657311807711015, 'n_estimators': 374, 'subsample': 0.8337737318813976, 'min_child_weight': 33}. Best is trial 1 with value: 0.060847583615567066.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:46:22,176]\u001b[0m Trial 7 finished with value: 0.06084483363487836 and parameters: {'max_depth': 5, 'learning_rate': 0.06731644719941389, 'n_estimators': 261, 'subsample': 0.8369434536274867, 'min_child_weight': 91}. Best is trial 7 with value: 0.06084483363487836.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:46:34,879]\u001b[0m Trial 8 finished with value: 0.06270294443747337 and parameters: {'max_depth': 3, 'learning_rate': 0.07305389740651248, 'n_estimators': 204, 'subsample': 0.7036309338551668, 'min_child_weight': 97}. Best is trial 7 with value: 0.06084483363487836.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:46:52,802]\u001b[0m Trial 9 finished with value: 0.06088716071132656 and parameters: {'max_depth': 5, 'learning_rate': 0.05350255714787812, 'n_estimators': 205, 'subsample': 0.8944850180102086, 'min_child_weight': 35}. Best is trial 7 with value: 0.06084483363487836.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:47:15,177]\u001b[0m Trial 10 finished with value: 0.06123698764965877 and parameters: {'max_depth': 4, 'learning_rate': 0.0618993290157487, 'n_estimators': 333, 'subsample': 0.8238252450385493, 'min_child_weight': 86}. Best is trial 7 with value: 0.06084483363487836.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:47:33,128]\u001b[0m Trial 11 finished with value: 0.060844491777640286 and parameters: {'max_depth': 5, 'learning_rate': 0.07765191592528717, 'n_estimators': 262, 'subsample': 0.8481108206618948, 'min_child_weight': 21}. Best is trial 11 with value: 0.060844491777640286.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:47:50,223]\u001b[0m Trial 12 finished with value: 0.06083848857149636 and parameters: {'max_depth': 5, 'learning_rate': 0.07789337195160986, 'n_estimators': 265, 'subsample': 0.8289720144748106, 'min_child_weight': 49}. Best is trial 12 with value: 0.06083848857149636.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:48:05,782]\u001b[0m Trial 13 finished with value: 0.06085945057059674 and parameters: {'max_depth': 5, 'learning_rate': 0.07919503816186922, 'n_estimators': 276, 'subsample': 0.8056071019913159, 'min_child_weight': 50}. Best is trial 12 with value: 0.06083848857149636.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:48:22,677]\u001b[0m Trial 14 finished with value: 0.061250079606466924 and parameters: {'max_depth': 4, 'learning_rate': 0.07984133834559855, 'n_estimators': 229, 'subsample': 0.7546637310378274, 'min_child_weight': 22}. Best is trial 12 with value: 0.06083848857149636.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:48:46,860]\u001b[0m Trial 15 finished with value: 0.060790268037386894 and parameters: {'max_depth': 5, 'learning_rate': 0.05632678345024505, 'n_estimators': 334, 'subsample': 0.8601352928050242, 'min_child_weight': 48}. Best is trial 15 with value: 0.060790268037386894.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:49:11,659]\u001b[0m Trial 16 finished with value: 0.061235732760150166 and parameters: {'max_depth': 4, 'learning_rate': 0.05089201074019928, 'n_estimators': 327, 'subsample': 0.8119079110762826, 'min_child_weight': 48}. Best is trial 15 with value: 0.060790268037386894.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:49:43,247]\u001b[0m Trial 17 finished with value: 0.06081801629200244 and parameters: {'max_depth': 5, 'learning_rate': 0.039279519701312805, 'n_estimators': 336, 'subsample': 0.8566325740206062, 'min_child_weight': 50}. Best is trial 15 with value: 0.060790268037386894.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:50:15,495]\u001b[0m Trial 18 finished with value: 0.060834883564867714 and parameters: {'max_depth': 5, 'learning_rate': 0.035052031772755975, 'n_estimators': 343, 'subsample': 0.8594696838515516, 'min_child_weight': 57}. Best is trial 15 with value: 0.060790268037386894.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:50:45,965]\u001b[0m Trial 19 finished with value: 0.06120156410234191 and parameters: {'max_depth': 4, 'learning_rate': 0.043450022640054126, 'n_estimators': 391, 'subsample': 0.8776365904911175, 'min_child_weight': 42}. Best is trial 15 with value: 0.060790268037386894.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:51:13,576]\u001b[0m Trial 20 finished with value: 0.06144286432048971 and parameters: {'max_depth': 4, 'learning_rate': 0.0316670993717274, 'n_estimators': 353, 'subsample': 0.8514642828148176, 'min_child_weight': 77}. Best is trial 15 with value: 0.060790268037386894.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:51:42,896]\u001b[0m Trial 21 finished with value: 0.06086190536738264 and parameters: {'max_depth': 5, 'learning_rate': 0.03422709621254498, 'n_estimators': 325, 'subsample': 0.8587854425042198, 'min_child_weight': 58}. Best is trial 15 with value: 0.060790268037386894.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:52:14,782]\u001b[0m Trial 22 finished with value: 0.06083142523522274 and parameters: {'max_depth': 5, 'learning_rate': 0.03419810223993019, 'n_estimators': 342, 'subsample': 0.8846723869734524, 'min_child_weight': 58}. Best is trial 15 with value: 0.060790268037386894.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:52:42,503]\u001b[0m Trial 23 finished with value: 0.06078404590647758 and parameters: {'max_depth': 5, 'learning_rate': 0.05566188000135743, 'n_estimators': 311, 'subsample': 0.8991529979261217, 'min_child_weight': 64}. Best is trial 23 with value: 0.06078404590647758.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:53:07,509]\u001b[0m Trial 24 finished with value: 0.06081462087298466 and parameters: {'max_depth': 5, 'learning_rate': 0.05535876386549714, 'n_estimators': 307, 'subsample': 0.8984788853570164, 'min_child_weight': 67}. Best is trial 23 with value: 0.06078404590647758.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "wp_study = optuna.create_study(direction=\"minimize\")\n",
    "wp_study.optimize(wp_objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c081be2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV RMSE: 0.06078404590647758\n",
      "Best params: {'max_depth': 5, 'learning_rate': 0.05566188000135743, 'n_estimators': 311, 'subsample': 0.8991529979261217, 'min_child_weight': 64}\n"
     ]
    }
   ],
   "source": [
    "best_params = wp_study.best_params\n",
    "best_score = wp_study.best_value\n",
    "\n",
    "print(\"Best CV RMSE:\", best_score)\n",
    "print(\"Best params:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "233ce880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add monotone constraints if not in params already\n",
    "best_params[\"monotone_constraints\"] = monotone_constraints_dict\n",
    "best_params[\"verbosity\"] = 0\n",
    "\n",
    "wp_model = XGBRegressor(**best_params)\n",
    "wp_model.fit(X_wp, y_wp_clipped)  # Train on full dataset\n",
    "\n",
    "\n",
    "def predict_wp(state_df):\n",
    "    \"\"\"\n",
    "    Returns win probability for the team with possession in state_df.\n",
    "    \"\"\"\n",
    "    if \"score_time_ratio\" not in state_df.columns:\n",
    "        state_df = state_df.copy()  # prevents SettingWithCopyWarning\n",
    "        state_df.loc[:, \"score_time_ratio\"] = (\n",
    "            state_df[\"score_differential\"].abs() / (state_df[\"game_seconds_remaining\"] + 1)\n",
    "        )\n",
    "\n",
    "    preds = wp_model.predict(state_df[wp_features])\n",
    "    \n",
    "    return np.clip(preds, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d04f264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wp_symmetric_adjust(state_df, predict_wp):\n",
    "    # Predict from original perspective\n",
    "    wp = predict_wp(state_df)\n",
    "\n",
    "    # Create flipped states\n",
    "    state_flipped = state_df.copy()\n",
    "    state_flipped[\"score_differential\"] *= -1\n",
    "    state_flipped[[\"posteam_timeouts_remaining\", \"defteam_timeouts_remaining\"]] = (\n",
    "        state_flipped[[\"defteam_timeouts_remaining\", \"posteam_timeouts_remaining\"]].values\n",
    "    )\n",
    "    state_flipped[\"yardline_100\"] = 100 - state_flipped[\"yardline_100\"]\n",
    "\n",
    "    # Only handle score_time_ratio if WP model actually uses it\n",
    "    if \"score_time_ratio\" in wp_features:\n",
    "        if \"score_time_ratio\" not in state_flipped.columns:\n",
    "            state_flipped.loc[:, \"score_time_ratio\"] = (\n",
    "                state_flipped[\"score_differential\"].abs() / (state_flipped[\"game_seconds_remaining\"] + 1)\n",
    "            )\n",
    "\n",
    "    wp_flipped = predict_wp(state_flipped)\n",
    "\n",
    "    # Symmetric adjustment\n",
    "    wp_sym = 0.5 * (wp + (1 - wp_flipped))\n",
    "\n",
    "    sym_weighting = 0.20\n",
    "    return (1 - sym_weighting) * wp + sym_weighting * wp_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d5cb42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create punt_df with only punt plays\n",
    "punt_df = pbp_train[pbp_train.play_type_actual == \"punt\"].dropna(subset=[\"kick_distance\", \"return_yards\"]).copy()\n",
    "\n",
    "# Compute net punt yardage: kick distance minus return yards, adjust for touchbacks (if available)\n",
    "# Assuming touchback puts ball at 20-yard line\n",
    "punt_df[\"net_punt\"] = punt_df[\"kick_distance\"] - punt_df[\"return_yards\"]\n",
    "punt_df.loc[punt_df[\"touchback\"] == 1, \"net_punt\"] = punt_df[\"yardline_100\"] - 20\n",
    "\n",
    "# Reset index to avoid any issues\n",
    "punt_df = punt_df.reset_index(drop=True)\n",
    "\n",
    "# Make temporal folds based on seasons in punt_df\n",
    "punt_folds = make_temporal_folds(punt_df, season_col=\"season\", min_train_seasons=3)\n",
    "\n",
    "# Features to predict net punt\n",
    "punt_df[\"score_time_ratio\"] = punt_df[\"score_differential\"].abs() / (punt_df[\"game_seconds_remaining\"] + 1)\n",
    "punt_features = [\n",
    "    \"yardline_100\", \n",
    "    \"game_seconds_remaining\", \n",
    "    \"half_seconds_remaining\",\n",
    "    \"score_differential\",\n",
    "    \"posteam_timeouts_remaining\",\n",
    "    \"defteam_timeouts_remaining\",\n",
    "    \"temp_F\",\n",
    "    \"wind_mph\"\n",
    "]\n",
    "\n",
    "X_punt = punt_df[punt_features].values\n",
    "y_punt = punt_df[\"net_punt\"].values\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_punt_scaled = X_scaler.fit_transform(X_punt)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_punt_scaled = y_scaler.fit_transform(y_punt.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfa9e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punt_objective(trial):\n",
    "    \n",
    "    # Suggest hyperparameters\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 16, 128)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    dropout_rate = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    epochs = 50\n",
    "\n",
    "    rmses = []\n",
    "\n",
    "    # Loop over temporal folds\n",
    "    for train_idx, val_idx in punt_folds:\n",
    "        # Prepare fold data\n",
    "        X_train = torch.tensor(X_punt_scaled[train_idx], dtype=torch.float32)\n",
    "        y_train = torch.tensor(y_punt_scaled[train_idx], dtype=torch.float32)\n",
    "        X_val = torch.tensor(X_punt_scaled[val_idx], dtype=torch.float32)\n",
    "        y_val = torch.tensor(y_punt_scaled[val_idx], dtype=torch.float32)\n",
    "\n",
    "        input_dim = X_train.shape[1]\n",
    "\n",
    "        # Build the network\n",
    "        layers = []\n",
    "        for i in range(n_layers):\n",
    "            layers.append(nn.Linear(input_dim if i == 0 else hidden_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "        layers.append(nn.Linear(hidden_size, 1))\n",
    "        \n",
    "        model = nn.Sequential(*layers)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        for epoch in range(epochs):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train)\n",
    "            loss = criterion(outputs, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_preds = model(X_val)\n",
    "            val_loss = criterion(val_preds, y_val).item()\n",
    "            rmses.append(np.sqrt(val_loss))\n",
    "\n",
    "    # Return mean RMSE across folds\n",
    "    return np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31dbba87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-07 22:53:13,164]\u001b[0m A new study created in memory with name: no-name-bd7a18f0-f301-45a0-9aad-b3a662a9fdee\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:53:16,398]\u001b[0m Trial 0 finished with value: 0.9241052388310889 and parameters: {'n_layers': 2, 'hidden_size': 54, 'lr': 0.0010051889693240693, 'dropout': 0.3242538683162355}. Best is trial 0 with value: 0.9241052388310889.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:53:20,657]\u001b[0m Trial 1 finished with value: 0.9146523982032363 and parameters: {'n_layers': 2, 'hidden_size': 88, 'lr': 0.0010089675066569295, 'dropout': 0.08788830281341692}. Best is trial 1 with value: 0.9146523982032363.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:53:23,293]\u001b[0m Trial 2 finished with value: 0.9432095436224532 and parameters: {'n_layers': 1, 'hidden_size': 126, 'lr': 0.0006016459863757766, 'dropout': 0.46103553267054065}. Best is trial 1 with value: 0.9146523982032363.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:53:24,832]\u001b[0m Trial 3 finished with value: 0.9929154286520374 and parameters: {'n_layers': 1, 'hidden_size': 59, 'lr': 0.00011035114179232453, 'dropout': 0.1696484954095227}. Best is trial 1 with value: 0.9146523982032363.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:53:26,059]\u001b[0m Trial 4 finished with value: 0.9170162014223429 and parameters: {'n_layers': 2, 'hidden_size': 23, 'lr': 0.00429269212707885, 'dropout': 0.42365109755234537}. Best is trial 1 with value: 0.9146523982032363.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:53:26,440]\u001b[0m Trial 5 finished with value: 0.9293704055661056 and parameters: {'n_layers': 1, 'hidden_size': 17, 'lr': 0.004540872785892095, 'dropout': 0.05986032285294146}. Best is trial 1 with value: 0.9146523982032363.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:53:30,709]\u001b[0m Trial 6 finished with value: 0.9117038781929239 and parameters: {'n_layers': 2, 'hidden_size': 92, 'lr': 0.005087514254490922, 'dropout': 0.23848506927250712}. Best is trial 6 with value: 0.9117038781929239.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:53:33,380]\u001b[0m Trial 7 finished with value: 0.9349655601052355 and parameters: {'n_layers': 1, 'hidden_size': 119, 'lr': 0.001100393982046092, 'dropout': 0.045727239997862934}. Best is trial 6 with value: 0.9117038781929239.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:53:38,654]\u001b[0m Trial 8 finished with value: 0.9122627907010497 and parameters: {'n_layers': 2, 'hidden_size': 106, 'lr': 0.0013059153222624875, 'dropout': 0.1921276218625782}. Best is trial 6 with value: 0.9117038781929239.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:53:40,308]\u001b[0m Trial 9 finished with value: 0.9421165926795567 and parameters: {'n_layers': 1, 'hidden_size': 66, 'lr': 0.0009586720931849338, 'dropout': 0.18930591007869957}. Best is trial 6 with value: 0.9117038781929239.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:53:47,283]\u001b[0m Trial 10 finished with value: 0.9114986357722985 and parameters: {'n_layers': 3, 'hidden_size': 89, 'lr': 0.009673336781787317, 'dropout': 0.3080880543197571}. Best is trial 10 with value: 0.9114986357722985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:53:54,065]\u001b[0m Trial 11 finished with value: 0.9126223833896361 and parameters: {'n_layers': 3, 'hidden_size': 88, 'lr': 0.009451489156319557, 'dropout': 0.32346670151153945}. Best is trial 10 with value: 0.9114986357722985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:54:00,652]\u001b[0m Trial 12 finished with value: 0.9118679829132319 and parameters: {'n_layers': 3, 'hidden_size': 89, 'lr': 0.009928203204270274, 'dropout': 0.30610564185515143}. Best is trial 10 with value: 0.9114986357722985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:54:08,361]\u001b[0m Trial 13 finished with value: 0.9127779239906907 and parameters: {'n_layers': 3, 'hidden_size': 104, 'lr': 0.003624692844142502, 'dropout': 0.26132854079633283}. Best is trial 10 with value: 0.9114986357722985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:54:11,834]\u001b[0m Trial 14 finished with value: 0.9153918012649355 and parameters: {'n_layers': 3, 'hidden_size': 42, 'lr': 0.002567529001144073, 'dropout': 0.3617522881908879}. Best is trial 10 with value: 0.9114986357722985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:54:15,465]\u001b[0m Trial 15 finished with value: 0.9397980061918355 and parameters: {'n_layers': 2, 'hidden_size': 78, 'lr': 0.00030927084910124775, 'dropout': 0.39787062431253123}. Best is trial 10 with value: 0.9114986357722985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:54:22,820]\u001b[0m Trial 16 finished with value: 0.9134795724865847 and parameters: {'n_layers': 3, 'hidden_size': 104, 'lr': 0.006297740043018873, 'dropout': 0.2451045827412846}. Best is trial 10 with value: 0.9114986357722985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:54:26,373]\u001b[0m Trial 17 finished with value: 0.9124602636312549 and parameters: {'n_layers': 2, 'hidden_size': 77, 'lr': 0.0024132298963104415, 'dropout': 0.13345365236399154}. Best is trial 10 with value: 0.9114986357722985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:54:33,124]\u001b[0m Trial 18 finished with value: 0.9126092302654614 and parameters: {'n_layers': 3, 'hidden_size': 97, 'lr': 0.006403170621778219, 'dropout': 0.2564691530722879}. Best is trial 10 with value: 0.9114986357722985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:54:38,867]\u001b[0m Trial 19 finished with value: 0.9122527885617814 and parameters: {'n_layers': 2, 'hidden_size': 115, 'lr': 0.0020549040658713034, 'dropout': 0.008552728058839526}. Best is trial 10 with value: 0.9114986357722985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:54:40,876]\u001b[0m Trial 20 finished with value: 0.914563753308222 and parameters: {'n_layers': 2, 'hidden_size': 34, 'lr': 0.006353787988503661, 'dropout': 0.4765505170541928}. Best is trial 10 with value: 0.9114986357722985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:54:47,474]\u001b[0m Trial 21 finished with value: 0.9121311298387547 and parameters: {'n_layers': 3, 'hidden_size': 87, 'lr': 0.008114642922792414, 'dropout': 0.30587514314067105}. Best is trial 10 with value: 0.9114986357722985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:54:54,461]\u001b[0m Trial 22 finished with value: 0.9129293335945808 and parameters: {'n_layers': 3, 'hidden_size': 96, 'lr': 0.009917152886050568, 'dropout': 0.2826383671584315}. Best is trial 10 with value: 0.9114986357722985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:54:59,977]\u001b[0m Trial 23 finished with value: 0.9131637350141336 and parameters: {'n_layers': 3, 'hidden_size': 73, 'lr': 0.003949060772964767, 'dropout': 0.37049440626818786}. Best is trial 10 with value: 0.9114986357722985.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:55:05,684]\u001b[0m Trial 24 finished with value: 0.9113362231582587 and parameters: {'n_layers': 3, 'hidden_size': 83, 'lr': 0.005848956112777361, 'dropout': 0.23668322087141194}. Best is trial 24 with value: 0.9113362231582587.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "punt_study = optuna.create_study(direction=\"minimize\")\n",
    "punt_study.optimize(punt_objective, n_trials=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f14bbb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV RMSE: 0.9113362231582587\n",
      "Best params: {'n_layers': 3, 'hidden_size': 83, 'lr': 0.005848956112777361, 'dropout': 0.23668322087141194}\n"
     ]
    }
   ],
   "source": [
    "best_params = punt_study.best_params\n",
    "best_score = punt_study.best_value\n",
    "n_layers = best_params[\"n_layers\"]\n",
    "hidden_size = best_params[\"hidden_size\"]\n",
    "dropout_rate = best_params[\"dropout\"]\n",
    "lr = best_params[\"lr\"]\n",
    "\n",
    "print(\"Best CV RMSE:\", best_score)\n",
    "print(\"Best params:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b01f731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final model\n",
    "layers = []\n",
    "input_dim = X_punt_scaled.shape[1]\n",
    "for i in range(n_layers):\n",
    "    layers.append(nn.Linear(input_dim if i==0 else hidden_size, hidden_size))\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.Dropout(dropout_rate))\n",
    "layers.append(nn.Linear(hidden_size, 1))\n",
    "punt_model = nn.Sequential(*layers)\n",
    "\n",
    "# Convert full data to tensors\n",
    "X_t = torch.tensor(X_punt_scaled, dtype=torch.float32)\n",
    "y_t = torch.tensor(y_punt_scaled, dtype=torch.float32)\n",
    "\n",
    "optimizer = torch.optim.Adam(punt_model.parameters(), lr=lr)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Train final model\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    preds = punt_model(X_t)\n",
    "    loss = loss_fn(preds, y_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12a28223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FG (LogReg) OOF RMSE: 0.3395836882168735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Filter to field goal attempts only ---\n",
    "fg_df = pbp_train[pbp_train.play_type_actual == \"field_goal\"].dropna(subset=[\"field_goal_result\"]).copy()\n",
    "fg_df = fg_df[fg_df.field_goal_result.isin(['made', 'missed', 'blocked'])]\n",
    "\n",
    "# Field goal\n",
    "fg_df[\"score_time_ratio\"] = fg_df[\"score_differential\"].abs() / (fg_df[\"game_seconds_remaining\"] + 1)\n",
    "fg_features = [\n",
    "    \"yardline_100\",\n",
    "    \"game_seconds_remaining\",\n",
    "    \"half_seconds_remaining\",\n",
    "    \"score_differential\",\n",
    "    \"temp_F\",\n",
    "    \"wind_mph\"\n",
    "]\n",
    "\n",
    "X_fg = fg_df[fg_features]\n",
    "y_fg = fg_df[\"fg_made\"]\n",
    "\n",
    "fg_folds = make_temporal_folds(\n",
    "    fg_df,\n",
    "    season_col=\"season\",\n",
    "    min_train_seasons=3\n",
    ")\n",
    "\n",
    "fg_oof_pred = pd.Series(index=fg_df.index, dtype=float)\n",
    "fg_df[\"fg_make_prob_oof\"] = fg_oof_pred\n",
    "\n",
    "for fold_num, (train_idx, val_idx) in enumerate(fg_folds, 1):\n",
    "    X_train = X_fg.loc[train_idx]\n",
    "    y_train = y_fg.loc[train_idx]\n",
    "    X_val   = X_fg.loc[val_idx]\n",
    "\n",
    "    fg_model_lr_fold = LogisticRegression(\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=1000\n",
    "    )\n",
    "\n",
    "    fg_model_lr_fold.fit(X_train, y_train)\n",
    "\n",
    "    fg_oof_pred.loc[val_idx] = fg_model_lr_fold.predict_proba(X_val)[:, 1]\n",
    "\n",
    "mask = fg_oof_pred.notna()\n",
    "fg_oof_rmse = np.sqrt(np.mean((fg_oof_pred[mask] - y_fg[mask]) ** 2))\n",
    "print(\"FG (LogReg) OOF RMSE:\", fg_oof_rmse)\n",
    "\n",
    "fg_model = LogisticRegression(\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "fg_model.fit(X_fg, y_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6362be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fg = 65\n",
    "fg_decay_threshold = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfe992ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to 4th-down go-for-it plays\n",
    "go_df = pbp_train[\n",
    "    (pbp_train['down'] == 4) &\n",
    "    (pbp_train['play_type_actual'] == 'go')  # filters out punts/FGs\n",
    "].copy()\n",
    "\n",
    "# Target: did the team convert?\n",
    "go_df = go_df.dropna(subset=['first_down'])\n",
    "\n",
    "# Go-for-it conversion\n",
    "go_df[\"score_time_ratio\"] = go_df[\"score_differential\"].abs() / (go_df[\"game_seconds_remaining\"] + 1)\n",
    "\n",
    "go_df[\"success\"] = (\n",
    "    (go_df[\"first_down\"] == 1) |\n",
    "    (go_df[\"touchdown\"] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Reset index to avoid any issues\n",
    "go_df = go_df.reset_index(drop=True)\n",
    "\n",
    "# Make temporal folds based on seasons in punt_df\n",
    "go_folds = make_temporal_folds(go_df, season_col=\"season\", min_train_seasons=3)\n",
    "\n",
    "# Features to predict net punt\n",
    "go_features = [\n",
    "    \"yardline_100\",\n",
    "    \"ydstogo\",\n",
    "    \"game_seconds_remaining\",\n",
    "    \"half_seconds_remaining\",\n",
    "    \"score_differential\",\n",
    "    \"posteam_timeouts_remaining\",\n",
    "    \"defteam_timeouts_remaining\",\n",
    "    \"temp_F\",\n",
    "    \"wind_mph\"\n",
    "]\n",
    "\n",
    "X_go = go_df[go_features].values\n",
    "y_go = go_df[\"success\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "154b0801",
   "metadata": {},
   "outputs": [],
   "source": [
    "monotone_constraints = [\n",
    "    -1,  # yardline_100 (farther → worse)\n",
    "    -1,  # ydstogo (longer → worse)\n",
    "    0,   # game_seconds_remaining\n",
    "    0,   # half_seconds_remaining\n",
    "    1,   # score_differential\n",
    "    0,   # posteam_timeouts_remaining\n",
    "    0,   # defteam_timeouts_remaining\n",
    "    0,   # temp_F\n",
    "    0    # wind_mph\n",
    "]\n",
    "\n",
    "def go_objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"monotone_constraints\": tuple(monotone_constraints),\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"use_label_encoder\": False,\n",
    "        \"tree_method\": \"hist\",\n",
    "    }\n",
    "\n",
    "    log_losses = []\n",
    "\n",
    "    for train_idx, val_idx in go_folds:\n",
    "        X_train, X_val = X_go[train_idx], X_go[val_idx]\n",
    "        y_train, y_val = y_go[train_idx], y_go[val_idx]\n",
    "\n",
    "        model = XGBClassifier(**params)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "        preds = model.predict_proba(X_val)[:, 1]\n",
    "        log_losses.append(log_loss(y_val, preds))\n",
    "\n",
    "    return np.mean(log_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7fd27b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-07 22:55:42,603]\u001b[0m A new study created in memory with name: no-name-55bdcfd0-44e9-4aeb-a924-70396751fb82\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:56:05,712]\u001b[0m Trial 0 finished with value: 0.6738475619347563 and parameters: {'max_depth': 5, 'learning_rate': 0.01881229276370419, 'n_estimators': 409, 'subsample': 0.7585125810070141, 'colsample_bytree': 0.8022383941590188}. Best is trial 0 with value: 0.6738475619347563.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:56:27,075]\u001b[0m Trial 1 finished with value: 0.6575888649072861 and parameters: {'max_depth': 5, 'learning_rate': 0.006823060491492993, 'n_estimators': 395, 'subsample': 0.8551315974449105, 'colsample_bytree': 0.9300817693319943}. Best is trial 1 with value: 0.6575888649072861.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:56:33,923]\u001b[0m Trial 2 finished with value: 0.6633609779913118 and parameters: {'max_depth': 8, 'learning_rate': 0.008657836898877521, 'n_estimators': 78, 'subsample': 0.799046354751364, 'colsample_bytree': 0.9920271368399676}. Best is trial 1 with value: 0.6575888649072861.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:56:45,601]\u001b[0m Trial 3 finished with value: 0.6628336658317245 and parameters: {'max_depth': 7, 'learning_rate': 0.01068911783415564, 'n_estimators': 156, 'subsample': 0.9039131352036848, 'colsample_bytree': 0.5462360230074887}. Best is trial 1 with value: 0.6575888649072861.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:57:18,641]\u001b[0m Trial 4 finished with value: 0.6629088349670089 and parameters: {'max_depth': 8, 'learning_rate': 0.007924453367281238, 'n_estimators': 361, 'subsample': 0.624263991515217, 'colsample_bytree': 0.7686698560081819}. Best is trial 1 with value: 0.6575888649072861.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:57:23,123]\u001b[0m Trial 5 finished with value: 0.6563402870319894 and parameters: {'max_depth': 5, 'learning_rate': 0.022427082988449473, 'n_estimators': 76, 'subsample': 0.9583025738853325, 'colsample_bytree': 0.9735432140465978}. Best is trial 5 with value: 0.6563402870319894.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:57:31,058]\u001b[0m Trial 6 finished with value: 0.6550595794911238 and parameters: {'max_depth': 3, 'learning_rate': 0.008998682808516489, 'n_estimators': 225, 'subsample': 0.942584267212301, 'colsample_bytree': 0.8673050977391155}. Best is trial 6 with value: 0.6550595794911238.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:58:04,477]\u001b[0m Trial 7 finished with value: 0.6756652112032394 and parameters: {'max_depth': 8, 'learning_rate': 0.0012869727949269185, 'n_estimators': 374, 'subsample': 0.5609159013043566, 'colsample_bytree': 0.5354816711721126}. Best is trial 6 with value: 0.6550595794911238.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:58:21,397]\u001b[0m Trial 8 finished with value: 0.6774649967197314 and parameters: {'max_depth': 4, 'learning_rate': 0.03623781252360592, 'n_estimators': 398, 'subsample': 0.8089996512356747, 'colsample_bytree': 0.5087980491036381}. Best is trial 6 with value: 0.6550595794911238.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:58:33,738]\u001b[0m Trial 9 finished with value: 0.6713197375083226 and parameters: {'max_depth': 3, 'learning_rate': 0.0011385575006233849, 'n_estimators': 381, 'subsample': 0.8029708169840734, 'colsample_bytree': 0.9085655035820155}. Best is trial 6 with value: 0.6550595794911238.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:58:41,837]\u001b[0m Trial 10 finished with value: 0.6753877980894967 and parameters: {'max_depth': 3, 'learning_rate': 0.07908259788932878, 'n_estimators': 249, 'subsample': 0.9933230277982739, 'colsample_bytree': 0.6603227030293961}. Best is trial 6 with value: 0.6550595794911238.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:59:05,348]\u001b[0m Trial 11 finished with value: 0.6643510824555092 and parameters: {'max_depth': 10, 'learning_rate': 0.0033260349969249626, 'n_estimators': 216, 'subsample': 0.9988408967581293, 'colsample_bytree': 0.8595362499167902}. Best is trial 6 with value: 0.6550595794911238.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:59:08,162]\u001b[0m Trial 12 finished with value: 0.6568807263395064 and parameters: {'max_depth': 5, 'learning_rate': 0.02941439015316434, 'n_estimators': 52, 'subsample': 0.920383961417533, 'colsample_bytree': 0.9662855998690733}. Best is trial 6 with value: 0.6550595794911238.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:59:14,367]\u001b[0m Trial 13 finished with value: 0.6694609755193668 and parameters: {'max_depth': 4, 'learning_rate': 0.0038196289696302965, 'n_estimators': 145, 'subsample': 0.6815641313924165, 'colsample_bytree': 0.8510302455734948}. Best is trial 6 with value: 0.6550595794911238.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:59:33,744]\u001b[0m Trial 14 finished with value: 0.6704126864189196 and parameters: {'max_depth': 6, 'learning_rate': 0.018082200201425813, 'n_estimators': 301, 'subsample': 0.916741216659142, 'colsample_bytree': 0.8791925621114579}. Best is trial 6 with value: 0.6550595794911238.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:59:49,858]\u001b[0m Trial 15 finished with value: 0.6978383386713207 and parameters: {'max_depth': 3, 'learning_rate': 0.07505524564657466, 'n_estimators': 499, 'subsample': 0.9526369712510208, 'colsample_bytree': 0.6583871240452916}. Best is trial 6 with value: 0.6550595794911238.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 22:59:55,253]\u001b[0m Trial 16 finished with value: 0.6602837683773276 and parameters: {'max_depth': 4, 'learning_rate': 0.03768991860206206, 'n_estimators': 123, 'subsample': 0.8592803296911627, 'colsample_bytree': 0.8201014712636311}. Best is trial 6 with value: 0.6550595794911238.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 23:00:07,270]\u001b[0m Trial 17 finished with value: 0.6700983736708115 and parameters: {'max_depth': 6, 'learning_rate': 0.002886020823126588, 'n_estimators': 186, 'subsample': 0.7056013190562596, 'colsample_bytree': 0.7108461776608874}. Best is trial 6 with value: 0.6550595794911238.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 23:00:20,007]\u001b[0m Trial 18 finished with value: 0.6605210899640268 and parameters: {'max_depth': 4, 'learning_rate': 0.01731257674534221, 'n_estimators': 297, 'subsample': 0.5028662981934652, 'colsample_bytree': 0.9546757413156328}. Best is trial 6 with value: 0.6550595794911238.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 23:00:32,060]\u001b[0m Trial 19 finished with value: 0.6667822683339183 and parameters: {'max_depth': 10, 'learning_rate': 0.004895566554735772, 'n_estimators': 109, 'subsample': 0.8594161582579642, 'colsample_bytree': 0.8998817693707283}. Best is trial 6 with value: 0.6550595794911238.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 23:00:51,242]\u001b[0m Trial 20 finished with value: 0.6711900025173341 and parameters: {'max_depth': 7, 'learning_rate': 0.001997249233302023, 'n_estimators': 241, 'subsample': 0.9720645594252773, 'colsample_bytree': 0.724118167417861}. Best is trial 6 with value: 0.6550595794911238.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 23:00:55,849]\u001b[0m Trial 21 finished with value: 0.6595798040971802 and parameters: {'max_depth': 5, 'learning_rate': 0.039852601469856155, 'n_estimators': 81, 'subsample': 0.9194500894620034, 'colsample_bytree': 0.9730484926549635}. Best is trial 6 with value: 0.6550595794911238.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 23:00:58,992]\u001b[0m Trial 22 finished with value: 0.6571226992382087 and parameters: {'max_depth': 5, 'learning_rate': 0.023013958938496087, 'n_estimators': 58, 'subsample': 0.9496522712589817, 'colsample_bytree': 0.9934145838724522}. Best is trial 6 with value: 0.6550595794911238.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 23:01:02,752]\u001b[0m Trial 23 finished with value: 0.6572711853061551 and parameters: {'max_depth': 6, 'learning_rate': 0.02647609170109487, 'n_estimators': 57, 'subsample': 0.8959935201541626, 'colsample_bytree': 0.9233040105738579}. Best is trial 6 with value: 0.6550595794911238.\u001b[0m\n",
      "\u001b[32m[I 2026-01-07 23:01:08,637]\u001b[0m Trial 24 finished with value: 0.6545718386688413 and parameters: {'max_depth': 3, 'learning_rate': 0.011751655372089886, 'n_estimators': 182, 'subsample': 0.9414325897484775, 'colsample_bytree': 0.9450159109407467}. Best is trial 24 with value: 0.6545718386688413.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run Optuna search\n",
    "go_study = optuna.create_study(direction=\"minimize\")\n",
    "go_study.optimize(go_objective, n_trials=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3025543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9450159109407467, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='logloss', feature_types=None, gamma=None,\n",
       "              grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.011751655372089886,\n",
       "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=(-1, -1, 0, 0, 1, 0, 0, 0, 0),\n",
       "              multi_strategy=None, n_estimators=182, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train final model with best hyperparameters\n",
    "best_params = go_study.best_trial.params\n",
    "best_params[\"monotone_constraints\"] = tuple(monotone_constraints)\n",
    "best_params[\"use_label_encoder\"] = False\n",
    "best_params[\"eval_metric\"] = \"logloss\"\n",
    "\n",
    "# Compute class imbalance weight\n",
    "pos = (y_go == 1).sum()\n",
    "neg = (y_go == 0).sum()\n",
    "scale_pos_weight = neg / pos\n",
    "\n",
    "go_model = XGBClassifier(**best_params, scale_pos_weight=scale_pos_weight)\n",
    "go_model.fit(X_go, y_go)  # feed raw features, no scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d6dca82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   feature  importance\n",
      "                   ydstogo    0.453676\n",
      "    game_seconds_remaining    0.100165\n",
      "    half_seconds_remaining    0.081602\n",
      "        score_differential    0.076177\n",
      "posteam_timeouts_remaining    0.073060\n",
      "                    temp_F    0.063917\n",
      "defteam_timeouts_remaining    0.059615\n",
      "              yardline_100    0.048739\n",
      "                  wind_mph    0.043048\n"
     ]
    }
   ],
   "source": [
    "imp = (pd.DataFrame({\n",
    "        \"feature\": go_features,\n",
    "        \"importance\": go_model.feature_importances_\n",
    "    })\n",
    "    .sort_values(\"importance\", ascending=False)\n",
    ")\n",
    "\n",
    "print(imp.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61bd5a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b15f5e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_penalty(y, center, scale):\n",
    "    \n",
    "    y = np.asarray(y, dtype=float)\n",
    "    ramp = sigmoid((y - center) / scale) # ~0 for y << center, ~1 for y >> center\n",
    "\n",
    "    return ramp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8e535e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_possessions_to_tie(score_differential):\n",
    "    \n",
    "    score_diff = np.asarray(score_differential)\n",
    "\n",
    "    return np.where(score_diff < 0, np.ceil(np.abs(score_diff) / 8), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c61343c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plays_df(df):\n",
    "    \n",
    "    # Compute final scores and win from offensive team perspective\n",
    "    final_scores = (\n",
    "        df.groupby(\"game_id\")\n",
    "           .tail(1)[[\"game_id\",\"home_team\",\"away_team\",\"home_score\",\"away_score\"]]\n",
    "           .copy()\n",
    "    )\n",
    "    final_scores[\"home_win\"] = (final_scores[\"home_score\"] > final_scores[\"away_score\"]).astype(int)\n",
    "\n",
    "    df = df.merge(final_scores[[\"game_id\",\"home_win\"]], on=\"game_id\", how=\"left\")\n",
    "    df[\"win_actual\"] = np.where(\n",
    "        df[\"posteam\"] == df[\"home_team\"],\n",
    "        df[\"home_win\"],\n",
    "        1 - df[\"home_win\"]\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0339def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_next_fg_conv_states(df):\n",
    "    \n",
    "    # Next state if successful field goal attempt\n",
    "    df['fg_success_yardline_100'] = 75\n",
    "    df['fg_success_down'] = 1\n",
    "    df['fg_success_ydstogo'] = 10\n",
    "    df['fg_success_game_seconds_remaining'] = np.maximum(0, df['game_seconds_remaining'] - 5)\n",
    "    df['fg_success_half_seconds_remaining'] = np.maximum(0, df['half_seconds_remaining'] - 5)\n",
    "    df['fg_success_score_differential'] = -(df['score_differential'] + 3)\n",
    "    df['fg_success_posteam_timeouts_remaining'] = df['defteam_timeouts_remaining']\n",
    "    df['fg_success_defteam_timeouts_remaining'] = df['posteam_timeouts_remaining']\n",
    "    df['fg_success_score_time_ratio'] = df['fg_success_score_differential'].abs() / (df['fg_success_game_seconds_remaining'] + 1)\n",
    "    df['fg_success_temp_F'] = df['temp_F']\n",
    "    df['fg_success_wind_mph'] = df['wind_mph']\n",
    "    \n",
    "    # Next state if failed field goal attempt\n",
    "    df['fg_fail_yardline_100'] = 100 - (df['yardline_100'] + 7)\n",
    "    df['fg_fail_down'] = 1\n",
    "    df['fg_fail_ydstogo'] = 10\n",
    "    df['fg_fail_game_seconds_remaining'] = np.maximum(0, df['game_seconds_remaining'] - 5)\n",
    "    df['fg_fail_half_seconds_remaining'] = np.maximum(0, df['half_seconds_remaining'] - 5)\n",
    "    df['fg_fail_score_differential'] = -df['score_differential']\n",
    "    df['fg_fail_posteam_timeouts_remaining'] = df['defteam_timeouts_remaining']\n",
    "    df['fg_fail_defteam_timeouts_remaining'] = df['posteam_timeouts_remaining']\n",
    "    df['fg_fail_score_time_ratio'] = df['fg_fail_score_differential'].abs() / (df['fg_fail_game_seconds_remaining'] + 1)\n",
    "    df['fg_fail_temp_F'] = df['temp_F']\n",
    "    df['fg_fail_wind_mph'] = df['wind_mph']\n",
    "    \n",
    "    # Next state if successful conversion attempt\n",
    "    df['go_success_yardline_100'] = df['yardline_100'] - df['ydstogo']\n",
    "    df['go_success_down'] = 1\n",
    "    df['go_success_ydstogo'] = np.minimum(10, df['go_success_yardline_100'])\n",
    "    df['go_success_game_seconds_remaining'] = np.maximum(0, df['game_seconds_remaining'] - 5)\n",
    "    df['go_success_half_seconds_remaining'] = np.maximum(0, df['half_seconds_remaining'] - 5)\n",
    "    df['go_success_score_differential'] = df['score_differential']\n",
    "    df['go_success_posteam_timeouts_remaining'] = df['posteam_timeouts_remaining']\n",
    "    df['go_success_defteam_timeouts_remaining'] = df['defteam_timeouts_remaining']\n",
    "    df['go_success_score_time_ratio'] = df['go_success_score_differential'].abs() / (df['go_success_game_seconds_remaining'] + 1)\n",
    "    df['go_success_temp_F'] = df['temp_F']\n",
    "    df['go_success_wind_mph'] = df['wind_mph']\n",
    "    \n",
    "    # Next state if failed conversion attempt\n",
    "    df['go_fail_yardline_100'] = 100 - df['yardline_100']\n",
    "    df['go_fail_down'] = 1\n",
    "    df['go_fail_ydstogo'] = 10\n",
    "    df['go_fail_game_seconds_remaining'] = np.maximum(0, df['game_seconds_remaining'] - 5)\n",
    "    df['go_fail_half_seconds_remaining'] = np.maximum(0, df['half_seconds_remaining'] - 5)\n",
    "    df['go_fail_score_differential'] = -df['score_differential']\n",
    "    df['go_fail_posteam_timeouts_remaining'] = df['defteam_timeouts_remaining']\n",
    "    df['go_fail_defteam_timeouts_remaining'] = df['posteam_timeouts_remaining']\n",
    "    df['go_fail_score_time_ratio'] = df['go_fail_score_differential'].abs() / (df['go_fail_game_seconds_remaining'] + 1)\n",
    "    df['go_fail_temp_F'] = df['temp_F']\n",
    "    df['go_fail_wind_mph'] = df['wind_mph']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a270cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ewp_fg(df):\n",
    "    \n",
    "    if \"down\" in df.columns:\n",
    "        fourth_down_mask = df[\"down\"] == 4\n",
    "    else:\n",
    "        fourth_down_mask = pd.Series(True, index=df.index)\n",
    "\n",
    "    success_cols = [f\"fg_success_{f}\" for f in wp_features]\n",
    "    fail_cols    = [f\"fg_fail_{f}\"    for f in wp_features]\n",
    "\n",
    "    X_fg_success = df.loc[fourth_down_mask, success_cols].copy()\n",
    "    X_fg_success.columns = wp_features\n",
    "\n",
    "    X_fg_fail = df.loc[fourth_down_mask, fail_cols].copy()\n",
    "    X_fg_fail.columns = wp_features\n",
    "\n",
    "    \n",
    "    wp_fg_success = 1 - wp_symmetric_adjust(X_fg_success, predict_wp)\n",
    "    wp_fg_fail = 1 - wp_symmetric_adjust(X_fg_fail, predict_wp)\n",
    "\n",
    "    # Predict FG make probability using current state\n",
    "    X_fg_current = df.loc[fourth_down_mask, fg_features].copy()\n",
    "    p_make = fg_model.predict_proba(X_fg_current)[:, 1]\n",
    "    yardlines = X_fg_current['yardline_100']\n",
    "    p_make_decayed = np.where(yardlines >= (fg_decay_threshold - 17), p_make * np.maximum(0, (max_fg - 17 - yardlines) / (max_fg - fg_decay_threshold)), p_make)\n",
    "\n",
    "    # Compute expected WP for FG attempt\n",
    "    ewp_fg = np.full(len(df), np.nan)\n",
    "    ewp_fg[fourth_down_mask] = np.clip(p_make_decayed * wp_fg_success + (1 - p_make_decayed) * wp_fg_fail, 0, 1)\n",
    "\n",
    "    wp_fg_success_array = np.full(len(df), np.nan)\n",
    "    wp_fg_success_array[fourth_down_mask] = wp_fg_success\n",
    "\n",
    "    wp_fg_fail_array = np.full(len(df), np.nan)\n",
    "    wp_fg_fail_array[fourth_down_mask] = wp_fg_fail\n",
    "\n",
    "    # Save to DataFrame\n",
    "    df[\"ewp_fg\"] = ewp_fg\n",
    "    df['wp_fg_success'] = wp_fg_success_array\n",
    "    df['wp_fg_fail'] = wp_fg_fail_array\n",
    "    df[\"p_make_fg\"] = 0\n",
    "    df.loc[fourth_down_mask, \"p_make_fg\"] = p_make_decayed\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "3ad38882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ewp_go(df, penalty_params=None):\n",
    "    penalty_params = penalty_params or {}\n",
    "\n",
    "    lam_f  = float(penalty_params.get(\"lam_fail\", 1))\n",
    "    center = float(penalty_params.get(\"fail_center\", 3.0))\n",
    "\n",
    "    if \"down\" in df.columns:\n",
    "        fourth_down_mask = df[\"down\"] == 4\n",
    "    else:\n",
    "        fourth_down_mask = pd.Series(True, index=df.index)\n",
    "        \n",
    "    wp_current = df.loc[fourth_down_mask, \"wp_current\"].to_numpy()\n",
    "\n",
    "    # Build success/fail WP feature frames\n",
    "    success_cols = [f\"go_success_{f}\" for f in wp_features]\n",
    "    fail_cols    = [f\"go_fail_{f}\"    for f in wp_features]\n",
    "\n",
    "    X_go_success = df.loc[fourth_down_mask, success_cols].copy()\n",
    "    X_go_success.columns = wp_features\n",
    "\n",
    "    X_go_fail = df.loc[fourth_down_mask, fail_cols].copy()\n",
    "    X_go_fail.columns = wp_features\n",
    "\n",
    "    # Raw state WPs (arrays aligned to fourth_down_mask rows)\n",
    "    wp_go_success_raw = wp_symmetric_adjust(X_go_success, predict_wp)\n",
    "    wp_go_fail_raw    = 1 - wp_symmetric_adjust(X_go_fail, predict_wp)\n",
    "\n",
    "    # \"Fail cost\" in WP points: how much worse failing is vs the current state.\n",
    "    # This keeps any extra fail penalty proportional to the actual downside of failing in-context.\n",
    "    fail_cost = np.maximum(0, wp_current - wp_go_fail_raw)\n",
    "\n",
    "    # Conversion probabilities\n",
    "    X_go_current = df.loc[fourth_down_mask, go_features].copy()\n",
    "    p_convert = go_model.predict_proba(X_go_current)[:, 1]\n",
    "\n",
    "    # Raw EWP\n",
    "    ewp_go_raw = np.clip(p_convert * wp_go_success_raw + (1 - p_convert) * wp_go_fail_raw, 0, 1)\n",
    "\n",
    "    # Distance-based fail penalty score (dimensionless) ...\n",
    "    go_fail_distance_penalty = sigmoid_penalty(\n",
    "        y=df.loc[fourth_down_mask, \"ydstogo\"].to_numpy(),\n",
    "        center=center,\n",
    "        scale=1.5\n",
    "    )\n",
    "    # Scale into WP units by fail_cost (still pre-lambda).\n",
    "    go_fail_distance_penalty *= fail_cost\n",
    "    go_fail_penalty_wp = lam_f * go_fail_distance_penalty\n",
    "\n",
    "    # Apply lambdas\n",
    "    wp_go_fail_adj = np.clip(wp_go_fail_raw - go_fail_penalty_wp,  0, 1)\n",
    "    ewp_go_adj     = np.clip(p_convert * wp_go_success_raw + (1 - p_convert) * wp_go_fail_adj, 0, 1)\n",
    "\n",
    "    # Write back\n",
    "    df.loc[fourth_down_mask, \"p_convert\"] = p_convert\n",
    "    df.loc[fourth_down_mask, \"ewp_go_raw\"] = ewp_go_raw\n",
    "    df.loc[fourth_down_mask, \"ewp_go_adj\"] = ewp_go_adj\n",
    "    df.loc[fourth_down_mask, \"wp_go_success_raw\"] = wp_go_success_raw\n",
    "    df.loc[fourth_down_mask, \"wp_go_fail_raw\"] = wp_go_fail_raw\n",
    "    df.loc[fourth_down_mask, \"wp_go_fail_adj\"] = wp_go_fail_adj\n",
    "    df.loc[fourth_down_mask, \"go_fail_distance_penalty\"] = go_fail_distance_penalty\n",
    "    df.loc[fourth_down_mask, \"go_fail_penalty_wp\"] = go_fail_penalty_wp\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "8d28bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_punt_next_state(df):\n",
    "    \n",
    "    if \"down\" in df.columns:\n",
    "        fourth_down_mask = df[\"down\"] == 4\n",
    "    else:\n",
    "        fourth_down_mask = pd.Series(True, index=df.index)\n",
    "        \n",
    "    X_punt_current = df.loc[fourth_down_mask, punt_features]\n",
    "\n",
    "    # 1. Pandas → numpy\n",
    "    X_punt_np = X_punt_current.values.astype(np.float32)\n",
    "\n",
    "    # 2. Scale inputs\n",
    "    X_punt_np_scaled = X_scaler.transform(X_punt_np)\n",
    "\n",
    "    # 3. numpy → torch\n",
    "    X_punt_tensor = torch.tensor(X_punt_np_scaled, dtype=torch.float32)\n",
    "\n",
    "    # 4. Predict (scaled output)\n",
    "    punt_model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_scaled_pred = punt_model(X_punt_tensor).squeeze().cpu().numpy()\n",
    "\n",
    "    # 5. Inverse transform target\n",
    "    punt_pred_yards = y_scaler.inverse_transform(\n",
    "        y_scaled_pred.reshape(-1, 1)\n",
    "    ).ravel()\n",
    "\n",
    "    punt_preds = np.zeros(len(df))\n",
    "    punt_preds[fourth_down_mask] = punt_pred_yards\n",
    "    \n",
    "    df['punt_pred_yards'] = punt_preds\n",
    " \n",
    "    landing_kicking = df['yardline_100'] - df['punt_pred_yards']\n",
    "    landing_kicking = np.where(landing_kicking < 0, 20, landing_kicking)  # Only clip beyond goal line\n",
    "    df['post_punt_yardline_100'] = 100 - landing_kicking # Flip possession\n",
    "\n",
    "    df['post_punt_down'] = 1\n",
    "    df['post_punt_ydstogo'] = 10\n",
    "    df['post_punt_game_seconds_remaining'] = np.maximum(0, df['game_seconds_remaining'] - 8)\n",
    "    df['post_punt_half_seconds_remaining'] = np.maximum(0, df['half_seconds_remaining'] - 8)\n",
    "    df['post_punt_score_differential'] = -df['score_differential']\n",
    "    df['post_punt_posteam_timeouts_remaining'] = df['defteam_timeouts_remaining']\n",
    "    df['post_punt_defteam_timeouts_remaining'] = df['posteam_timeouts_remaining']\n",
    "    df['post_punt_score_time_ratio'] = df['post_punt_score_differential'].abs() / (df['post_punt_game_seconds_remaining'] + 1)\n",
    "    df['post_punt_temp_F'] = df['temp_F']\n",
    "    df['post_punt_wind_mph'] = df['wind_mph']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "29d60321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ewp_punt(df):\n",
    "    \n",
    "    if \"down\" in df.columns:\n",
    "        fourth_down_mask = df[\"down\"] == 4\n",
    "    else:\n",
    "        fourth_down_mask = pd.Series(True, index=df.index)\n",
    "\n",
    "    post_cols = [f\"post_punt_{f}\" for f in wp_features]\n",
    "\n",
    "    X_post_punt = df.loc[fourth_down_mask, post_cols].copy()\n",
    "    X_post_punt.columns = wp_features\n",
    "    \n",
    "    wp_post_punt = 1 - wp_symmetric_adjust(X_post_punt, predict_wp)\n",
    "\n",
    "    # Compute expected WP for FG attempt\n",
    "    ewp_punt = np.full(len(df), np.nan)\n",
    "    ewp_punt[fourth_down_mask] = wp_post_punt\n",
    "\n",
    "    # Save to DataFrame\n",
    "    df[\"ewp_punt\"] = ewp_punt\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "903c7216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recommendations(df, test=False):\n",
    "    \n",
    "    ewp_cols = [\"ewp_punt\", \"ewp_fg\", \"ewp_go_adj\"]\n",
    "    \n",
    "    if not test:\n",
    "\n",
    "        # Compute actual EWP for each row (using actual_ewp_col)\n",
    "        bad = set(df[\"actual_ewp_col\"].dropna().unique()) - set(df.columns)\n",
    "        if bad:\n",
    "            raise KeyError(f\"actual_ewp_col points to missing columns: {bad}\")\n",
    "\n",
    "        col_idx = df[[\"actual_ewp_col\"]].apply(\n",
    "            lambda x: df.columns.get_loc(x[0]),\n",
    "            axis=1\n",
    "        ).to_numpy()\n",
    "\n",
    "        row_idx = np.arange(len(df))\n",
    "        df[\"ewp_actual\"] = df.to_numpy()[row_idx, col_idx]\n",
    "\n",
    "    # Compute best EWP\n",
    "    df[\"ewp_best\"] = df[ewp_cols].max(axis=1)\n",
    "\n",
    "    # Mask\n",
    "    valid = (df[\"down\"] == 4) & df[ewp_cols].notna().all(axis=1)\n",
    "\n",
    "    # decision margin only for valid rows (avoids weird NaNs)\n",
    "    df[\"decision_margin\"] = np.nan\n",
    "    ewp_sorted = np.sort(df.loc[valid, ewp_cols].values, axis=1)\n",
    "    df.loc[valid, \"decision_margin\"] = ewp_sorted[:, -1] - ewp_sorted[:, -2]\n",
    "    \n",
    "    col_to_action = {\n",
    "        \"ewp_punt\": \"punt\",\n",
    "        \"ewp_fg\": \"field_goal\",\n",
    "        \"ewp_go_adj\": \"go\"\n",
    "    }\n",
    "\n",
    "    # determine best_col and recommended_play only for valid rows\n",
    "    df[\"best_col\"] = np.nan\n",
    "    df.loc[valid, \"best_col\"] = df.loc[valid, ewp_cols].idxmax(axis=1)\n",
    "    df[\"recommended_play\"] = np.nan\n",
    "    if valid.any():\n",
    "        df.loc[valid, \"recommended_play\"] = (\n",
    "            df.loc[valid, ewp_cols].idxmax(axis=1).map(col_to_action)\n",
    "        )\n",
    "    \n",
    "    # For cases where we know play_type_actual\n",
    "    if not test:\n",
    "        df[\"regret_actual\"] = pd.to_numeric(df[\"ewp_best\"] - df[\"ewp_actual\"], errors=\"coerce\")\n",
    "        \n",
    "        # Identify disagreement (only meaningful when recommendation exists)\n",
    "        df[\"disagreed\"] = np.nan\n",
    "        df.loc[valid, \"disagreed\"] = ~(\n",
    "            ((df.play_type_actual == \"punt\") & (df.recommended_play == \"punt\")) |\n",
    "            ((df.play_type_actual == \"field_goal\") & (df.recommended_play == \"field_goal\")) |\n",
    "            ((df.play_type_actual == \"go\") & (df.recommended_play == \"go\"))\n",
    "        )\n",
    "\n",
    "        df[\"follow_model\"] = np.nan\n",
    "        df.loc[valid, \"follow_model\"] = (df.loc[valid, \"actual_ewp_col\"] == df.loc[valid, \"best_col\"]).astype(int)\n",
    "       \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "db73c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_state(pbp_fourth, best_params, nd=4):\n",
    "    r = pbp_fourth.iloc[0]\n",
    "\n",
    "    # --- Hyperparams\n",
    "    lam_f  = float(best_params.get(\"lam_fail\", 0.0))\n",
    "    center = float(best_params.get(\"fail_center\", np.nan))\n",
    "\n",
    "    # --- Core quantities\n",
    "    wp_current = float(r.wp_current)\n",
    "    p_convert  = float(r.p_convert)\n",
    "\n",
    "    wp_succ_raw = float(r.wp_go_success_raw)\n",
    "    wp_fail_raw = float(r.wp_go_fail_raw)\n",
    "    wp_fail_adj = float(r.wp_go_fail_adj)\n",
    "\n",
    "    # --- GO fail penalty decomposition\n",
    "    fail_cost = max(0.0, wp_current - wp_fail_raw)\n",
    "    prelambda_wp = float(r.go_fail_distance_penalty)   # activation * fail_cost (WP units)\n",
    "    activation = prelambda_wp / fail_cost if fail_cost > 0 else 0.0\n",
    "    activation = float(np.clip(activation, 0.0, 1.0))\n",
    "\n",
    "    applied_fail_wp  = lam_f * prelambda_wp\n",
    "    implied_ewp_drop = (1.0 - p_convert) * applied_fail_wp\n",
    "\n",
    "    # --- Deltas vs current\n",
    "    go_delta_raw = float(r.ewp_go_raw - wp_current)\n",
    "    go_delta_adj = float(r.ewp_go_adj - wp_current)\n",
    "    fg_delta     = float(r.ewp_fg     - wp_current)\n",
    "    punt_delta   = float(r.ewp_punt   - wp_current)\n",
    "\n",
    "    # =========================\n",
    "    print(\"\\nTOPLINE\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"wp_current                    : {wp_current:.{nd}f}\")\n",
    "    print(f\"recommended_play              : {r.recommended_play}\")\n",
    "    print(f\"decision_margin               : {float(r.decision_margin):.{nd}f}\")\n",
    "\n",
    "    print(\"\\nEXPECTED WIN PROBABILITIES\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"go (raw)                      : {float(r.ewp_go_raw):.{nd}f}   (Δ: {go_delta_raw:+.{nd}f})\")\n",
    "    print(f\"go (adj)                      : {float(r.ewp_go_adj):.{nd}f}   (Δ: {go_delta_adj:+.{nd}f})\")\n",
    "    print(f\"field goal                    : {float(r.ewp_fg):.{nd}f}   (Δ: {fg_delta:+.{nd}f})\")\n",
    "    print(f\"punt                          : {float(r.ewp_punt):.{nd}f}   (Δ: {punt_delta:+.{nd}f})\")\n",
    "\n",
    "    print(\"\\nGO DETAILS\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"p_convert                     : {p_convert:.{nd}f}\")\n",
    "    print(f\"wp_success (raw)              : {wp_succ_raw:.{nd}f}\")\n",
    "    print(f\"wp_fail    (raw→adj)          : {wp_fail_raw:.{nd}f} → {wp_fail_adj:.{nd}f}\")\n",
    "\n",
    "    print(\"\\nGO FAIL PENALTY BREAKDOWN\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"fail_center                   : {center:.{nd}f}\")\n",
    "    print(f\"lam_fail                      : {lam_f:.{nd}f}\")\n",
    "    print(f\"fail_cost (WP)                : {fail_cost:.{nd}f}\")\n",
    "    print(f\"activation [0,1]              : {activation:.{nd}f}\")\n",
    "    print(f\"pre-lambda penalty (WP)       : {prelambda_wp:.{nd}f}\")\n",
    "    print(f\"applied fail penalty (WP)     : {applied_fail_wp:.{nd}f}\")\n",
    "    print(f\"implied drop in GO EWP (WP)   : {implied_ewp_drop:.{nd}f}\")\n",
    "\n",
    "    print(\"\\nFG DETAILS\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"p_make_fg                     : {float(r.p_make_fg):.{nd}f}\")\n",
    "    print(f\"wp_success                    : {float(r.wp_fg_success):.{nd}f}\")\n",
    "    print(f\"wp_fail                       : {float(r.wp_fg_fail):.{nd}f}\")\n",
    "\n",
    "    print(\"\\nPUNT CONTEXT\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"predicted net punt yds        : {float(r.punt_pred_yards):.{nd}f}\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "260c88ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_with_ewp(df, test=False, penalty_params=None):\n",
    "    \n",
    "    penalty_params = penalty_params or {}\n",
    "\n",
    "    pbp_pre_computed = df.copy()\n",
    "    pbp_pre_computed[\"wp_pred\"] = wp_symmetric_adjust(pbp_pre_computed, predict_wp)\n",
    "\n",
    "    # Outcomes only exist for real data\n",
    "    if not test:\n",
    "        pbp_pre_computed = create_plays_df(pbp_pre_computed)\n",
    "\n",
    "    # shared features\n",
    "    pbp_pre_computed[\"score_time_ratio\"] = (pbp_pre_computed[\"score_differential\"].abs() / (pbp_pre_computed[\"game_seconds_remaining\"] + 1))\n",
    "    pbp_pre_computed[\"scoring_possessions_to_tie\"] = scoring_possessions_to_tie(pbp_pre_computed[\"score_differential\"])\n",
    "\n",
    "    # current-state WP (for penalty functions, etc.)\n",
    "    pbp_pre_computed[\"wp_current\"] = wp_symmetric_adjust(\n",
    "        pbp_pre_computed[wp_features], predict_wp\n",
    "    )\n",
    "\n",
    "    # EWP components (these should internally compute their own mask based on df[\"down\"] == 4)\n",
    "    pbp_pre_computed = create_next_fg_conv_states(pbp_pre_computed)\n",
    "    pbp_pre_computed = calculate_ewp_fg(pbp_pre_computed)\n",
    "    pbp_pre_computed = calculate_ewp_go(pbp_pre_computed, penalty_params=penalty_params)\n",
    "    pbp_pre_computed = create_punt_next_state(pbp_pre_computed)\n",
    "    pbp_pre_computed = calculate_ewp_punt(pbp_pre_computed)\n",
    "\n",
    "    # recommendations/regret/follow_model/etc.\n",
    "    pbp_pre_computed = make_recommendations(pbp_pre_computed, test=test)\n",
    "    pbp_fourth = pbp_pre_computed[pbp_pre_computed.down == 4].copy()\n",
    "    \n",
    "    if test:\n",
    "        report_state(pbp_fourth, penalty_params)\n",
    "\n",
    "    return pbp_pre_computed, pbp_fourth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "25539b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_score_cvar(\n",
    "    pbp_fourth_df,\n",
    "    go_value_col=\"ewp_go_raw\",\n",
    "    tail_q=0.95,\n",
    "    w_tail=1.0,\n",
    "    w_go_tail=2.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    CVaR-style tuning score to encourage non-trivial lambdas by heavily penalizing\n",
    "    worst-case (tail) regret, especially on plays where the policy recommends GO.\n",
    "    \"\"\"\n",
    "\n",
    "    d = pbp_fourth_df.copy()\n",
    "\n",
    "    if len(d) == 0:\n",
    "        return np.inf\n",
    "\n",
    "    punt = d[\"ewp_punt\"].to_numpy()\n",
    "    fg   = d[\"ewp_fg\"].to_numpy()\n",
    "    go   = d[go_value_col].to_numpy()\n",
    "    rec  = d[\"recommended_play\"].to_numpy()\n",
    "\n",
    "    # RAW-best value\n",
    "    ewp_best_value = np.maximum.reduce([punt, fg, go])\n",
    "\n",
    "    # RAW value of the recommended action (policy action evaluated by RAW)\n",
    "    ewp_model_value = np.where(\n",
    "        rec == \"punt\",\n",
    "        punt,\n",
    "        np.where(\n",
    "            rec == \"field_goal\",\n",
    "            fg,\n",
    "            go\n",
    "        )\n",
    "    )\n",
    "\n",
    "    exp_regret = np.clip(ewp_best_value - ewp_model_value, 0.0, None)\n",
    "    mean_term = exp_regret.mean()\n",
    "\n",
    "    # CVaR over all plays: mean of worst tail_q regrets\n",
    "    q_all = np.quantile(exp_regret, tail_q)\n",
    "    tail_all = exp_regret[exp_regret >= q_all]\n",
    "    cvar_all = tail_all.mean() if tail_all.size > 0 else 0.0\n",
    "\n",
    "    # CVaR restricted to plays where policy recommends GO\n",
    "    is_go = (rec == \"go\")\n",
    "    if is_go.any():\n",
    "        exp_regret_go = exp_regret[is_go]\n",
    "        q_go = np.quantile(exp_regret_go, tail_q)\n",
    "        tail_go = exp_regret_go[exp_regret_go >= q_go]\n",
    "        cvar_go = tail_go.mean() if tail_go.size > 0 else 0.0\n",
    "    else:\n",
    "        cvar_go = 0.0\n",
    "\n",
    "    return float(mean_term + w_tail * cvar_all + w_go_tail * cvar_go)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a87f2933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_score_failure_altbest(\n",
    "    pbp_fourth_df,\n",
    "    tail_q=0.95,\n",
    "    w_go=2.0,          # primary\n",
    "    w_go_tail=6.0,     # primary tail emphasis\n",
    "    w_fg=0.5,          # secondary\n",
    "    w_fg_tail=1.5,     # secondary tail\n",
    "    w_regret=0.1,      # small baseline sanity term\n",
    "):\n",
    "    d = pbp_fourth_df\n",
    "\n",
    "    # ---- validity mask (restrict to rows where we have what we need)\n",
    "    needed = [\"down\",\"recommended_play\",\"ewp_punt\",\"ewp_fg\",\"ewp_go_raw\",\"p_convert\",\"wp_go_fail_raw\"]\n",
    "    valid = (d[\"down\"] == 4)\n",
    "    for c in needed:\n",
    "        valid &= d[c].notna()\n",
    "\n",
    "    if not valid.any():\n",
    "        return float(\"inf\")\n",
    "\n",
    "    df = d.loc[valid].copy()\n",
    "\n",
    "    punt   = df[\"ewp_punt\"].to_numpy()\n",
    "    fg     = df[\"ewp_fg\"].to_numpy()\n",
    "    go_raw = df[\"ewp_go_raw\"].to_numpy()\n",
    "    rec    = df[\"recommended_play\"].to_numpy()\n",
    "\n",
    "    # ---- small baseline: regret vs RAW-best (keeps policy from doing nonsense)\n",
    "    best_raw = np.maximum.reduce([punt, fg, go_raw])\n",
    "    chosen_raw = np.where(rec==\"punt\", punt, np.where(rec==\"field_goal\", fg, go_raw))\n",
    "    regret = np.clip(best_raw - chosen_raw, 0.0, None)\n",
    "    mean_regret = regret.mean()\n",
    "\n",
    "    # ---- GO fail downside relative to best alternative (punt/FG)\n",
    "    alt_best_non_go = np.maximum(punt, fg)\n",
    "    wp_go_fail = df[\"wp_go_fail_raw\"].to_numpy()\n",
    "\n",
    "    p_fail = 1.0 - df[\"p_convert\"].to_numpy()\n",
    "    is_go = (rec == \"go\")\n",
    "\n",
    "    if is_go.any():\n",
    "        downside_go = np.clip(alt_best_non_go - wp_go_fail, 0.0, None)\n",
    "        risk_go = p_fail * downside_go\n",
    "        risk_go = risk_go[is_go]\n",
    "\n",
    "        mean_go = risk_go.mean()\n",
    "        q = np.quantile(risk_go, tail_q)\n",
    "        tail = risk_go[risk_go >= q]\n",
    "        cvar_go = tail.mean() if tail.size else 0.0\n",
    "    else:\n",
    "        mean_go = 0.0\n",
    "        cvar_go = 0.0\n",
    "\n",
    "    # ---- FG miss downside relative to best alternative (punt/GO)\n",
    "    mean_fg = 0.0\n",
    "    cvar_fg = 0.0\n",
    "    if (\"p_make_fg\" in df.columns) and (\"wp_fg_fail\" in df.columns) and df[\"p_make_fg\"].notna().all() and df[\"wp_fg_fail\"].notna().all():\n",
    "        p_miss = 1.0 - df[\"p_make_fg\"].to_numpy()\n",
    "        wp_fg_fail = df[\"wp_fg_fail\"].to_numpy()\n",
    "\n",
    "        alt_best_non_fg = np.maximum(punt, go_raw)\n",
    "        is_fg = (rec == \"field_goal\")\n",
    "\n",
    "        if is_fg.any():\n",
    "            downside_fg = np.clip(alt_best_non_fg - wp_fg_fail, 0.0, None)\n",
    "            risk_fg = p_miss * downside_fg\n",
    "            risk_fg = risk_fg[is_fg]\n",
    "\n",
    "            mean_fg = risk_fg.mean()\n",
    "            q = np.quantile(risk_fg, tail_q)\n",
    "            tail = risk_fg[risk_fg >= q]\n",
    "            cvar_fg = tail.mean() if tail.size else 0.0\n",
    "    \n",
    "    return float(\n",
    "        w_regret * mean_regret\n",
    "        + w_go * mean_go + w_go_tail * cvar_go\n",
    "        + w_fg * mean_fg + w_fg_tail * cvar_fg\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "9d5fbc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    params = {\n",
    "        # penalties\n",
    "        \"lam_fail\":    trial.suggest_float(\"lam_fail\",    0.0, 0.10),\n",
    "        \"fail_center\": trial.suggest_float(\"fail_center\", 1.0, 7.0),\n",
    "    }\n",
    "\n",
    "    fold_scores = []\n",
    "\n",
    "    for train_idx, val_idx in folds:\n",
    "        fold_train = pbp_train.loc[train_idx]\n",
    "        fold_val   = pbp_train.loc[val_idx]\n",
    "        _, pbp_fourth_val = create_df_with_ewp(fold_val, penalty_params=params)\n",
    "\n",
    "        fold_scores.append(tuning_score_failure_altbest(pbp_fourth_val))\n",
    "\n",
    "    return float(np.mean(fold_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3965d55a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-08 02:08:05,537]\u001b[0m A new study created in memory with name: no-name-14829047-60b8-4fab-9a5f-ddbae0745a31\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:08:08,622]\u001b[0m Trial 0 finished with value: 0.38695422824668124 and parameters: {'lam_fail': 0.024106193957466084, 'fail_center': 4.850485657998806}. Best is trial 0 with value: 0.38695422824668124.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:08:11,637]\u001b[0m Trial 1 finished with value: 0.38473766016126487 and parameters: {'lam_fail': 0.04086880590745506, 'fail_center': 4.204556422735703}. Best is trial 1 with value: 0.38473766016126487.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:08:14,688]\u001b[0m Trial 2 finished with value: 0.3870277320556826 and parameters: {'lam_fail': 0.029830002887512898, 'fail_center': 5.9320207379167735}. Best is trial 1 with value: 0.38473766016126487.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:08:17,686]\u001b[0m Trial 3 finished with value: 0.378761634322865 and parameters: {'lam_fail': 0.09636464594561854, 'fail_center': 4.832808255670822}. Best is trial 3 with value: 0.378761634322865.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:08:20,752]\u001b[0m Trial 4 finished with value: 0.38125979512578057 and parameters: {'lam_fail': 0.06667217565268645, 'fail_center': 2.3735072806094912}. Best is trial 3 with value: 0.378761634322865.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:08:23,768]\u001b[0m Trial 5 finished with value: 0.3827479563255944 and parameters: {'lam_fail': 0.08311136836462285, 'fail_center': 6.734361801699672}. Best is trial 3 with value: 0.378761634322865.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:08:26,859]\u001b[0m Trial 6 finished with value: 0.38388041523975514 and parameters: {'lam_fail': 0.052590756597121924, 'fail_center': 2.828359490697599}. Best is trial 3 with value: 0.378761634322865.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:08:29,951]\u001b[0m Trial 7 finished with value: 0.3828065447913101 and parameters: {'lam_fail': 0.08957270636446991, 'fail_center': 6.669788372765819}. Best is trial 3 with value: 0.378761634322865.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:08:33,000]\u001b[0m Trial 8 finished with value: 0.38456431537062113 and parameters: {'lam_fail': 0.05413619705364289, 'fail_center': 6.814751268852055}. Best is trial 3 with value: 0.378761634322865.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:08:36,133]\u001b[0m Trial 9 finished with value: 0.3848139648907281 and parameters: {'lam_fail': 0.04206015935728248, 'fail_center': 4.4860559098688}. Best is trial 3 with value: 0.378761634322865.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:08:39,316]\u001b[0m Trial 10 finished with value: 0.3898922128428797 and parameters: {'lam_fail': 0.001426473580912524, 'fail_center': 1.6846131831164306}. Best is trial 3 with value: 0.378761634322865.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:08:42,516]\u001b[0m Trial 11 finished with value: 0.37959483323017973 and parameters: {'lam_fail': 0.07127469539923352, 'fail_center': 2.8323949691467094}. Best is trial 3 with value: 0.378761634322865.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:08:45,648]\u001b[0m Trial 12 finished with value: 0.376087633292424 and parameters: {'lam_fail': 0.09574524311160931, 'fail_center': 3.202620784213003}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:08:48,831]\u001b[0m Trial 13 finished with value: 0.3798777327765885 and parameters: {'lam_fail': 0.09780081641301161, 'fail_center': 5.393349334703722}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:08:51,998]\u001b[0m Trial 14 finished with value: 0.3768717391462217 and parameters: {'lam_fail': 0.09840792968358995, 'fail_center': 3.523342872404627}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:08:55,131]\u001b[0m Trial 15 finished with value: 0.3797621915419272 and parameters: {'lam_fail': 0.07872172820260492, 'fail_center': 3.7759363863377384}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:08:58,313]\u001b[0m Trial 16 finished with value: 0.3768813035880119 and parameters: {'lam_fail': 0.09995266530636254, 'fail_center': 3.63615613078629}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:09:01,480]\u001b[0m Trial 17 finished with value: 0.3812563700405448 and parameters: {'lam_fail': 0.06418799138993761, 'fail_center': 1.448752833258693}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:09:04,663]\u001b[0m Trial 18 finished with value: 0.37974444774139604 and parameters: {'lam_fail': 0.08137771152733048, 'fail_center': 3.2907417125869483}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:09:07,929]\u001b[0m Trial 19 finished with value: 0.3783421790637932 and parameters: {'lam_fail': 0.08735272687254149, 'fail_center': 2.5842275366273877}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:09:11,228]\u001b[0m Trial 20 finished with value: 0.3793231967456651 and parameters: {'lam_fail': 0.0715029901023006, 'fail_center': 1.956577679641506}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:09:14,762]\u001b[0m Trial 21 finished with value: 0.3789195390889636 and parameters: {'lam_fail': 0.09543188479808525, 'fail_center': 3.6127453673858785}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:09:18,160]\u001b[0m Trial 22 finished with value: 0.37632733502887633 and parameters: {'lam_fail': 0.09809435292302453, 'fail_center': 3.3809942342833867}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:09:21,410]\u001b[0m Trial 23 finished with value: 0.3791362604474566 and parameters: {'lam_fail': 0.08936757829227032, 'fail_center': 3.3717994867037655}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:09:24,593]\u001b[0m Trial 24 finished with value: 0.3782812229702789 and parameters: {'lam_fail': 0.07629848780127346, 'fail_center': 1.105703077384033}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:09:27,809]\u001b[0m Trial 25 finished with value: 0.3783760144018987 and parameters: {'lam_fail': 0.0905216642363188, 'fail_center': 3.2622540368279003}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:09:31,043]\u001b[0m Trial 26 finished with value: 0.3821906109002846 and parameters: {'lam_fail': 0.0613727622038631, 'fail_center': 4.164043171121943}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:09:34,275]\u001b[0m Trial 27 finished with value: 0.3786522726876185 and parameters: {'lam_fail': 0.08490545486766743, 'fail_center': 3.0580070787382816}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:09:37,491]\u001b[0m Trial 28 finished with value: 0.37696499454803295 and parameters: {'lam_fail': 0.0931329368454355, 'fail_center': 2.225643683654623}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:09:40,723]\u001b[0m Trial 29 finished with value: 0.38789266691669216 and parameters: {'lam_fail': 0.014973233728262973, 'fail_center': 4.85137142911657}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:09:44,030]\u001b[0m Trial 30 finished with value: 0.3797632578131728 and parameters: {'lam_fail': 0.07385779091069597, 'fail_center': 4.5583607443021394}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:09:47,426]\u001b[0m Trial 31 finished with value: 0.3781693243732964 and parameters: {'lam_fail': 0.09890089777941675, 'fail_center': 3.876715769915317}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:09:50,606]\u001b[0m Trial 32 finished with value: 0.3768630961070666 and parameters: {'lam_fail': 0.09985941140810875, 'fail_center': 3.5757924675379833}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:09:53,756]\u001b[0m Trial 33 finished with value: 0.37921303625289227 and parameters: {'lam_fail': 0.08381569598435212, 'fail_center': 4.025858534422573}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:09:56,938]\u001b[0m Trial 34 finished with value: 0.3767940887929835 and parameters: {'lam_fail': 0.0920834794118688, 'fail_center': 2.9091680591375537}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:10:00,221]\u001b[0m Trial 35 finished with value: 0.37681317858532176 and parameters: {'lam_fail': 0.09055162090566604, 'fail_center': 2.606095164592441}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:10:03,462]\u001b[0m Trial 36 finished with value: 0.38666618863653934 and parameters: {'lam_fail': 0.02609684153298969, 'fail_center': 2.3679301872331013}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-08 02:10:06,704]\u001b[0m Trial 37 finished with value: 0.37745588559124055 and parameters: {'lam_fail': 0.09311928695346262, 'fail_center': 2.8729430122467585}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:10:09,963]\u001b[0m Trial 38 finished with value: 0.37902285266733976 and parameters: {'lam_fail': 0.07976203448521704, 'fail_center': 2.023950891470656}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:10:13,353]\u001b[0m Trial 39 finished with value: 0.38299740234470886 and parameters: {'lam_fail': 0.059523620621268716, 'fail_center': 2.6364696265763587}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:10:16,686]\u001b[0m Trial 40 finished with value: 0.3846283286429659 and parameters: {'lam_fail': 0.040464418845435876, 'fail_center': 3.0327908869495204}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:10:19,985]\u001b[0m Trial 41 finished with value: 0.3770878525100544 and parameters: {'lam_fail': 0.0878917351450616, 'fail_center': 2.537469600212176}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:10:23,235]\u001b[0m Trial 42 finished with value: 0.37688606332134805 and parameters: {'lam_fail': 0.0935626855298371, 'fail_center': 3.132788623088895}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:10:26,518]\u001b[0m Trial 43 finished with value: 0.3787082600537024 and parameters: {'lam_fail': 0.09330023072105945, 'fail_center': 4.345905751128289}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:10:29,767]\u001b[0m Trial 44 finished with value: 0.37819448179044546 and parameters: {'lam_fail': 0.08542041863141786, 'fail_center': 2.114146980311673}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:10:33,076]\u001b[0m Trial 45 finished with value: 0.37982584216635695 and parameters: {'lam_fail': 0.0686707422386796, 'fail_center': 2.7788273511544457}. Best is trial 12 with value: 0.376087633292424.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:10:36,333]\u001b[0m Trial 46 finished with value: 0.37427025676760506 and parameters: {'lam_fail': 0.09916997798443841, 'fail_center': 1.741168677940121}. Best is trial 46 with value: 0.37427025676760506.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:10:39,566]\u001b[0m Trial 47 finished with value: 0.37645579675547725 and parameters: {'lam_fail': 0.09041497085623801, 'fail_center': 1.707192004449656}. Best is trial 46 with value: 0.37427025676760506.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:10:43,014]\u001b[0m Trial 48 finished with value: 0.3838671061979679 and parameters: {'lam_fail': 0.04517971229433487, 'fail_center': 1.7362289048495816}. Best is trial 46 with value: 0.37427025676760506.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:10:46,282]\u001b[0m Trial 49 finished with value: 0.377764790460382 and parameters: {'lam_fail': 0.0763611869591134, 'fail_center': 1.059829205454575}. Best is trial 46 with value: 0.37427025676760506.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:10:49,531]\u001b[0m Trial 50 finished with value: 0.3735695764502597 and parameters: {'lam_fail': 0.09585130440852435, 'fail_center': 1.4005580961332584}. Best is trial 50 with value: 0.3735695764502597.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:10:52,764]\u001b[0m Trial 51 finished with value: 0.3735695764502597 and parameters: {'lam_fail': 0.095786585975571, 'fail_center': 1.370010950741275}. Best is trial 50 with value: 0.3735695764502597.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:10:56,055]\u001b[0m Trial 52 finished with value: 0.37349607003278956 and parameters: {'lam_fail': 0.09641241884060611, 'fail_center': 1.37272138832723}. Best is trial 52 with value: 0.37349607003278956.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:10:59,430]\u001b[0m Trial 53 finished with value: 0.3733756706684562 and parameters: {'lam_fail': 0.09630869162170218, 'fail_center': 1.224182713710833}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:11:02,713]\u001b[0m Trial 54 finished with value: 0.3739952082811988 and parameters: {'lam_fail': 0.09559670124809362, 'fail_center': 1.4271516685288448}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:11:05,962]\u001b[0m Trial 55 finished with value: 0.3770877565832994 and parameters: {'lam_fail': 0.08356011748891684, 'fail_center': 1.3610248521608703}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:11:09,253]\u001b[0m Trial 56 finished with value: 0.37338132761791504 and parameters: {'lam_fail': 0.09673536154123305, 'fail_center': 1.3165053142874867}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:11:12,697]\u001b[0m Trial 57 finished with value: 0.3735730582086168 and parameters: {'lam_fail': 0.09584281898271796, 'fail_center': 1.3699020581876002}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:11:16,128]\u001b[0m Trial 58 finished with value: 0.3749319036426822 and parameters: {'lam_fail': 0.08704317592946631, 'fail_center': 1.2087087309075595}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:11:19,484]\u001b[0m Trial 59 finished with value: 0.3739854742535069 and parameters: {'lam_fail': 0.09585631594564457, 'fail_center': 1.5825709868652333}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:11:22,743]\u001b[0m Trial 60 finished with value: 0.3784935273565996 and parameters: {'lam_fail': 0.08174993297717204, 'fail_center': 1.3084441768630097}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:11:26,043]\u001b[0m Trial 61 finished with value: 0.37398027244707654 and parameters: {'lam_fail': 0.09610327267306513, 'fail_center': 1.5193853689829213}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:11:29,242]\u001b[0m Trial 62 finished with value: 0.3735742707507449 and parameters: {'lam_fail': 0.09570150259133889, 'fail_center': 1.0330818454145416}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:11:32,525]\u001b[0m Trial 63 finished with value: 0.3769022108637497 and parameters: {'lam_fail': 0.0875901005908792, 'fail_center': 1.905712738797495}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:11:35,763]\u001b[0m Trial 64 finished with value: 0.3898922128428797 and parameters: {'lam_fail': 0.0010715833129922789, 'fail_center': 1.0422299835990105}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:11:38,974]\u001b[0m Trial 65 finished with value: 0.3733924843579428 and parameters: {'lam_fail': 0.09564989423068296, 'fail_center': 1.2008014987916293}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:11:42,256]\u001b[0m Trial 66 finished with value: 0.3749127880292561 and parameters: {'lam_fail': 0.08971025334243633, 'fail_center': 1.2506351265463607}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:11:45,589]\u001b[0m Trial 67 finished with value: 0.37909370999756037 and parameters: {'lam_fail': 0.07755580291121848, 'fail_center': 1.899207606942833}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:11:48,823]\u001b[0m Trial 68 finished with value: 0.3883589411010388 and parameters: {'lam_fail': 0.009470698272994432, 'fail_center': 1.5434071182393652}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:11:52,075]\u001b[0m Trial 69 finished with value: 0.37484283331978324 and parameters: {'lam_fail': 0.092101130646018, 'fail_center': 1.2528609458143574}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:11:55,272]\u001b[0m Trial 70 finished with value: 0.3806576329648992 and parameters: {'lam_fail': 0.09993953819352612, 'fail_center': 6.329250801231999}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:11:58,505]\u001b[0m Trial 71 finished with value: 0.3735547298420549 and parameters: {'lam_fail': 0.09635335293530324, 'fail_center': 1.0133688431004066}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:12:01,721]\u001b[0m Trial 72 finished with value: 0.3739230216008051 and parameters: {'lam_fail': 0.09665212577822693, 'fail_center': 1.205635523884894}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:12:05,004]\u001b[0m Trial 73 finished with value: 0.3767244402057348 and parameters: {'lam_fail': 0.08626762929591483, 'fail_center': 1.4642885010115725}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-08 02:12:08,210]\u001b[0m Trial 74 finished with value: 0.37667742631978385 and parameters: {'lam_fail': 0.09313237216077487, 'fail_center': 1.818495868240905}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:12:11,370]\u001b[0m Trial 75 finished with value: 0.3862234992014857 and parameters: {'lam_fail': 0.0351621718095219, 'fail_center': 1.6101408970260107}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:12:15,218]\u001b[0m Trial 76 finished with value: 0.3759781028557112 and parameters: {'lam_fail': 0.09680815516801605, 'fail_center': 2.2892144628781397}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:12:18,802]\u001b[0m Trial 77 finished with value: 0.37901669425762907 and parameters: {'lam_fail': 0.08107036716105, 'fail_center': 2.074272317292274}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:12:22,285]\u001b[0m Trial 78 finished with value: 0.3748996492305964 and parameters: {'lam_fail': 0.09013739747239745, 'fail_center': 1.3781454370342383}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:12:25,701]\u001b[0m Trial 79 finished with value: 0.3747453526608576 and parameters: {'lam_fail': 0.0938921019652384, 'fail_center': 1.2123379152155165}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:12:29,051]\u001b[0m Trial 80 finished with value: 0.37407314815869647 and parameters: {'lam_fail': 0.09997991007339956, 'fail_center': 1.0508564393450959}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:12:32,467]\u001b[0m Trial 81 finished with value: 0.3739775478860847 and parameters: {'lam_fail': 0.09656591017778948, 'fail_center': 1.0037549298847837}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:12:35,700]\u001b[0m Trial 82 finished with value: 0.37516905326817895 and parameters: {'lam_fail': 0.0948985069735684, 'fail_center': 1.620700142980775}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:12:38,899]\u001b[0m Trial 83 finished with value: 0.3800068523872289 and parameters: {'lam_fail': 0.08911735349358081, 'fail_center': 5.290987717651631}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:12:42,138]\u001b[0m Trial 84 finished with value: 0.37489673156690195 and parameters: {'lam_fail': 0.09088153421972535, 'fail_center': 1.3734993684357275}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:12:45,332]\u001b[0m Trial 85 finished with value: 0.37398499617209857 and parameters: {'lam_fail': 0.09780075136712495, 'fail_center': 1.1727906959824108}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:12:48,665]\u001b[0m Trial 86 finished with value: 0.37520772265972935 and parameters: {'lam_fail': 0.08441835597635478, 'fail_center': 1.003086439431672}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:12:51,955]\u001b[0m Trial 87 finished with value: 0.3766254480784208 and parameters: {'lam_fail': 0.09411353200353861, 'fail_center': 1.7814086736321428}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:12:55,146]\u001b[0m Trial 88 finished with value: 0.37353962726915324 and parameters: {'lam_fail': 0.09779605671547262, 'fail_center': 1.4501968275503838}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:12:58,541]\u001b[0m Trial 89 finished with value: 0.37490473336081026 and parameters: {'lam_fail': 0.09160477269872075, 'fail_center': 1.5111211394199877}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:13:02,197]\u001b[0m Trial 90 finished with value: 0.3767616100106296 and parameters: {'lam_fail': 0.08762417729133067, 'fail_center': 2.165328956791135}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:13:05,545]\u001b[0m Trial 91 finished with value: 0.37381086337703867 and parameters: {'lam_fail': 0.09712659871561061, 'fail_center': 1.3946199497504392}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:13:09,054]\u001b[0m Trial 92 finished with value: 0.37398499617209857 and parameters: {'lam_fail': 0.09774342143209688, 'fail_center': 1.1498026408113649}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:13:12,629]\u001b[0m Trial 93 finished with value: 0.37484562425929546 and parameters: {'lam_fail': 0.09241521859516506, 'fail_center': 1.3118374996732571}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:13:16,094]\u001b[0m Trial 94 finished with value: 0.37516905326817895 and parameters: {'lam_fail': 0.09493850815870927, 'fail_center': 1.6310055311175}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:13:19,807]\u001b[0m Trial 95 finished with value: 0.3768926168393736 and parameters: {'lam_fail': 0.0886414099369005, 'fail_center': 1.9141144988333174}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:13:23,162]\u001b[0m Trial 96 finished with value: 0.3825307580785787 and parameters: {'lam_fail': 0.056817586925160306, 'fail_center': 1.1464869931239547}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:13:26,476]\u001b[0m Trial 97 finished with value: 0.37353962726915324 and parameters: {'lam_fail': 0.09817543153670766, 'fail_center': 1.5048100204979074}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:13:29,785]\u001b[0m Trial 98 finished with value: 0.37428185911041967 and parameters: {'lam_fail': 0.09830417476232543, 'fail_center': 1.691661643247254}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n",
      "\u001b[32m[I 2026-01-08 02:13:33,151]\u001b[0m Trial 99 finished with value: 0.3735357529430675 and parameters: {'lam_fail': 0.09972516971251777, 'fail_center': 1.4913177581106958}. Best is trial 53 with value: 0.3733756706684562.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'lam_fail': 0.09630869162170218, 'fail_center': 1.224182713710833}\n",
      "\n",
      "Best CV score: 0.3733756706684562\n"
     ]
    }
   ],
   "source": [
    "# folds on pbp_train (expanding window)\n",
    "folds = make_temporal_folds(pbp_train)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "best_params = study.best_params\n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print()\n",
    "print(\"Best CV score:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "f0cf0a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned test score: 0.40339126496890354\n"
     ]
    }
   ],
   "source": [
    "# Recompute on full TRAIN + full TEST using tuned params\n",
    "pbp_pre_train_tuned, pbp_fourth_train_tuned = create_df_with_ewp(pbp_train, penalty_params=best_params)\n",
    "pbp_pre_test_tuned, pbp_fourth_test_tuned = create_df_with_ewp(pbp_test, penalty_params=best_params)\n",
    "\n",
    "# Tuning metric on the test season\n",
    "print(\"Tuned test score:\", tuning_score_failure_altbest(pbp_fourth_test_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "afa437a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOPLINE\n",
      "----------------------------------------\n",
      "wp_current                    : 0.4483\n",
      "recommended_play              : field_goal\n",
      "decision_margin               : 0.1019\n",
      "\n",
      "EXPECTED WIN PROBABILITIES\n",
      "----------------------------------------\n",
      "go (raw)                      : 0.4021   (Δ: -0.0462)\n",
      "go (adj)                      : 0.3918   (Δ: -0.0565)\n",
      "field goal                    : 0.4937   (Δ: +0.0454)\n",
      "punt                          : 0.1724   (Δ: -0.2759)\n",
      "\n",
      "GO DETAILS\n",
      "----------------------------------------\n",
      "p_convert                     : 0.3941\n",
      "wp_success (raw)              : 0.6846\n",
      "wp_fail    (raw→adj)          : 0.2183 → 0.2013\n",
      "\n",
      "GO FAIL PENALTY BREAKDOWN\n",
      "----------------------------------------\n",
      "fail_center                   : 1.2242\n",
      "lam_fail                      : 0.0963\n",
      "fail_cost (WP)                : 0.2300\n",
      "activation [0,1]              : 0.7656\n",
      "pre-lambda penalty (WP)       : 0.1761\n",
      "applied fail penalty (WP)     : 0.0170\n",
      "implied drop in GO EWP (WP)   : 0.0103\n",
      "\n",
      "FG DETAILS\n",
      "----------------------------------------\n",
      "p_make_fg                     : 0.9776\n",
      "wp_success                    : 0.5001\n",
      "wp_fail                       : 0.2138\n",
      "\n",
      "PUNT CONTEXT\n",
      "----------------------------------------\n",
      "predicted net punt yds        : 11.4215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state = {\n",
    "  \"yardline_100\": 3,\n",
    "  \"down\": 4,\n",
    "  \"ydstogo\": 3,\n",
    "  \"game_seconds_remaining\": 5,   \n",
    "  \"half_seconds_remaining\": 5,\n",
    "  \"score_differential\": -3,      \n",
    "  \"posteam_timeouts_remaining\": 1,\n",
    "  \"defteam_timeouts_remaining\": 0,\n",
    "  \"temp_F\": 61,\n",
    "  \"wind_mph\": 13\n",
    "}\n",
    "\n",
    "test_state = pd.DataFrame([state])\n",
    "test_pbp_pre_computed, test_pbp_fourth = create_df_with_ewp(test_state, test=True, penalty_params=best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "d3410e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05440210249671485"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = pbp_fourth_test_tuned.copy()\n",
    "m = (d[\"down\"]==4) & d[[\"decision_margin\",\"go_fail_distance_penalty\",\"p_convert\"]].notna().all(axis=1)\n",
    "\n",
    "delta_ewp = (1 - d.loc[m, \"p_convert\"]) * d.loc[m, \"go_fail_penalty_wp\"]\n",
    "(delta_ewp > d.loc[m, \"decision_margin\"]).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "4d340a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3805.000000\n",
       "mean        0.004463\n",
       "std         0.003515\n",
       "min         0.000000\n",
       "50%         0.004254\n",
       "90%         0.008446\n",
       "95%         0.010628\n",
       "99%         0.016640\n",
       "max         0.025174\n",
       "Name: go_fail_penalty_wp, dtype: float64"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pbp_fourth_test_tuned.loc[m, \"go_fail_penalty_wp\"].describe(percentiles=[.9,.95,.99])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "129ac4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brier score: 0.15837\n",
      "Reliability: 0.00092\n",
      "Resolution: 0.09033\n",
      "Uncertainty: 0.24871\n",
      "Brier check (reliability - resolution + uncertainty): 0.15930\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute calibration, Brier score, reliability/resolution\n",
    "# Bin predicted WP\n",
    "bins = np.linspace(0, 1, 11)\n",
    "wp_bin = pd.cut(pbp_fourth_test_tuned['wp_pred'], bins, include_lowest=True)\n",
    "\n",
    "# Aggregate by bin\n",
    "cal_table = pbp_fourth_test_tuned.groupby(wp_bin).agg(\n",
    "    wp_pred_mean=('wp_pred', 'mean'),\n",
    "    win_rate=('win_actual', 'mean'),\n",
    "    count=('win_actual', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Brier score\n",
    "brier = np.mean((pbp_fourth_test_tuned['wp_pred'] - pbp_fourth_test_tuned['win_actual'])**2)\n",
    "\n",
    "# Reliability and resolution\n",
    "N = len(pbp_fourth_test_tuned)\n",
    "reliability = np.sum(cal_table['count'] / N * (cal_table['wp_pred_mean'] - cal_table['win_rate'])**2)\n",
    "resolution = np.sum(cal_table['count'] / N * (cal_table['win_rate'] - pbp_fourth_test_tuned['win_actual'].mean())**2)\n",
    "uncertainty = np.mean(pbp_fourth_test_tuned['win_actual']) * (1 - np.mean(pbp_fourth_test_tuned['win_actual']))\n",
    "brier_check = reliability - resolution + uncertainty\n",
    "\n",
    "# Print results\n",
    "print(f\"Brier score: {brier:.5f}\")\n",
    "print(f\"Reliability: {reliability:.5f}\")\n",
    "print(f\"Resolution: {resolution:.5f}\")\n",
    "print(f\"Uncertainty: {uncertainty:.5f}\")\n",
    "print(f\"Brier check (reliability - resolution + uncertainty): {brier_check:.5f}\")\n",
    "\n",
    "# Plot calibration\n",
    "x = cal_table['wp_pred_mean'].values.ravel()  # ensures 1D\n",
    "y = cal_table['win_rate'].values.ravel()     # ensures 1D\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(x, y, marker='o')\n",
    "plt.plot([0,1], [0,1], '--', color='gray')\n",
    "plt.xlabel('Predicted WP')\n",
    "plt.ylabel('Observed WP')\n",
    "plt.title('Calibration Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "bebf30e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wp_pred</th>\n",
       "      <th>wp_pred_mean</th>\n",
       "      <th>win_rate</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(-0.001, 0.1]</td>\n",
       "      <td>0.028692</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.1, 0.2]</td>\n",
       "      <td>0.145941</td>\n",
       "      <td>0.102881</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.2, 0.3]</td>\n",
       "      <td>0.254055</td>\n",
       "      <td>0.230159</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.3, 0.4]</td>\n",
       "      <td>0.352066</td>\n",
       "      <td>0.364486</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.4, 0.5]</td>\n",
       "      <td>0.451286</td>\n",
       "      <td>0.454855</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.5, 0.6]</td>\n",
       "      <td>0.554089</td>\n",
       "      <td>0.517073</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0.6, 0.7]</td>\n",
       "      <td>0.652651</td>\n",
       "      <td>0.599369</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0.7, 0.8]</td>\n",
       "      <td>0.744525</td>\n",
       "      <td>0.733119</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(0.8, 0.9]</td>\n",
       "      <td>0.854370</td>\n",
       "      <td>0.897338</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(0.9, 1.0]</td>\n",
       "      <td>0.958073</td>\n",
       "      <td>0.997238</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         wp_pred  wp_pred_mean  win_rate  count\n",
       "0  (-0.001, 0.1]      0.028692  0.007905    506\n",
       "1     (0.1, 0.2]      0.145941  0.102881    243\n",
       "2     (0.2, 0.3]      0.254055  0.230159    378\n",
       "3     (0.3, 0.4]      0.352066  0.364486    428\n",
       "4     (0.4, 0.5]      0.451286  0.454855    587\n",
       "5     (0.5, 0.6]      0.554089  0.517073    410\n",
       "6     (0.6, 0.7]      0.652651  0.599369    317\n",
       "7     (0.7, 0.8]      0.744525  0.733119    311\n",
       "8     (0.8, 0.9]      0.854370  0.897338    263\n",
       "9     (0.9, 1.0]      0.958073  0.997238    362"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "bf943f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ewp_punt</th>\n",
       "      <th>ewp_fg</th>\n",
       "      <th>ewp_go_adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0.0, 0.1]</th>\n",
       "      <td>0.022</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.1, 0.2]</th>\n",
       "      <td>0.090</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.2, 0.3]</th>\n",
       "      <td>0.254</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.3, 0.4]</th>\n",
       "      <td>0.407</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.4, 0.5]</th>\n",
       "      <td>0.454</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.5, 0.6]</th>\n",
       "      <td>0.506</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.6, 0.7]</th>\n",
       "      <td>0.639</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.7, 0.8]</th>\n",
       "      <td>0.748</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.8, 0.9]</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.9, 1.0]</th>\n",
       "      <td>0.994</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ewp_punt  ewp_fg  ewp_go_adj\n",
       "(0.0, 0.1]     0.022   0.019       0.007\n",
       "(0.1, 0.2]     0.090   0.147       0.104\n",
       "(0.2, 0.3]     0.254   0.280       0.242\n",
       "(0.3, 0.4]     0.407   0.408       0.379\n",
       "(0.4, 0.5]     0.454   0.499       0.473\n",
       "(0.5, 0.6]     0.506   0.541       0.512\n",
       "(0.6, 0.7]     0.639   0.728       0.657\n",
       "(0.7, 0.8]     0.748   0.729       0.725\n",
       "(0.8, 0.9]     0.912   0.920       0.915\n",
       "(0.9, 1.0]     0.994   0.988       0.997"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = np.linspace(0, 1, 11)\n",
    "calibration_df = pd.DataFrame(index=pd.IntervalIndex.from_tuples([(round(bins[i],2), round(bins[i+1],2)) for i in range(len(bins)-1)]))\n",
    "\n",
    "# Function to compute empirical win fraction per bin\n",
    "def empirical_win_fraction(pred_col):\n",
    "    return pbp_fourth_test_tuned.groupby(pd.cut(pbp_fourth_test_tuned[pred_col], bins=bins))['win_actual'].mean()\n",
    "\n",
    "# Compute results for each play type\n",
    "calibration_df['ewp_punt'] = round(empirical_win_fraction('ewp_punt'),3)\n",
    "calibration_df['ewp_fg'] = round(empirical_win_fraction('ewp_fg'),3)\n",
    "calibration_df['ewp_go_adj'] = round(empirical_win_fraction('ewp_go_adj'),3)\n",
    "\n",
    "# Bins indicate predicted wp bin; columns are how often a team actually won in that predicted wp bin\n",
    "calibration_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "5e9d9219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No EWP violations detected.\n"
     ]
    }
   ],
   "source": [
    "ewp_columns = ['ewp_punt', 'ewp_fg', 'ewp_go_adj']\n",
    "\n",
    "# Boolean mask of violations\n",
    "violation_mask = (pbp_fourth_test_tuned[ewp_columns] < 0) | (pbp_fourth_test_tuned[ewp_columns] > 1)\n",
    "\n",
    "# Count violations per column\n",
    "violations = violation_mask.sum()\n",
    "\n",
    "if violations.sum() == 0:\n",
    "    print(\"No EWP violations detected.\")\n",
    "else:\n",
    "    print(\"Violations detected:\")\n",
    "    print(violations)\n",
    "    print(pbp_fourth_test_tuned[violation_mask.any(axis=1)].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "9c2cdeaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010528973"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = pbp_fourth_test_tuned[wp_features]\n",
    "state_flipped = state.copy()\n",
    "state_flipped[\"score_differential\"] *= -1\n",
    "state_flipped[[\"posteam_timeouts_remaining\",\"defteam_timeouts_remaining\"]] = (\n",
    "    state_flipped[[\"defteam_timeouts_remaining\",\"posteam_timeouts_remaining\"]].values\n",
    ")\n",
    "state_flipped[\"yardline_100\"] = 100 - state_flipped[\"yardline_100\"]\n",
    "state_flipped[\"score_time_ratio\"] = state_flipped[\"score_differential\"].abs() / (state_flipped[\"game_seconds_remaining\"] + 1)\n",
    "\n",
    "wp = wp_symmetric_adjust(state, predict_wp)\n",
    "wp_flipped = wp_symmetric_adjust(state_flipped, predict_wp)\n",
    "flip_err = wp + wp_flipped - 1\n",
    "\n",
    "flip_err.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "3a28a143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011782318523727048"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conditional mean regret\n",
    "pbp_fourth_test_tuned[pbp_fourth_test_tuned.follow_model == 0].regret_actual.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a593dbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regret by Play Type Conditioned on Coach Disagreement:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>95th</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>play_type_actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>field_goal</th>\n",
       "      <td>283</td>\n",
       "      <td>0.009751</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>0.029282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>468</td>\n",
       "      <td>0.014965</td>\n",
       "      <td>0.010715</td>\n",
       "      <td>0.045924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>punt</th>\n",
       "      <td>229</td>\n",
       "      <td>0.007788</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>0.024611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  size      mean    median      95th\n",
       "play_type_actual                                    \n",
       "field_goal         283  0.009751  0.006840  0.029282\n",
       "go                 468  0.014965  0.010715  0.045924\n",
       "punt               229  0.007788  0.005567  0.024611"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute regret stats by play type ---\n",
    "df_disagree = pbp_fourth_test_tuned[pbp_fourth_test_tuned[\"disagreed\"] == True].copy()\n",
    "regret_by_play = df_disagree.groupby('play_type_actual')['regret_actual'].agg(['mean', 'median'])\n",
    "df_disagree['regret_actual'] = pd.to_numeric(df_disagree['regret_actual'], errors='coerce')\n",
    "\n",
    "# Compute stats\n",
    "regret_by_play = df_disagree.groupby('play_type_actual')['regret_actual'].agg(['size', 'mean', 'median'])\n",
    "regret_by_play['95th'] = df_disagree.groupby('play_type_actual')['regret_actual'].quantile(0.95)\n",
    "\n",
    "print(\"Regret by Play Type Conditioned on Coach Disagreement:\")\n",
    "regret_by_play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "eb03fefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regret vs Decision Margin (Disagreements)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>p95</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision_margin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(-0.001, 0.000557]</th>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.000557, 0.00183]</th>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00183, 0.00365]</th>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.005883</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00365, 0.00536]</th>\n",
       "      <td>0.005254</td>\n",
       "      <td>0.010062</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00536, 0.00736]</th>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.008165</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00736, 0.00974]</th>\n",
       "      <td>0.009124</td>\n",
       "      <td>0.011596</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00974, 0.013]</th>\n",
       "      <td>0.011887</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.013, 0.0179]</th>\n",
       "      <td>0.015792</td>\n",
       "      <td>0.019636</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0179, 0.0261]</th>\n",
       "      <td>0.021801</td>\n",
       "      <td>0.027530</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0261, 0.073]</th>\n",
       "      <td>0.042054</td>\n",
       "      <td>0.072189</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mean       p95  count\n",
       "decision_margin                               \n",
       "(-0.001, 0.000557]   0.000214  0.000552     98\n",
       "(0.000557, 0.00183]  0.001644  0.004057     98\n",
       "(0.00183, 0.00365]   0.003185  0.005883     98\n",
       "(0.00365, 0.00536]   0.005254  0.010062     98\n",
       "(0.00536, 0.00736]   0.006868  0.008165     98\n",
       "(0.00736, 0.00974]   0.009124  0.011596     98\n",
       "(0.00974, 0.013]     0.011887  0.014760     98\n",
       "(0.013, 0.0179]      0.015792  0.019636     98\n",
       "(0.0179, 0.0261]     0.021801  0.027530     98\n",
       "(0.0261, 0.073]      0.042054  0.072189     98"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Follow Model Rate vs Decision Margin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>follow_rate</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>margin_bin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(-0.001, 0.0021]</th>\n",
       "      <td>0.440945</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0021, 0.00496]</th>\n",
       "      <td>0.584211</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00496, 0.00784]</th>\n",
       "      <td>0.632546</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00784, 0.0114]</th>\n",
       "      <td>0.673684</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0114, 0.0154]</th>\n",
       "      <td>0.716535</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0154, 0.0213]</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0213, 0.0282]</th>\n",
       "      <td>0.855263</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0282, 0.0378]</th>\n",
       "      <td>0.887139</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0378, 0.0532]</th>\n",
       "      <td>0.915789</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0532, 0.411]</th>\n",
       "      <td>0.968504</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    follow_rate  count\n",
       "margin_bin                            \n",
       "(-0.001, 0.0021]       0.440945    381\n",
       "(0.0021, 0.00496]      0.584211    380\n",
       "(0.00496, 0.00784]     0.632546    381\n",
       "(0.00784, 0.0114]      0.673684    380\n",
       "(0.0114, 0.0154]       0.716535    381\n",
       "(0.0154, 0.0213]       0.750000    380\n",
       "(0.0213, 0.0282]       0.855263    380\n",
       "(0.0282, 0.0378]       0.887139    381\n",
       "(0.0378, 0.0532]       0.915789    380\n",
       "(0.0532, 0.411]        0.968504    381"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regret vs margin for disagreements\n",
    "disagree_bins = pd.qcut(df_disagree[\"decision_margin\"], q=10, duplicates=\"drop\")\n",
    "regret_by_margin = df_disagree.groupby(disagree_bins)[\"regret_actual\"].agg(\n",
    "    mean=\"mean\",\n",
    "    p95=lambda x: np.percentile(x, 95),\n",
    "    count=\"count\"\n",
    ")\n",
    "print(\"Regret vs Decision Margin (Disagreements)\")\n",
    "display(regret_by_margin)\n",
    "\n",
    "# Bin decision margin\n",
    "pbp_fourth_test_tuned[\"margin_bin\"] = pd.qcut(pbp_fourth_test_tuned[\"decision_margin\"], 10)\n",
    "follow_by_margin = pbp_fourth_test_tuned.groupby(\"margin_bin\").agg(\n",
    "    follow_rate=(\"follow_model\", \"mean\"),\n",
    "    count=(\"follow_model\", \"size\")\n",
    ")\n",
    "print(\"Follow Model Rate vs Decision Margin\")\n",
    "follow_by_margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "3b75617e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recommended_play</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>field_goal</th>\n",
       "      <td>0.064182</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>0.068488</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>punt</th>\n",
       "      <td>0.061914</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mean  size\n",
       "recommended_play                \n",
       "field_goal        0.064182     8\n",
       "go                0.068488     1\n",
       "punt              0.061914     6"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disagree[(df_disagree.decision_margin > .05)].groupby('recommended_play')['regret_actual'].agg(['mean', 'size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "b2aa8366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Recommended</th>\n",
       "      <th>punt</th>\n",
       "      <th>field_goal</th>\n",
       "      <th>go</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>punt</th>\n",
       "      <td>1710</td>\n",
       "      <td>31</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>field_goal</th>\n",
       "      <td>112</td>\n",
       "      <td>777</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>304</td>\n",
       "      <td>164</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Recommended  punt  field_goal   go\n",
       "Actual                            \n",
       "punt         1710          31  198\n",
       "field_goal    112         777  171\n",
       "go            304         164  338"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pbp_fourth_test_tuned[pbp_fourth_test_tuned.season == 2024]\n",
    "\n",
    "labels = [\"punt\", \"field_goal\", \"go\"]\n",
    "\n",
    "cm_df = test[[\"play_type_actual\", \"recommended_play\"]].dropna()\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    cm_df[\"play_type_actual\"].astype(str),\n",
    "    cm_df[\"recommended_play\"].astype(str),\n",
    "    labels=labels\n",
    ")\n",
    "\n",
    "confusion = pd.DataFrame(\n",
    "    cm,\n",
    "    index=pd.Index(labels, name=\"Actual\"),\n",
    "    columns=pd.Index(labels, name=\"Recommended\")\n",
    ")\n",
    "\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "75ac2a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Recommended</th>\n",
       "      <th>punt</th>\n",
       "      <th>field_goal</th>\n",
       "      <th>go</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>punt</th>\n",
       "      <td>0.8819</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>field_goal</th>\n",
       "      <td>0.1057</td>\n",
       "      <td>0.7330</td>\n",
       "      <td>0.1613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>0.3772</td>\n",
       "      <td>0.2035</td>\n",
       "      <td>0.4194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Recommended    punt  field_goal      go\n",
       "Actual                                 \n",
       "punt         0.8819      0.0160  0.1021\n",
       "field_goal   0.1057      0.7330  0.1613\n",
       "go           0.3772      0.2035  0.4194"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_norm = confusion.div(confusion.sum(axis=1), axis=0)\n",
    "round(confusion_norm,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09a679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
