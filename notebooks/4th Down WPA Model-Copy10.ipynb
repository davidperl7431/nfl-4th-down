{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a449ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1fd77fb2bd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import optuna\n",
    "\n",
    "# modeling\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.special import logit, expit\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# PyTorch for conversion model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# nfl pbp loader\n",
    "import nfl_data_py as nfl\n",
    "\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "\n",
    "# reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f038186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading play-by-play for seasons: range(2011, 2026)\n",
      "2011 done.\n",
      "2012 done.\n",
      "2013 done.\n",
      "2014 done.\n",
      "2015 done.\n",
      "2016 done.\n",
      "2017 done.\n",
      "2018 done.\n",
      "2019 done.\n",
      "2020 done.\n",
      "2021 done.\n",
      "2022 done.\n",
      "2023 done.\n",
      "2024 done.\n",
      "2025 done.\n",
      "Rows loaded: 722172\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>play_id</th>\n",
       "      <th>game_id</th>\n",
       "      <th>old_game_id</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>season_type</th>\n",
       "      <th>week</th>\n",
       "      <th>posteam</th>\n",
       "      <th>posteam_type</th>\n",
       "      <th>defteam</th>\n",
       "      <th>...</th>\n",
       "      <th>was_pressure</th>\n",
       "      <th>route</th>\n",
       "      <th>defense_man_zone_type</th>\n",
       "      <th>defense_coverage_type</th>\n",
       "      <th>offense_names</th>\n",
       "      <th>defense_names</th>\n",
       "      <th>offense_positions</th>\n",
       "      <th>defense_positions</th>\n",
       "      <th>offense_numbers</th>\n",
       "      <th>defense_numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2011_01_ATL_CHI</td>\n",
       "      <td>2011091105</td>\n",
       "      <td>CHI</td>\n",
       "      <td>ATL</td>\n",
       "      <td>REG</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>2011_01_ATL_CHI</td>\n",
       "      <td>2011091105</td>\n",
       "      <td>CHI</td>\n",
       "      <td>ATL</td>\n",
       "      <td>REG</td>\n",
       "      <td>1</td>\n",
       "      <td>CHI</td>\n",
       "      <td>home</td>\n",
       "      <td>ATL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.0</td>\n",
       "      <td>2011_01_ATL_CHI</td>\n",
       "      <td>2011091105</td>\n",
       "      <td>CHI</td>\n",
       "      <td>ATL</td>\n",
       "      <td>REG</td>\n",
       "      <td>1</td>\n",
       "      <td>CHI</td>\n",
       "      <td>home</td>\n",
       "      <td>ATL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.0</td>\n",
       "      <td>2011_01_ATL_CHI</td>\n",
       "      <td>2011091105</td>\n",
       "      <td>CHI</td>\n",
       "      <td>ATL</td>\n",
       "      <td>REG</td>\n",
       "      <td>1</td>\n",
       "      <td>CHI</td>\n",
       "      <td>home</td>\n",
       "      <td>ATL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112.0</td>\n",
       "      <td>2011_01_ATL_CHI</td>\n",
       "      <td>2011091105</td>\n",
       "      <td>CHI</td>\n",
       "      <td>ATL</td>\n",
       "      <td>REG</td>\n",
       "      <td>1</td>\n",
       "      <td>CHI</td>\n",
       "      <td>home</td>\n",
       "      <td>ATL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 398 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   play_id          game_id old_game_id home_team away_team season_type  week  \\\n",
       "0      1.0  2011_01_ATL_CHI  2011091105       CHI       ATL         REG     1   \n",
       "1     36.0  2011_01_ATL_CHI  2011091105       CHI       ATL         REG     1   \n",
       "2     69.0  2011_01_ATL_CHI  2011091105       CHI       ATL         REG     1   \n",
       "3     91.0  2011_01_ATL_CHI  2011091105       CHI       ATL         REG     1   \n",
       "4    112.0  2011_01_ATL_CHI  2011091105       CHI       ATL         REG     1   \n",
       "\n",
       "  posteam posteam_type defteam  ... was_pressure  route defense_man_zone_type  \\\n",
       "0    None         None    None  ...          NaN    NaN                   NaN   \n",
       "1     CHI         home     ATL  ...          NaN    NaN                   NaN   \n",
       "2     CHI         home     ATL  ...          NaN    NaN                   NaN   \n",
       "3     CHI         home     ATL  ...          NaN    NaN                   NaN   \n",
       "4     CHI         home     ATL  ...          NaN    NaN                   NaN   \n",
       "\n",
       "   defense_coverage_type  offense_names  defense_names offense_positions  \\\n",
       "0                    NaN            NaN            NaN               NaN   \n",
       "1                    NaN            NaN            NaN               NaN   \n",
       "2                    NaN            NaN            NaN               NaN   \n",
       "3                    NaN            NaN            NaN               NaN   \n",
       "4                    NaN            NaN            NaN               NaN   \n",
       "\n",
       "   defense_positions  offense_numbers  defense_numbers  \n",
       "0                NaN              NaN              NaN  \n",
       "1                NaN              NaN              NaN  \n",
       "2                NaN              NaN              NaN  \n",
       "3                NaN              NaN              NaN  \n",
       "4                NaN              NaN              NaN  \n",
       "\n",
       "[5 rows x 398 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download PBP\n",
    "seasons = range(2011,2026)\n",
    "print(\"Loading play-by-play for seasons:\", seasons)\n",
    "raw_pbp = nfl.import_pbp_data(seasons, downcast=False)  # returns a DataFrame (likely large)\n",
    "\n",
    "print(\"Rows loaded:\", raw_pbp.shape[0])\n",
    "raw_pbp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02287f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_weather(weather_str):\n",
    "    \"\"\"\n",
    "    Parses a weather string into structured features:\n",
    "        - temp_F: float\n",
    "        - humidity: float (percentage)\n",
    "        - wind_mph: float\n",
    "        - wind_dir: str\n",
    "        - conditions: str (general description, e.g., 'sunny', 'cloudy', etc.)\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        \"temp_F\": None,\n",
    "        \"humidity\": None,\n",
    "        \"wind_mph\": None,\n",
    "        \"wind_dir\": None,\n",
    "        \"conditions\": None\n",
    "    }\n",
    "    \n",
    "    if not isinstance(weather_str, str):\n",
    "        return result\n",
    "    \n",
    "    lower_str = weather_str.lower()\n",
    "    \n",
    "    # Extract temperature\n",
    "    temp_match = re.search(r'(\\d+)\\s*°?\\s*f', lower_str)\n",
    "    if temp_match:\n",
    "        result['temp_F'] = float(temp_match.group(1))\n",
    "    \n",
    "    # Extract humidity\n",
    "    hum_match = re.search(r'humidity[:\\s]*(\\d+)%', lower_str)\n",
    "    if hum_match:\n",
    "        result['humidity'] = float(hum_match.group(1))\n",
    "    \n",
    "    # Extract wind speed and direction\n",
    "    wind_match = re.search(r'wind[:\\s]*([nesw]+)\\s*(\\d+)\\s*mph', lower_str)\n",
    "    if wind_match:\n",
    "        result['wind_dir'] = wind_match.group(1).upper()\n",
    "        result['wind_mph'] = float(wind_match.group(2))\n",
    "    \n",
    "    # Extract general conditions\n",
    "    conditions = []\n",
    "    for cond in ['sunny', 'cloudy', 'clear', 'rain', 'snow', 'fog', 'drizzle', 'storm', 'windy']:\n",
    "        if cond in lower_str:\n",
    "            conditions.append(cond)\n",
    "    if conditions:\n",
    "        result['conditions'] = ','.join(conditions)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def deconstruct_weather(df, weather_col='weather'):\n",
    "    \"\"\"\n",
    "    Adds structured weather columns to a DataFrame based on a weather string column.\n",
    "    \n",
    "    New columns added:\n",
    "      - temp_F\n",
    "      - humidity\n",
    "      - wind_mph\n",
    "      - wind_dir\n",
    "      - conditions\n",
    "    \"\"\"\n",
    "    weather_data = df[weather_col].apply(parse_weather)\n",
    "    weather_df = pd.DataFrame(weather_data.tolist())\n",
    "    df = pd.concat([df.reset_index(drop=True), weather_df], axis=1)\n",
    "    \n",
    "    # Fill missing wind speeds with 0\n",
    "    df['wind_mph'] = df['wind_mph'].fillna(0)\n",
    "\n",
    "    # Fill missing temperatures with 60°F\n",
    "    df['temp_F'] = df['temp_F'].fillna(60)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6062feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = ['play_type', 'season', 'home_wp_post', 'away_wp_post', 'weather', 'yardline_100', 'ydstogo',\n",
    "               'game_seconds_remaining', 'half_seconds_remaining', 'posteam', 'defteam',\n",
    "               'posteam_timeouts_remaining', 'defteam_timeouts_remaining', 'kick_distance', 'touchback',\n",
    "                'return_yards', 'first_down', 'touchdown', 'game_id', 'score_differential',\n",
    "                'home_team', 'away_team', 'home_score', 'away_score', 'down', 'field_goal_result', 'penalty',\n",
    "               'home_coach', 'away_coach']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "159098a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp = raw_pbp.loc[:, cols_to_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3da8c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_to_col = {\n",
    "    \"punt\": \"punt\",\n",
    "    \"field_goal\": \"field_goal\",\n",
    "    \"run\": \"go\",\n",
    "    \"pass\": \"go\"\n",
    "}\n",
    "\n",
    "pbp[\"play_type_actual\"] = pbp[\"play_type\"].map(action_to_col)\n",
    "pbp = pbp[pbp.play_type_actual.isin(['punt', 'go', 'field_goal'])]\n",
    "pbp = deconstruct_weather(pbp)\n",
    "pbp = pbp[pbp.penalty == 0]\n",
    "pbp['fg_made'] = (pbp[\"field_goal_result\"] == \"made\").astype(int)\n",
    "\n",
    "action_to_ewp_col = {\n",
    "    \"punt\": \"ewp_punt\",\n",
    "    \"field_goal\": \"ewp_fg\",\n",
    "    \"go\": \"ewp_go_adj\"\n",
    "}\n",
    "pbp[\"actual_ewp_col\"] = pbp[\"play_type_actual\"].map(action_to_ewp_col)\n",
    "\n",
    "pbp[\"possession_coach\"] = np.where(\n",
    "    pbp[\"posteam\"] == pbp[\"home_team\"],\n",
    "    pbp[\"home_coach\"],\n",
    "    pbp[\"away_coach\"]\n",
    ")\n",
    "\n",
    "pbp[\"defending_coach\"] = np.where(\n",
    "    pbp[\"posteam\"] == pbp[\"home_team\"],\n",
    "    pbp[\"away_coach\"],\n",
    "    pbp[\"home_coach\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09e7bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = pbp.season.unique() # seasons\n",
    "test_season = seasons.max()\n",
    "\n",
    "pbp_train = pbp[pbp.season != test_season]\n",
    "pbp_test = pbp[pbp.season == test_season]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5683fcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_temporal_folds(df, season_col=\"season\", min_train_seasons=3):\n",
    "    \"\"\"\n",
    "    Expanding-window CV folds by season.\n",
    "    Returns list of (train_idx, val_idx).\n",
    "    \"\"\"\n",
    "    seasons = np.sort(df[season_col].unique())\n",
    "    folds = []\n",
    "\n",
    "    for i in range(min_train_seasons, len(seasons)):\n",
    "        train_seasons = seasons[:i]\n",
    "        val_season = seasons[i]\n",
    "\n",
    "        train_idx = df[df[season_col].isin(train_seasons)].index\n",
    "        val_idx = df[df[season_col] == val_season].index\n",
    "\n",
    "        folds.append((train_idx, val_idx))\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3a81eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Drop rows missing home/away WP\n",
    "wp_df = pbp_train.dropna(subset=[\"home_wp_post\", \"away_wp_post\"]).copy()\n",
    "\n",
    "# --- Define features\n",
    "wp_df[\"score_time_ratio\"] = wp_df[\"score_differential\"].abs() / (wp_df[\"game_seconds_remaining\"] + 1)\n",
    "wp_features = [\n",
    "    \"yardline_100\",\n",
    "    \"down\",\n",
    "    \"ydstogo\",\n",
    "    \"game_seconds_remaining\",\n",
    "    \"half_seconds_remaining\",\n",
    "    \"score_differential\",\n",
    "    \"posteam_timeouts_remaining\",\n",
    "    \"defteam_timeouts_remaining\",\n",
    "    \"temp_F\",\n",
    "    \"wind_mph\"\n",
    "]\n",
    "\n",
    "# --- Define posteam WP target\n",
    "wp_df[\"wp_target\"] = np.where(\n",
    "    wp_df[\"posteam\"] == wp_df[\"home_team\"],\n",
    "    wp_df[\"home_wp_post\"],\n",
    "    wp_df[\"away_wp_post\"]\n",
    ")\n",
    "\n",
    "wp_df = wp_df.reset_index(drop=True)\n",
    "\n",
    "X_wp = wp_df[wp_features]\n",
    "y_wp = wp_df[\"wp_target\"]\n",
    "\n",
    "# --- Clip target to avoid exact 0/1 ---\n",
    "epsilon = 1e-6\n",
    "y_wp_clipped = y_wp.clip(epsilon, 1 - epsilon).reset_index(drop=True)\n",
    "\n",
    "# --- Monotone constraints\n",
    "monotone_constraints_dict = {\n",
    "    \"yardline_100\": -1,               # closer to opponent endzone → WP ↑\n",
    "    \"down\": -1,                       # higher down (worse) → WP ↓\n",
    "    \"ydstogo\": -1,                    # more yards to go → WP ↓\n",
    "    \"score_differential\": 1,          # lead → WP ↑\n",
    "    \"posteam_timeouts_remaining\": 1,  # more TOs → WP ↑\n",
    "    \"defteam_timeouts_remaining\": -1  # opponent TOs → WP ↓\n",
    "}\n",
    "\n",
    "mono_tuple = tuple(monotone_constraints_dict.get(c, 0) for c in X_wp.columns)\n",
    "\n",
    "wp_folds = make_temporal_folds(wp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04c09fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wp_objective(trial):\n",
    "    \n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 5),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.02, 0.08),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 400),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 0.9),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 0.9),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 20, 100),\n",
    "        \"verbosity\": 0,\n",
    "        \"monotone_constraints\": mono_tuple,\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"early_stopping_rounds\": 100,\n",
    "        \"max_bin\": 128,\n",
    "        \"n_jobs\": 4,\n",
    "    }\n",
    "\n",
    "    rmses = []\n",
    "    for train_idx, val_idx in wp_folds:\n",
    "        X_train = X_wp.iloc[train_idx].to_numpy(dtype=np.float32, copy=False)\n",
    "        X_val   = X_wp.iloc[val_idx].to_numpy(dtype=np.float32, copy=False)\n",
    "        y_train = y_wp_clipped.iloc[train_idx].to_numpy(dtype=np.float32, copy=False)\n",
    "        y_val   = y_wp_clipped.iloc[val_idx].to_numpy(dtype=np.float32, copy=False)\n",
    "\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        preds = model.predict(X_val)\n",
    "        rmses.append(mean_squared_error(y_val, preds, squared=False))\n",
    "\n",
    "    return float(np.mean(rmses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9264a522",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) unable to open database file\n(Background on this error at: http://sqlalche.me/e/14/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_wrap_pool_connect\u001b[1;34m(self, fn, connection)\u001b[0m\n\u001b[0;32m   3140\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3141\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3142\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mdialect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdbapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\pool\\base.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \"\"\"\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_ConnectionFairy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\pool\\base.py\u001b[0m in \u001b[0;36m_checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m    754\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfairy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m             \u001b[0mfairy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ConnectionRecord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    756\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\pool\\base.py\u001b[0m in \u001b[0;36mcheckout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheckout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m         \u001b[0mrec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\pool\\impl.py\u001b[0m in \u001b[0;36m_do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\pool\\base.py\u001b[0m in \u001b[0;36m_create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_ConnectionRecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\pool\\base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_connect_check\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinalize_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\pool\\base.py\u001b[0m in \u001b[0;36m__connect\u001b[1;34m(self, first_connect_check)\u001b[0m\n\u001b[0;32m    604\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msafe_reraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m                 \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error on connect(): %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m                 compat.raise_(\n\u001b[0m\u001b[0;32m     71\u001b[0m                     \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\util\\compat.py\u001b[0m in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\pool\\base.py\u001b[0m in \u001b[0;36m__connect\u001b[1;34m(self, first_connect_check)\u001b[0m\n\u001b[0;32m    598\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstarttime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m             \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invoke_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m             \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Created new connection %r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\create.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    577\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdialect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\default.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;31m# inherits the docstring from interfaces.Dialect.connect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdbapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: unable to open database file",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-1918158dffea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"sqlite:///optuna/wp_study.db\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m wp_study = optuna.create_study(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mstudy_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"testing_wp_study\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"minimize\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36mcreate_study\u001b[1;34m(storage, sampler, pruner, study_name, direction, load_if_exists, directions)\u001b[0m\n\u001b[0;32m   1134\u001b[0m     ]\n\u001b[0;32m   1135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1136\u001b[1;33m     \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstorages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_storage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1137\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m         \u001b[0mstudy_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_new_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\storages\\__init__.py\u001b[0m in \u001b[0;36mget_storage\u001b[1;34m(storage)\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mRedisStorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_CachedStorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRDBStorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRDBStorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_CachedStorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\storages\\_rdb\\storage.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, url, engine_kwargs, skip_compatibility_check, heartbeat_interval, grace_period, failed_trial_callback)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoped_session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoped_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msessionmaker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBaseModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_version_manager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_VersionManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoped_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\sql\\schema.py\u001b[0m in \u001b[0;36mcreate_all\u001b[1;34m(self, bind, tables, checkfirst)\u001b[0m\n\u001b[0;32m   4742\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbind\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4743\u001b[0m             \u001b[0mbind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_bind_or_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4744\u001b[1;33m         bind._run_ddl_visitor(\n\u001b[0m\u001b[0;32m   4745\u001b[0m             \u001b[0mddl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSchemaGenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4746\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_run_ddl_visitor\u001b[1;34m(self, visitorcallable, element, **kwargs)\u001b[0m\n\u001b[0;32m   3005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_ddl_visitor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisitorcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3007\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3008\u001b[0m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_ddl_visitor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvisitorcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self, close_with_result)\u001b[0m\n\u001b[0;32m   2921\u001b[0m             \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2922\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2923\u001b[1;33m             \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclose_with_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclose_with_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2924\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[0mtrans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self, close_with_result)\u001b[0m\n\u001b[0;32m   3093\u001b[0m         \"\"\"\n\u001b[0;32m   3094\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3095\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_connection_cls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclose_with_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclose_with_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3097\u001b[0m     @util.deprecated(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, engine, connection, close_with_result, _branch_from, _execution_options, _dispatch, _has_events)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[0mconnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mconnection\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m                 \u001b[1;32melse\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m             )\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36mraw_connection\u001b[1;34m(self, _connection)\u001b[0m\n\u001b[0;32m   3172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3173\u001b[0m         \"\"\"\n\u001b[1;32m-> 3174\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wrap_pool_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_connection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_wrap_pool_connect\u001b[1;34m(self, fn, connection)\u001b[0m\n\u001b[0;32m   3142\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mdialect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdbapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3143\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mconnection\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3144\u001b[1;33m                 Connection._handle_dbapi_exception_noconnection(\n\u001b[0m\u001b[0;32m   3145\u001b[0m                     \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdialect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3146\u001b[0m                 )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception_noconnection\u001b[1;34m(cls, e, dialect, engine)\u001b[0m\n\u001b[0;32m   2001\u001b[0m             \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewraise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2002\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2003\u001b[1;33m             util.raise_(\n\u001b[0m\u001b[0;32m   2004\u001b[0m                 \u001b[0msqlalchemy_exception\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2005\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\util\\compat.py\u001b[0m in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[1;31m# credit to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_wrap_pool_connect\u001b[1;34m(self, fn, connection)\u001b[0m\n\u001b[0;32m   3139\u001b[0m         \u001b[0mdialect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdialect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3140\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3141\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3142\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mdialect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdbapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3143\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mconnection\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\pool\\base.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m         \"\"\"\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_ConnectionFairy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_return_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\pool\\base.py\u001b[0m in \u001b[0;36m_checkout\u001b[1;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[0;32m    753\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_checkout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreadconns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfairy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfairy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m             \u001b[0mfairy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ConnectionRecord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    756\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[0mfairy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\pool\\base.py\u001b[0m in \u001b[0;36mcheckout\u001b[1;34m(cls, pool)\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheckout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m         \u001b[0mrec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m             \u001b[0mdbapi_connection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\pool\\impl.py\u001b[0m in \u001b[0;36m_do_get\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_get\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrecreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\pool\\base.py\u001b[0m in \u001b[0;36m_create_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;34m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_ConnectionRecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_invalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_checkin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\pool\\base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, pool, connect)\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_connect_check\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinalize_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\pool\\base.py\u001b[0m in \u001b[0;36m__connect\u001b[1;34m(self, first_connect_check)\u001b[0m\n\u001b[0;32m    603\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msafe_reraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m                 \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Error on connect(): %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfirst_connect_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\util\\langhelpers.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exc_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# remove potential circular references\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m                 compat.raise_(\n\u001b[0m\u001b[0;32m     71\u001b[0m                     \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                     \u001b[0mwith_traceback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexc_tb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\util\\compat.py\u001b[0m in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[1;31m# credit to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\pool\\base.py\u001b[0m in \u001b[0;36m__connect\u001b[1;34m(self, first_connect_check)\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstarttime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m             \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invoke_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m             \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Created new connection %r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\create.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(connection_record)\u001b[0m\n\u001b[0;32m    576\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mconnection\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdialect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[0mcreator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpop_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"creator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\default.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mcargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;31m# inherits the docstring from interfaces.Dialect.connect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdbapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate_connect_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: (sqlite3.OperationalError) unable to open database file\n(Background on this error at: http://sqlalche.me/e/14/e3q8)"
     ]
    }
   ],
   "source": [
    "storage = \"sqlite:///optuna/wp_study.db\"\n",
    "\n",
    "wp_study = optuna.create_study(\n",
    "    study_name=\"testing_wp_study\",\n",
    "    direction=\"minimize\",\n",
    "    storage=storage,\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "wp_study.optimize(wp_objective, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c081be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_best_params = wp_study.best_params\n",
    "wp_best_score = wp_study.best_value\n",
    "\n",
    "print(\"Best CV RMSE:\", wp_best_score)\n",
    "print()\n",
    "print(\"Best params:\", wp_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233ce880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add monotone constraints if not in params already\n",
    "best_params[\"monotone_constraints\"] = monotone_constraints_dict\n",
    "best_params[\"verbosity\"] = 0\n",
    "\n",
    "wp_model = XGBRegressor(**wp_best_params)\n",
    "wp_model.fit(X_wp, y_wp_clipped)  # Train on full dataset\n",
    "\n",
    "\n",
    "def predict_wp(state_df):\n",
    "    \"\"\"\n",
    "    Returns win probability for the team with possession in state_df.\n",
    "    \"\"\"\n",
    "    if \"score_time_ratio\" not in state_df.columns:\n",
    "        state_df = state_df.copy()  # prevents SettingWithCopyWarning\n",
    "        state_df.loc[:, \"score_time_ratio\"] = (\n",
    "            state_df[\"score_differential\"].abs() / (state_df[\"game_seconds_remaining\"] + 1)\n",
    "        )\n",
    "\n",
    "    preds = wp_model.predict(state_df[wp_features])\n",
    "    \n",
    "    return np.clip(preds, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wp_symmetric_adjust(state_df, predict_wp):\n",
    "    # Predict from original perspective\n",
    "    wp = predict_wp(state_df)\n",
    "\n",
    "    # Create flipped states\n",
    "    state_flipped = state_df.copy()\n",
    "    state_flipped[\"score_differential\"] *= -1\n",
    "    state_flipped[[\"posteam_timeouts_remaining\", \"defteam_timeouts_remaining\"]] = (\n",
    "        state_flipped[[\"defteam_timeouts_remaining\", \"posteam_timeouts_remaining\"]].values\n",
    "    )\n",
    "    state_flipped[\"yardline_100\"] = 100 - state_flipped[\"yardline_100\"]\n",
    "\n",
    "    # Only handle score_time_ratio if WP model actually uses it\n",
    "    if \"score_time_ratio\" in wp_features:\n",
    "        if \"score_time_ratio\" not in state_flipped.columns:\n",
    "            state_flipped.loc[:, \"score_time_ratio\"] = (\n",
    "                state_flipped[\"score_differential\"].abs() / (state_flipped[\"game_seconds_remaining\"] + 1)\n",
    "            )\n",
    "\n",
    "    wp_flipped = predict_wp(state_flipped)\n",
    "\n",
    "    # Symmetric adjustment\n",
    "    wp_sym = 0.5 * (wp + (1 - wp_flipped))\n",
    "\n",
    "    sym_weighting = 0.20\n",
    "    return (1 - sym_weighting) * wp + sym_weighting * wp_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab7ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = (pd.DataFrame({\n",
    "        \"feature\": wp_features,\n",
    "        \"importance\": wp_model.feature_importances_\n",
    "    })\n",
    "    .sort_values(\"importance\", ascending=False)\n",
    ")\n",
    "\n",
    "print(imp.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5cb42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create punt_df with only punt plays\n",
    "punt_df = pbp_train[pbp_train.play_type_actual == \"punt\"].dropna(subset=[\"kick_distance\", \"return_yards\"]).copy()\n",
    "\n",
    "# Compute net punt yardage: kick distance minus return yards, adjust for touchbacks (if available)\n",
    "# Assuming touchback puts ball at 20-yard line\n",
    "punt_df[\"net_punt\"] = punt_df[\"kick_distance\"] - punt_df[\"return_yards\"]\n",
    "punt_df.loc[punt_df[\"touchback\"] == 1, \"net_punt\"] = punt_df[\"yardline_100\"] - 20\n",
    "\n",
    "# Reset index to avoid any issues\n",
    "punt_df = punt_df.reset_index(drop=True)\n",
    "\n",
    "# Make temporal folds based on seasons in punt_df\n",
    "punt_folds = make_temporal_folds(punt_df)\n",
    "\n",
    "# Features to predict net punt\n",
    "punt_df[\"score_time_ratio\"] = punt_df[\"score_differential\"].abs() / (punt_df[\"game_seconds_remaining\"] + 1)\n",
    "punt_features = [\n",
    "    \"yardline_100\", \n",
    "    \"game_seconds_remaining\", \n",
    "    \"half_seconds_remaining\",\n",
    "    \"score_differential\",\n",
    "    \"posteam_timeouts_remaining\",\n",
    "    \"defteam_timeouts_remaining\",\n",
    "    \"temp_F\",\n",
    "    \"wind_mph\"\n",
    "]\n",
    "\n",
    "X_punt = punt_df[punt_features].values\n",
    "y_punt = punt_df[\"net_punt\"].values\n",
    "\n",
    "X_scaler = StandardScaler()\n",
    "X_punt_scaled = X_scaler.fit_transform(X_punt)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_punt_scaled = y_scaler.fit_transform(y_punt.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296053db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punt_objective(trial):\n",
    "\n",
    "    # Hyperparameters\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 16, 128)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    dropout_rate = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "\n",
    "    max_epochs = 500\n",
    "    patience = 20\n",
    "    tol = 1e-4\n",
    "\n",
    "    rmses = []\n",
    "\n",
    "    for train_idx, val_idx in punt_folds:\n",
    "\n",
    "        X_train = torch.tensor(X_punt_scaled[train_idx], dtype=torch.float32)\n",
    "        y_train = torch.tensor(y_punt_scaled[train_idx], dtype=torch.float32)\n",
    "        X_val   = torch.tensor(X_punt_scaled[val_idx], dtype=torch.float32)\n",
    "        y_val   = torch.tensor(y_punt_scaled[val_idx], dtype=torch.float32)\n",
    "\n",
    "        input_dim = X_train.shape[1]\n",
    "\n",
    "        layers = []\n",
    "        for i in range(n_layers):\n",
    "            layers.append(nn.Linear(input_dim if i == 0 else hidden_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "        layers.append(nn.Linear(hidden_size, 1))\n",
    "\n",
    "        model = nn.Sequential(*layers)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        best_val = np.inf\n",
    "        wait = 0\n",
    "        best_state = None\n",
    "\n",
    "        # ---- training with early stopping ----\n",
    "        for epoch in range(max_epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X_train)\n",
    "            loss = criterion(preds, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # validation\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_preds = model(X_val)\n",
    "                val_loss = criterion(val_preds, y_val).item()\n",
    "\n",
    "            if val_loss < best_val - tol:\n",
    "                best_val = val_loss\n",
    "                wait = 0\n",
    "                best_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "            else:\n",
    "                wait += 1\n",
    "                if wait >= patience:\n",
    "                    break\n",
    "\n",
    "        # restore best model\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "        rmses.append(np.sqrt(best_val))\n",
    "\n",
    "    return np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f594ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = \"sqlite:///optuna/punt_study.db\"\n",
    "\n",
    "punt_study = optuna.create_study(\n",
    "    study_name=\"punt_study\",\n",
    "    direction=\"minimize\",\n",
    "    storage=storage,\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "punt_study.optimize(punt_objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14bbb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "punt_best_params = punt_study.best_params\n",
    "punt_best_score = punt_study.best_value\n",
    "n_layers = punt_best_params[\"n_layers\"]\n",
    "hidden_size = punt_best_params[\"hidden_size\"]\n",
    "dropout_rate = punt_best_params[\"dropout\"]\n",
    "lr = punt_best_params[\"lr\"]\n",
    "\n",
    "print(\"Best CV RMSE:\", punt_best_score)\n",
    "print()\n",
    "print(\"Best params:\", punt_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final model\n",
    "layers = []\n",
    "input_dim = X_punt_scaled.shape[1]\n",
    "for i in range(n_layers):\n",
    "    layers.append(nn.Linear(input_dim if i==0 else hidden_size, hidden_size))\n",
    "    layers.append(nn.ReLU())\n",
    "    layers.append(nn.Dropout(dropout_rate))\n",
    "layers.append(nn.Linear(hidden_size, 1))\n",
    "punt_model = nn.Sequential(*layers)\n",
    "\n",
    "# Convert full data to tensors\n",
    "X_t = torch.tensor(X_punt_scaled, dtype=torch.float32)\n",
    "y_t = torch.tensor(y_punt_scaled, dtype=torch.float32)\n",
    "\n",
    "optimizer = torch.optim.Adam(punt_model.parameters(), lr=lr)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Train final model\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    preds = punt_model(X_t)\n",
    "    loss = loss_fn(preds, y_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a28223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Filter to field goal attempts only ---\n",
    "fg_df = pbp_train[pbp_train.play_type_actual == \"field_goal\"].dropna(subset=[\"field_goal_result\"]).copy()\n",
    "fg_df = fg_df[fg_df.field_goal_result.isin(['made', 'missed', 'blocked'])]\n",
    "\n",
    "# Field goal\n",
    "fg_df[\"score_time_ratio\"] = fg_df[\"score_differential\"].abs() / (fg_df[\"game_seconds_remaining\"] + 1)\n",
    "fg_features = [\n",
    "    \"yardline_100\",\n",
    "    \"game_seconds_remaining\",\n",
    "    \"half_seconds_remaining\",\n",
    "    \"score_differential\",\n",
    "    \"temp_F\",\n",
    "    \"wind_mph\"\n",
    "]\n",
    "\n",
    "X_fg = fg_df[fg_features]\n",
    "y_fg = fg_df[\"fg_made\"]\n",
    "\n",
    "fg_folds = make_temporal_folds(fg_df)\n",
    "\n",
    "fg_oof_pred = pd.Series(index=fg_df.index, dtype=float)\n",
    "fg_df[\"fg_make_prob_oof\"] = fg_oof_pred\n",
    "\n",
    "for fold_num, (train_idx, val_idx) in enumerate(fg_folds, 1):\n",
    "    X_train = X_fg.loc[train_idx]\n",
    "    y_train = y_fg.loc[train_idx]\n",
    "    X_val   = X_fg.loc[val_idx]\n",
    "\n",
    "    fg_model_lr_fold = LogisticRegression(\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=1000\n",
    "    )\n",
    "\n",
    "    fg_model_lr_fold.fit(X_train, y_train)\n",
    "\n",
    "    fg_oof_pred.loc[val_idx] = fg_model_lr_fold.predict_proba(X_val)[:, 1]\n",
    "\n",
    "mask = fg_oof_pred.notna()\n",
    "fg_oof_rmse = np.sqrt(np.mean((fg_oof_pred[mask] - y_fg[mask]) ** 2))\n",
    "print(\"FG (LogReg) OOF RMSE:\", fg_oof_rmse)\n",
    "\n",
    "fg_model = LogisticRegression(\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "fg_model.fit(X_fg, y_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6362be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fg = 65\n",
    "fg_decay_threshold = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe992ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to 4th-down go-for-it plays\n",
    "go_df = pbp_train[\n",
    "    (pbp_train['down'] == 4) &\n",
    "    (pbp_train['play_type_actual'] == 'go')  # filters out punts/FGs\n",
    "].copy()\n",
    "\n",
    "# Target: did the team convert?\n",
    "go_df = go_df.dropna(subset=['first_down'])\n",
    "\n",
    "# Go-for-it conversion\n",
    "go_df[\"score_time_ratio\"] = go_df[\"score_differential\"].abs() / (go_df[\"game_seconds_remaining\"] + 1)\n",
    "\n",
    "go_df[\"success\"] = (\n",
    "    (go_df[\"first_down\"] == 1) |\n",
    "    (go_df[\"touchdown\"] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Reset index to avoid any issues\n",
    "go_df = go_df.reset_index(drop=True)\n",
    "\n",
    "# Make temporal folds based on seasons in punt_df\n",
    "go_folds = make_temporal_folds(go_df)\n",
    "\n",
    "# Features to predict net punt\n",
    "go_features = [\n",
    "    \"yardline_100\",\n",
    "    \"ydstogo\",\n",
    "    \"game_seconds_remaining\",\n",
    "    \"half_seconds_remaining\",\n",
    "    \"score_differential\",\n",
    "    \"posteam_timeouts_remaining\",\n",
    "    \"defteam_timeouts_remaining\",\n",
    "    \"temp_F\",\n",
    "    \"wind_mph\"\n",
    "]\n",
    "\n",
    "X_go = go_df[go_features].values\n",
    "y_go = go_df[\"success\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154b0801",
   "metadata": {},
   "outputs": [],
   "source": [
    "monotone_constraints = [\n",
    "    -1,  # yardline_100 (farther → worse)\n",
    "    -1,  # ydstogo (longer → worse)\n",
    "    0,   # game_seconds_remaining\n",
    "    0,   # half_seconds_remaining\n",
    "    1,   # score_differential\n",
    "    0,   # posteam_timeouts_remaining\n",
    "    0,   # defteam_timeouts_remaining\n",
    "    0,   # temp_F\n",
    "    0    # wind_mph\n",
    "]\n",
    "\n",
    "def go_objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"monotone_constraints\": tuple(monotone_constraints),\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"early_stopping_rounds\" : 100,\n",
    "        \"use_label_encoder\": False,\n",
    "        \"tree_method\": \"hist\",\n",
    "    }\n",
    "\n",
    "    log_losses = []\n",
    "\n",
    "    for train_idx, val_idx in go_folds:\n",
    "        X_train, X_val = X_go[train_idx], X_go[val_idx]\n",
    "        y_train, y_val = y_go[train_idx], y_go[val_idx]\n",
    "\n",
    "        model = XGBClassifier(**params)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "        preds = model.predict_proba(X_val)[:, 1]\n",
    "        log_losses.append(log_loss(y_val, preds))\n",
    "\n",
    "    return np.mean(log_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a51eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = \"sqlite:///optuna/go_study.db\"\n",
    "\n",
    "go_study = optuna.create_study(\n",
    "    study_name=\"go_study\",\n",
    "    direction=\"minimize\",\n",
    "    storage=storage,\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "go_study.optimize(go_objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3025543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with best hyperparameters\n",
    "go_best_params = go_study.best_trial.params\n",
    "go_best_params[\"monotone_constraints\"] = tuple(monotone_constraints)\n",
    "go_best_params[\"use_label_encoder\"] = False\n",
    "go_best_params[\"eval_metric\"] = \"logloss\"\n",
    "\n",
    "# Compute class imbalance weight\n",
    "pos = (y_go == 1).sum()\n",
    "neg = (y_go == 0).sum()\n",
    "scale_pos_weight = neg / pos\n",
    "\n",
    "go_model = XGBClassifier(**go_best_params, scale_pos_weight=scale_pos_weight)\n",
    "go_model.fit(X_go, y_go)  # feed raw features, no scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6dca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = (pd.DataFrame({\n",
    "        \"feature\": go_features,\n",
    "        \"importance\": go_model.feature_importances_\n",
    "    })\n",
    "    .sort_values(\"importance\", ascending=False)\n",
    ")\n",
    "\n",
    "print(imp.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bd5a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15f5e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_penalty(y, center, scale):\n",
    "    \n",
    "    y = np.asarray(y, dtype=float)\n",
    "    ramp = sigmoid((y - center) / scale) # ~0 for y << center, ~1 for y >> center\n",
    "\n",
    "    return ramp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e535e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_possessions_to_tie(score_differential):\n",
    "    \n",
    "    score_diff = np.asarray(score_differential)\n",
    "\n",
    "    return np.where(score_diff < 0, np.ceil(np.abs(score_diff) / 8), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61343c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plays_df(df):\n",
    "    \n",
    "    # Compute final scores and win from offensive team perspective\n",
    "    final_scores = (\n",
    "        df.groupby(\"game_id\")\n",
    "           .tail(1)[[\"game_id\",\"home_team\",\"away_team\",\"home_score\",\"away_score\"]]\n",
    "           .copy()\n",
    "    )\n",
    "    final_scores[\"home_win\"] = (final_scores[\"home_score\"] > final_scores[\"away_score\"]).astype(int)\n",
    "\n",
    "    df = df.merge(final_scores[[\"game_id\",\"home_win\"]], on=\"game_id\", how=\"left\")\n",
    "    df[\"win_actual\"] = np.where(\n",
    "        df[\"posteam\"] == df[\"home_team\"],\n",
    "        df[\"home_win\"],\n",
    "        1 - df[\"home_win\"]\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0339def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_next_fg_conv_states(df):\n",
    "    \n",
    "    # Next state if successful field goal attempt\n",
    "    df['fg_success_yardline_100'] = 75\n",
    "    df['fg_success_down'] = 1\n",
    "    df['fg_success_ydstogo'] = 10\n",
    "    df['fg_success_game_seconds_remaining'] = np.maximum(0, df['game_seconds_remaining'] - 5)\n",
    "    df['fg_success_half_seconds_remaining'] = np.maximum(0, df['half_seconds_remaining'] - 5)\n",
    "    df['fg_success_score_differential'] = -(df['score_differential'] + 3)\n",
    "    df['fg_success_posteam_timeouts_remaining'] = df['defteam_timeouts_remaining']\n",
    "    df['fg_success_defteam_timeouts_remaining'] = df['posteam_timeouts_remaining']\n",
    "    df['fg_success_score_time_ratio'] = df['fg_success_score_differential'].abs() / (df['fg_success_game_seconds_remaining'] + 1)\n",
    "    df['fg_success_temp_F'] = df['temp_F']\n",
    "    df['fg_success_wind_mph'] = df['wind_mph']\n",
    "    \n",
    "    # Next state if failed field goal attempt\n",
    "    df['fg_fail_yardline_100'] = np.minimum(80, 100 - (df['yardline_100'] + 7)) # Account for inside 20-yardline edge case\n",
    "    df['fg_fail_down'] = 1\n",
    "    df['fg_fail_ydstogo'] = 10\n",
    "    df['fg_fail_game_seconds_remaining'] = np.maximum(0, df['game_seconds_remaining'] - 5)\n",
    "    df['fg_fail_half_seconds_remaining'] = np.maximum(0, df['half_seconds_remaining'] - 5)\n",
    "    df['fg_fail_score_differential'] = -df['score_differential']\n",
    "    df['fg_fail_posteam_timeouts_remaining'] = df['defteam_timeouts_remaining']\n",
    "    df['fg_fail_defteam_timeouts_remaining'] = df['posteam_timeouts_remaining']\n",
    "    df['fg_fail_score_time_ratio'] = df['fg_fail_score_differential'].abs() / (df['fg_fail_game_seconds_remaining'] + 1)\n",
    "    df['fg_fail_temp_F'] = df['temp_F']\n",
    "    df['fg_fail_wind_mph'] = df['wind_mph']\n",
    "    \n",
    "    # Next state if successful conversion attempt\n",
    "    df['go_success_yardline_100'] = df['yardline_100'] - df['ydstogo'] - 1 # Assume advancement to 1 yd beyond line to gain\n",
    "    df['go_success_down'] = 1\n",
    "    df['go_success_ydstogo'] = np.minimum(10, df['go_success_yardline_100'])\n",
    "    df['go_success_game_seconds_remaining'] = np.maximum(0, df['game_seconds_remaining'] - 5)\n",
    "    df['go_success_half_seconds_remaining'] = np.maximum(0, df['half_seconds_remaining'] - 5)\n",
    "    df['go_success_score_differential'] = df['score_differential']\n",
    "    df['go_success_posteam_timeouts_remaining'] = df['posteam_timeouts_remaining']\n",
    "    df['go_success_defteam_timeouts_remaining'] = df['defteam_timeouts_remaining']\n",
    "    df['go_success_score_time_ratio'] = df['go_success_score_differential'].abs() / (df['go_success_game_seconds_remaining'] + 1)\n",
    "    df['go_success_temp_F'] = df['temp_F']\n",
    "    df['go_success_wind_mph'] = df['wind_mph']\n",
    "    \n",
    "    # Next state if failed conversion attempt\n",
    "    df['go_fail_yardline_100'] = 100 - df['yardline_100']\n",
    "    df['go_fail_down'] = 1\n",
    "    df['go_fail_ydstogo'] = 10\n",
    "    df['go_fail_game_seconds_remaining'] = np.maximum(0, df['game_seconds_remaining'] - 5)\n",
    "    df['go_fail_half_seconds_remaining'] = np.maximum(0, df['half_seconds_remaining'] - 5)\n",
    "    df['go_fail_score_differential'] = -df['score_differential']\n",
    "    df['go_fail_posteam_timeouts_remaining'] = df['defteam_timeouts_remaining']\n",
    "    df['go_fail_defteam_timeouts_remaining'] = df['posteam_timeouts_remaining']\n",
    "    df['go_fail_score_time_ratio'] = df['go_fail_score_differential'].abs() / (df['go_fail_game_seconds_remaining'] + 1)\n",
    "    df['go_fail_temp_F'] = df['temp_F']\n",
    "    df['go_fail_wind_mph'] = df['wind_mph']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a270cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ewp_fg(df):\n",
    "    \n",
    "    if \"down\" in df.columns:\n",
    "        fourth_down_mask = df[\"down\"] == 4\n",
    "    else:\n",
    "        fourth_down_mask = pd.Series(True, index=df.index)\n",
    "\n",
    "    success_cols = [f\"fg_success_{f}\" for f in wp_features]\n",
    "    fail_cols    = [f\"fg_fail_{f}\"    for f in wp_features]\n",
    "\n",
    "    X_fg_success = df.loc[fourth_down_mask, success_cols].copy()\n",
    "    X_fg_success.columns = wp_features\n",
    "\n",
    "    X_fg_fail = df.loc[fourth_down_mask, fail_cols].copy()\n",
    "    X_fg_fail.columns = wp_features\n",
    "    \n",
    "    wp_fg_success = 1 - wp_symmetric_adjust(X_fg_success, predict_wp)\n",
    "    wp_fg_fail = 1 - wp_symmetric_adjust(X_fg_fail, predict_wp)\n",
    "\n",
    "    # Predict FG make probability using current state\n",
    "    X_fg_current = df.loc[fourth_down_mask, fg_features].copy()\n",
    "    p_make = fg_model.predict_proba(X_fg_current)[:, 1]\n",
    "    yardlines = X_fg_current['yardline_100']\n",
    "    p_make_decayed = np.where(yardlines >= (fg_decay_threshold - 17), p_make * np.maximum(0, (max_fg - 17 - yardlines) / (max_fg - fg_decay_threshold)), p_make)\n",
    "\n",
    "    # Compute expected WP for FG attempt\n",
    "    ewp_fg = np.full(len(df), np.nan)\n",
    "    ewp_fg[fourth_down_mask] = np.clip(p_make_decayed * wp_fg_success + (1 - p_make_decayed) * wp_fg_fail, 0, 1)\n",
    "\n",
    "    wp_fg_success_array = np.full(len(df), np.nan)\n",
    "    wp_fg_success_array[fourth_down_mask] = wp_fg_success\n",
    "\n",
    "    wp_fg_fail_array = np.full(len(df), np.nan)\n",
    "    wp_fg_fail_array[fourth_down_mask] = wp_fg_fail\n",
    "\n",
    "    # Save to DataFrame\n",
    "    df[\"ewp_fg\"] = ewp_fg\n",
    "    df['wp_fg_success'] = wp_fg_success_array\n",
    "    df['wp_fg_fail'] = wp_fg_fail_array\n",
    "    df[\"p_make_fg\"] = 0\n",
    "    df.loc[fourth_down_mask, \"p_make_fg\"] = p_make_decayed\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1604fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ewp_go(df, penalty_params=None):\n",
    "    \n",
    "    penalty_params = penalty_params or {}\n",
    "    lam_f  = float(penalty_params.get(\"lam_fail\", 0.0))\n",
    "\n",
    "    if \"down\" in df.columns:\n",
    "        fourth_down_mask = df[\"down\"] == 4\n",
    "    else:\n",
    "        fourth_down_mask = pd.Series(True, index=df.index)\n",
    "\n",
    "    wp_current = df.loc[fourth_down_mask, \"wp_current\"].to_numpy()\n",
    "\n",
    "    # Build success/fail WP feature frames\n",
    "    success_cols = [f\"go_success_{f}\" for f in wp_features]\n",
    "    fail_cols    = [f\"go_fail_{f}\"    for f in wp_features]\n",
    "\n",
    "    X_go_success = df.loc[fourth_down_mask, success_cols].copy()\n",
    "    X_go_success.columns = wp_features\n",
    "\n",
    "    X_go_fail = df.loc[fourth_down_mask, fail_cols].copy()\n",
    "    X_go_fail.columns = wp_features\n",
    "\n",
    "    # Raw state WPs (arrays aligned to fourth_down_mask rows)\n",
    "    wp_go_success_raw = wp_symmetric_adjust(X_go_success, predict_wp)\n",
    "    wp_go_fail_raw    = 1 - wp_symmetric_adjust(X_go_fail, predict_wp)\n",
    "\n",
    "    # Conversion probabilities\n",
    "    X_go_current = df.loc[fourth_down_mask, go_features].copy()\n",
    "    p_convert = go_model.predict_proba(X_go_current)[:, 1]\n",
    "\n",
    "    # Raw EWP\n",
    "    ewp_go_raw = np.clip(p_convert * wp_go_success_raw + (1 - p_convert) * wp_go_fail_raw, 0, 1)\n",
    "\n",
    "    # --- pre-lambda penalty in WP units\n",
    "    fail_cost = np.maximum(0, wp_current - wp_go_fail_raw)\n",
    "    go_fail_penalty_wp = lam_f * fail_cost\n",
    "\n",
    "    # Apply lambdas\n",
    "    wp_go_fail_adj = np.clip(wp_go_fail_raw - go_fail_penalty_wp,  0, 1)\n",
    "    ewp_go_adj     = np.clip(p_convert * wp_go_success_raw + (1 - p_convert) * wp_go_fail_adj, 0, 1)\n",
    "\n",
    "    # Write back\n",
    "    df.loc[fourth_down_mask, \"p_convert\"] = p_convert\n",
    "    df.loc[fourth_down_mask, \"ewp_go_raw\"] = ewp_go_raw\n",
    "    df.loc[fourth_down_mask, \"ewp_go_adj\"] = ewp_go_adj\n",
    "    df.loc[fourth_down_mask, \"wp_go_success_raw\"] = wp_go_success_raw\n",
    "    df.loc[fourth_down_mask, \"wp_go_fail_raw\"] = wp_go_fail_raw\n",
    "    df.loc[fourth_down_mask, \"wp_go_fail_adj\"] = wp_go_fail_adj\n",
    "    df.loc[fourth_down_mask, \"go_fail_penalty_wp\"] = go_fail_penalty_wp\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d28bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_punt_next_state(df):\n",
    "    \n",
    "    if \"down\" in df.columns:\n",
    "        fourth_down_mask = df[\"down\"] == 4\n",
    "    else:\n",
    "        fourth_down_mask = pd.Series(True, index=df.index)\n",
    "        \n",
    "    X_punt_current = df.loc[fourth_down_mask, punt_features]\n",
    "\n",
    "    X_punt_np = X_punt_current.values.astype(np.float32)\n",
    "    X_punt_np_scaled = X_scaler.transform(X_punt_np) # Scale inputs\n",
    "    X_punt_tensor = torch.tensor(X_punt_np_scaled, dtype=torch.float32)\n",
    "\n",
    "    # Predict (scaled output)\n",
    "    punt_model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_scaled_pred = punt_model(X_punt_tensor).squeeze().cpu().numpy()\n",
    "\n",
    "    # Inverse transform target\n",
    "    punt_pred_yards = y_scaler.inverse_transform(\n",
    "        y_scaled_pred.reshape(-1, 1)\n",
    "    ).ravel()\n",
    "\n",
    "    punt_preds = np.zeros(len(df))\n",
    "    punt_preds[fourth_down_mask] = punt_pred_yards\n",
    "    \n",
    "    df['punt_pred_yards'] = punt_preds\n",
    " \n",
    "    landing_kicking = df['yardline_100'] - df['punt_pred_yards']\n",
    "    landing_kicking = np.where(landing_kicking < 0, 20, landing_kicking)  # Only clip beyond goal line\n",
    "    df['post_punt_yardline_100'] = 100 - landing_kicking # Flip field\n",
    "\n",
    "    df['post_punt_down'] = 1\n",
    "    df['post_punt_ydstogo'] = 10\n",
    "    df['post_punt_game_seconds_remaining'] = np.maximum(0, df['game_seconds_remaining'] - 8)\n",
    "    df['post_punt_half_seconds_remaining'] = np.maximum(0, df['half_seconds_remaining'] - 8)\n",
    "    df['post_punt_score_differential'] = -df['score_differential']\n",
    "    df['post_punt_posteam_timeouts_remaining'] = df['defteam_timeouts_remaining']\n",
    "    df['post_punt_defteam_timeouts_remaining'] = df['posteam_timeouts_remaining']\n",
    "    df['post_punt_score_time_ratio'] = df['post_punt_score_differential'].abs() / (df['post_punt_game_seconds_remaining'] + 1)\n",
    "    df['post_punt_temp_F'] = df['temp_F']\n",
    "    df['post_punt_wind_mph'] = df['wind_mph']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d60321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ewp_punt(df):\n",
    "    \n",
    "    if \"down\" in df.columns:\n",
    "        fourth_down_mask = df[\"down\"] == 4\n",
    "    else:\n",
    "        fourth_down_mask = pd.Series(True, index=df.index)\n",
    "\n",
    "    post_cols = [f\"post_punt_{f}\" for f in wp_features]\n",
    "\n",
    "    X_post_punt = df.loc[fourth_down_mask, post_cols].copy()\n",
    "    X_post_punt.columns = wp_features\n",
    "    \n",
    "    wp_post_punt = 1 - wp_symmetric_adjust(X_post_punt, predict_wp)\n",
    "\n",
    "    # Compute expected WP for FG attempt\n",
    "    ewp_punt = np.full(len(df), np.nan)\n",
    "    ewp_punt[fourth_down_mask] = wp_post_punt\n",
    "\n",
    "    # Save to DataFrame\n",
    "    df[\"ewp_punt\"] = ewp_punt\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903c7216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recommendations(df, test=False):\n",
    "    \n",
    "    ewp_cols = [\"ewp_punt\", \"ewp_fg\", \"ewp_go_adj\"]\n",
    "    \n",
    "    if not test:\n",
    "\n",
    "        # Compute actual EWP for each row (using actual_ewp_col)\n",
    "        bad = set(df[\"actual_ewp_col\"].dropna().unique()) - set(df.columns)\n",
    "        if bad:\n",
    "            raise KeyError(f\"actual_ewp_col points to missing columns: {bad}\")\n",
    "\n",
    "        col_idx = df[[\"actual_ewp_col\"]].apply(\n",
    "            lambda x: df.columns.get_loc(x[0]),\n",
    "            axis=1\n",
    "        ).to_numpy()\n",
    "\n",
    "        row_idx = np.arange(len(df))\n",
    "        df[\"ewp_actual\"] = df.to_numpy()[row_idx, col_idx]\n",
    "\n",
    "    # Compute best EWP\n",
    "    df[\"ewp_best\"] = df[ewp_cols].max(axis=1)\n",
    "\n",
    "    # Mask\n",
    "    valid = (df[\"down\"] == 4) & df[ewp_cols].notna().all(axis=1)\n",
    "\n",
    "    # decision margin only for valid rows (avoids weird NaNs)\n",
    "    df[\"decision_margin\"] = np.nan\n",
    "    ewp_sorted = np.sort(df.loc[valid, ewp_cols].values, axis=1)\n",
    "    df.loc[valid, \"decision_margin\"] = ewp_sorted[:, -1] - ewp_sorted[:, -2]\n",
    "    \n",
    "    # go_margin: go vs best alternative\n",
    "    df[\"go_margin\"] = np.nan\n",
    "    df.loc[valid, \"go_margin\"] = (\n",
    "        df.loc[valid, \"ewp_go_adj\"]\n",
    "        - df.loc[valid, [\"ewp_punt\", \"ewp_fg\"]].max(axis=1)\n",
    "    )\n",
    "    \n",
    "    col_to_action = {\n",
    "        \"ewp_punt\": \"punt\",\n",
    "        \"ewp_fg\": \"field_goal\",\n",
    "        \"ewp_go_adj\": \"go\"\n",
    "    }\n",
    "\n",
    "    # determine best_col and recommended_play only for valid rows\n",
    "    df[\"best_col\"] = np.nan\n",
    "    df.loc[valid, \"best_col\"] = df.loc[valid, ewp_cols].idxmax(axis=1)\n",
    "    df[\"recommended_play\"] = np.nan\n",
    "    if valid.any():\n",
    "        df.loc[valid, \"recommended_play\"] = (\n",
    "            df.loc[valid, ewp_cols].idxmax(axis=1).map(col_to_action)\n",
    "        )\n",
    "    \n",
    "    # For cases where we know play_type_actual\n",
    "    if not test:\n",
    "        df[\"regret_actual\"] = pd.to_numeric(df[\"ewp_best\"] - df[\"ewp_actual\"], errors=\"coerce\")\n",
    "        \n",
    "        # Identify disagreement (only meaningful when recommendation exists)\n",
    "        df[\"disagreed\"] = np.nan\n",
    "        df.loc[valid, \"disagreed\"] = ~(\n",
    "            ((df.play_type_actual == \"punt\") & (df.recommended_play == \"punt\")) |\n",
    "            ((df.play_type_actual == \"field_goal\") & (df.recommended_play == \"field_goal\")) |\n",
    "            ((df.play_type_actual == \"go\") & (df.recommended_play == \"go\"))\n",
    "        )\n",
    "\n",
    "        df[\"follow_model\"] = np.nan\n",
    "        df.loc[valid, \"follow_model\"] = (df.loc[valid, \"actual_ewp_col\"] == df.loc[valid, \"best_col\"]).astype(int)\n",
    "       \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db73c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_state(pbp_fourth, best_params, nd=4):\n",
    "    r = pbp_fourth.iloc[0]\n",
    "\n",
    "    # --- Hyperparams\n",
    "    lam_f  = float(best_params.get(\"lam_fail\", 0.0))\n",
    "\n",
    "    # --- Core quantities\n",
    "    wp_current = float(r.wp_current)\n",
    "    p_convert  = float(r.p_convert)\n",
    "\n",
    "    wp_succ_raw = float(r.wp_go_success_raw)\n",
    "    wp_fail_raw = float(r.wp_go_fail_raw)\n",
    "    wp_fail_adj = float(r.wp_go_fail_adj)\n",
    "\n",
    "    # --- GO fail penalty decomposition\n",
    "    fail_cost = max(0.0, wp_current - wp_fail_raw)\n",
    "    applied_fail_wp = float(r.go_fail_penalty_wp)\n",
    "    implied_ewp_drop = (1.0 - p_convert) * applied_fail_wp\n",
    "\n",
    "    # --- Deltas vs current\n",
    "    go_delta_raw = float(r.ewp_go_raw - wp_current)\n",
    "    go_delta_adj = float(r.ewp_go_adj - wp_current)\n",
    "    fg_delta     = float(r.ewp_fg     - wp_current)\n",
    "    punt_delta   = float(r.ewp_punt   - wp_current)\n",
    "\n",
    "    # =========================\n",
    "    print(\"\\nTOPLINE\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"wp_current                    : {wp_current:.{nd}f}\")\n",
    "    print(f\"recommended_play              : {r.recommended_play}\")\n",
    "    print(f\"decision_margin               : {float(r.decision_margin):.{nd}f}\")\n",
    "\n",
    "    print(\"\\nEXPECTED WIN PROBABILITIES\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"go (raw)                      : {float(r.ewp_go_raw):.{nd}f}   (Δ: {go_delta_raw:+.{nd}f})\")\n",
    "    print(f\"go (adj)                      : {float(r.ewp_go_adj):.{nd}f}   (Δ: {go_delta_adj:+.{nd}f})\")\n",
    "    print(f\"field goal                    : {float(r.ewp_fg):.{nd}f}   (Δ: {fg_delta:+.{nd}f})\")\n",
    "    print(f\"punt                          : {float(r.ewp_punt):.{nd}f}   (Δ: {punt_delta:+.{nd}f})\")\n",
    "\n",
    "    print(\"\\nGO DETAILS\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"p_convert                     : {p_convert:.{nd}f}\")\n",
    "    print(f\"wp_success (raw)              : {wp_succ_raw:.{nd}f}\")\n",
    "    print(f\"wp_fail    (raw→adj)          : {wp_fail_raw:.{nd}f} → {wp_fail_adj:.{nd}f}\")\n",
    "    \n",
    "    print(\"\\nFG DETAILS\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"p_make_fg                     : {float(r.p_make_fg):.{nd}f}\")\n",
    "    print(f\"wp_success                    : {float(r.wp_fg_success):.{nd}f}\")\n",
    "    print(f\"wp_fail                       : {float(r.wp_fg_fail):.{nd}f}\")\n",
    "\n",
    "    print(\"\\nPUNT CONTEXT\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"predicted net punt yds        : {float(r.punt_pred_yards):.{nd}f}\")\n",
    "\n",
    "    print(\"\\nGO FAIL PENALTY BREAKDOWN\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"lam_fail                      : {lam_f:.{nd}f}\")\n",
    "    print(f\"fail_cost (WP)                : {fail_cost:.{nd}f}\")\n",
    "    print(f\"applied fail penalty (WP)     : {applied_fail_wp:.{nd}f}\")\n",
    "    print(f\"implied drop in GO EWP (WP)   : {implied_ewp_drop:.{nd}f}\")\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260c88ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_with_ewp(df, test=False, penalty_params=None):\n",
    "    \n",
    "    penalty_params = penalty_params or {}\n",
    "\n",
    "    pbp_pre_computed = df.copy()\n",
    "    pbp_pre_computed[\"wp_pred\"] = wp_symmetric_adjust(pbp_pre_computed, predict_wp)\n",
    "\n",
    "    # Outcomes only exist for real data\n",
    "    if not test:\n",
    "        pbp_pre_computed = create_plays_df(pbp_pre_computed)\n",
    "\n",
    "    # shared features\n",
    "    pbp_pre_computed[\"score_time_ratio\"] = (pbp_pre_computed[\"score_differential\"].abs() / (pbp_pre_computed[\"game_seconds_remaining\"] + 1))\n",
    "    pbp_pre_computed[\"scoring_possessions_to_tie\"] = scoring_possessions_to_tie(pbp_pre_computed[\"score_differential\"])\n",
    "\n",
    "    # current-state WP (for penalty functions, etc.)\n",
    "    pbp_pre_computed[\"wp_current\"] = wp_symmetric_adjust(\n",
    "        pbp_pre_computed[wp_features], predict_wp\n",
    "    )\n",
    "\n",
    "    # EWP components (these should internally compute their own mask based on df[\"down\"] == 4)\n",
    "    pbp_pre_computed = create_next_fg_conv_states(pbp_pre_computed)\n",
    "    pbp_pre_computed = calculate_ewp_fg(pbp_pre_computed)\n",
    "    pbp_pre_computed = calculate_ewp_go(pbp_pre_computed, penalty_params=penalty_params)\n",
    "    pbp_pre_computed = create_punt_next_state(pbp_pre_computed)\n",
    "    pbp_pre_computed = calculate_ewp_punt(pbp_pre_computed)\n",
    "\n",
    "    # recommendations/regret/follow_model/etc.\n",
    "    pbp_pre_computed = make_recommendations(pbp_pre_computed, test=test)\n",
    "    pbp_fourth = pbp_pre_computed[pbp_pre_computed.down == 4].copy()\n",
    "    \n",
    "    if test:\n",
    "        report_state(pbp_fourth, penalty_params)\n",
    "\n",
    "    return pbp_pre_computed, pbp_fourth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87f2933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_score_failure_altbest(\n",
    "    pbp_fourth_df,\n",
    "    tail_q=0.95,\n",
    "    w_go=2.0,          # primary\n",
    "    w_go_tail=6.0,     # primary tail emphasis\n",
    "    w_fg=0.5,          # secondary\n",
    "    w_fg_tail=1.5,     # secondary tail\n",
    "    w_regret=0.1,      # small baseline sanity term\n",
    "):\n",
    "    d = pbp_fourth_df\n",
    "\n",
    "    # ---- validity mask (restrict to rows where we have what we need)\n",
    "    needed = [\"down\",\"recommended_play\",\"ewp_punt\",\"ewp_fg\",\"ewp_go_raw\",\"p_convert\",\"wp_go_fail_raw\"]\n",
    "    valid = (d[\"down\"] == 4)\n",
    "    for c in needed:\n",
    "        valid &= d[c].notna()\n",
    "\n",
    "    if not valid.any():\n",
    "        return float(\"inf\")\n",
    "\n",
    "    df = d.loc[valid].copy()\n",
    "\n",
    "    punt   = df[\"ewp_punt\"].to_numpy()\n",
    "    fg     = df[\"ewp_fg\"].to_numpy()\n",
    "    go_raw = df[\"ewp_go_raw\"].to_numpy()\n",
    "    rec    = df[\"recommended_play\"].to_numpy()\n",
    "\n",
    "    # ---- small baseline: regret vs RAW-best (keeps policy from doing nonsense)\n",
    "    best_raw = np.maximum.reduce([punt, fg, go_raw])\n",
    "    chosen_raw = np.where(rec==\"punt\", punt, np.where(rec==\"field_goal\", fg, go_raw))\n",
    "    regret = np.clip(best_raw - chosen_raw, 0.0, None)\n",
    "    mean_regret = regret.mean()\n",
    "\n",
    "    # ---- GO fail downside relative to best alternative (punt/FG)\n",
    "    alt_best_non_go = np.maximum(punt, fg)\n",
    "    wp_go_fail = df[\"wp_go_fail_raw\"].to_numpy()\n",
    "\n",
    "    p_fail = 1.0 - df[\"p_convert\"].to_numpy()\n",
    "    is_go = (rec == \"go\")\n",
    "\n",
    "    if is_go.any():\n",
    "        downside_go = np.clip(alt_best_non_go - wp_go_fail, 0.0, None)\n",
    "        risk_go = p_fail * downside_go\n",
    "        risk_go = risk_go[is_go]\n",
    "\n",
    "        mean_go = risk_go.mean()\n",
    "        q = np.quantile(risk_go, tail_q)\n",
    "        tail = risk_go[risk_go >= q]\n",
    "        cvar_go = tail.mean() if tail.size else 0.0\n",
    "    else:\n",
    "        mean_go = 0.0\n",
    "        cvar_go = 0.0\n",
    "\n",
    "    # ---- FG miss downside relative to best alternative (punt/GO)\n",
    "    mean_fg = 0.0\n",
    "    cvar_fg = 0.0\n",
    "    if (\"p_make_fg\" in df.columns) and (\"wp_fg_fail\" in df.columns) and df[\"p_make_fg\"].notna().all() and df[\"wp_fg_fail\"].notna().all():\n",
    "        p_miss = 1.0 - df[\"p_make_fg\"].to_numpy()\n",
    "        wp_fg_fail = df[\"wp_fg_fail\"].to_numpy()\n",
    "\n",
    "        alt_best_non_fg = np.maximum(punt, go_raw)\n",
    "        is_fg = (rec == \"field_goal\")\n",
    "\n",
    "        if is_fg.any():\n",
    "            downside_fg = np.clip(alt_best_non_fg - wp_fg_fail, 0.0, None)\n",
    "            risk_fg = p_miss * downside_fg\n",
    "            risk_fg = risk_fg[is_fg]\n",
    "\n",
    "            mean_fg = risk_fg.mean()\n",
    "            q = np.quantile(risk_fg, tail_q)\n",
    "            tail = risk_fg[risk_fg >= q]\n",
    "            cvar_fg = tail.mean() if tail.size else 0.0\n",
    "    \n",
    "    return float(\n",
    "        w_regret * mean_regret\n",
    "        + w_go * mean_go + w_go_tail * cvar_go\n",
    "        + w_fg * mean_fg + w_fg_tail * cvar_fg\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5fbc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty_objective(trial):\n",
    "    \n",
    "    lam = trial.suggest_float(\"lam_fail\", 0.0, 0.001)\n",
    "    params = {\n",
    "        \"lam_fail\": lam\n",
    "    }\n",
    "\n",
    "    fold_scores = []\n",
    "    for train_idx, val_idx in folds:\n",
    "        fold_val = pbp_train.loc[val_idx]\n",
    "        _, pbp_fourth_val = create_df_with_ewp(fold_val, penalty_params=params)\n",
    "        fold_scores.append(tuning_score_failure_altbest(pbp_fourth_val))\n",
    "\n",
    "    score = float(np.mean(fold_scores))\n",
    "\n",
    "    lam0 = 0.04\n",
    "    beta = 2.5\n",
    "    penalty = beta * max(0.0, lam - lam0)**2\n",
    "    \n",
    "    return score + penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3965d55a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# folds on pbp_train (expanding window)\n",
    "folds = make_temporal_folds(pbp_train)\n",
    "\n",
    "penalty_study = optuna.create_study(direction=\"minimize\")\n",
    "penalty_study.optimize(penalty_objective, n_trials=100)\n",
    "penalty_best_params = penalty_study.best_params\n",
    "\n",
    "print(\"Best params:\", penalty_study.best_params)\n",
    "print()\n",
    "print(\"Best CV score:\", penalty_study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cf0a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute on full TRAIN + full TEST using tuned params\n",
    "pbp_pre_train_tuned, pbp_fourth_train_tuned = create_df_with_ewp(pbp_train, penalty_params=penalty_best_params)\n",
    "pbp_pre_test_tuned, pbp_fourth_test_tuned = create_df_with_ewp(pbp_test, penalty_params=penalty_best_params)\n",
    "\n",
    "# Tuning metric on the test season\n",
    "print(\"Tuned test score:\", tuning_score_failure_altbest(pbp_fourth_test_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa437a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "state = {\n",
    "  \"yardline_100\": 15,\n",
    "  \"down\": 4,\n",
    "  \"ydstogo\": 4,\n",
    "  \"game_seconds_remaining\": 2200,\n",
    "  \"half_seconds_remaining\": 400,\n",
    "  \"score_differential\": -3,\n",
    "  \"posteam_timeouts_remaining\": 3,\n",
    "  \"defteam_timeouts_remaining\": 3,\n",
    "  \"temp_F\": 30,\n",
    "  \"wind_mph\": 10\n",
    "}\n",
    "\n",
    "test_state = pd.DataFrame([state])\n",
    "test_pbp_pre_computed, test_pbp_fourth = create_df_with_ewp(test_state, test=True, penalty_params=penalty_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ac4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute calibration, Brier score, reliability/resolution\n",
    "# Bin predicted WP\n",
    "bins = np.linspace(0, 1, 11)\n",
    "wp_bin = pd.cut(pbp_fourth_test_tuned['wp_pred'], bins, include_lowest=True)\n",
    "\n",
    "# Aggregate by bin\n",
    "cal_table = pbp_fourth_test_tuned.groupby(wp_bin).agg(\n",
    "    wp_pred_mean=('wp_pred', 'mean'),\n",
    "    win_rate=('win_actual', 'mean'),\n",
    "    count=('win_actual', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Brier score\n",
    "brier = np.mean((pbp_fourth_test_tuned['wp_pred'] - pbp_fourth_test_tuned['win_actual'])**2)\n",
    "\n",
    "# Reliability and resolution\n",
    "N = len(pbp_fourth_test_tuned)\n",
    "reliability = np.sum(cal_table['count'] / N * (cal_table['wp_pred_mean'] - cal_table['win_rate'])**2)\n",
    "resolution = np.sum(cal_table['count'] / N * (cal_table['win_rate'] - pbp_fourth_test_tuned['win_actual'].mean())**2)\n",
    "uncertainty = np.mean(pbp_fourth_test_tuned['win_actual']) * (1 - np.mean(pbp_fourth_test_tuned['win_actual']))\n",
    "brier_check = reliability - resolution + uncertainty\n",
    "\n",
    "# Print results\n",
    "print(f\"Brier score: {brier:.5f}\")\n",
    "print(f\"Reliability: {reliability:.5f}\")\n",
    "print(f\"Resolution: {resolution:.5f}\")\n",
    "print(f\"Uncertainty: {uncertainty:.5f}\")\n",
    "print(f\"Brier check (reliability - resolution + uncertainty): {brier_check:.5f}\")\n",
    "\n",
    "# Plot calibration\n",
    "x = cal_table['wp_pred_mean'].values.ravel()  # ensures 1D\n",
    "y = cal_table['win_rate'].values.ravel()     # ensures 1D\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(x, y, marker='o')\n",
    "plt.plot([0,1], [0,1], '--', color='gray')\n",
    "plt.xlabel('Predicted WP')\n",
    "plt.ylabel('Observed WP')\n",
    "plt.title('Calibration Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebf30e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf943f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 1, 11)\n",
    "calibration_df = pd.DataFrame(index=pd.IntervalIndex.from_tuples([(round(bins[i],2), round(bins[i+1],2)) for i in range(len(bins)-1)]))\n",
    "\n",
    "# Function to compute empirical win fraction per bin\n",
    "def empirical_win_fraction(pred_col):\n",
    "    return pbp_fourth_test_tuned.groupby(pd.cut(pbp_fourth_test_tuned[pred_col], bins=bins))['win_actual'].mean()\n",
    "\n",
    "# Compute results for each play type\n",
    "calibration_df['ewp_punt'] = round(empirical_win_fraction('ewp_punt'),3)\n",
    "calibration_df['ewp_fg'] = round(empirical_win_fraction('ewp_fg'),3)\n",
    "calibration_df['ewp_go_adj'] = round(empirical_win_fraction('ewp_go_adj'),3)\n",
    "\n",
    "# Bins indicate predicted wp bin; columns are how often a team actually won in that predicted wp bin\n",
    "calibration_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d9219",
   "metadata": {},
   "outputs": [],
   "source": [
    "ewp_columns = ['ewp_punt', 'ewp_fg', 'ewp_go_adj']\n",
    "\n",
    "# Boolean mask of violations\n",
    "violation_mask = (pbp_fourth_test_tuned[ewp_columns] < 0) | (pbp_fourth_test_tuned[ewp_columns] > 1)\n",
    "\n",
    "# Count violations per column\n",
    "violations = violation_mask.sum()\n",
    "\n",
    "if violations.sum() == 0:\n",
    "    print(\"No EWP violations detected.\")\n",
    "else:\n",
    "    print(\"Violations detected:\")\n",
    "    print(violations)\n",
    "    print(pbp_fourth_test_tuned[violation_mask.any(axis=1)].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2cdeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = pbp_fourth_test_tuned[wp_features]\n",
    "state_flipped = state.copy()\n",
    "state_flipped[\"score_differential\"] *= -1\n",
    "state_flipped[[\"posteam_timeouts_remaining\",\"defteam_timeouts_remaining\"]] = (\n",
    "    state_flipped[[\"defteam_timeouts_remaining\",\"posteam_timeouts_remaining\"]].values\n",
    ")\n",
    "state_flipped[\"yardline_100\"] = 100 - state_flipped[\"yardline_100\"]\n",
    "state_flipped[\"score_time_ratio\"] = state_flipped[\"score_differential\"].abs() / (state_flipped[\"game_seconds_remaining\"] + 1)\n",
    "\n",
    "wp = wp_symmetric_adjust(state, predict_wp)\n",
    "wp_flipped = wp_symmetric_adjust(state_flipped, predict_wp)\n",
    "flip_err = wp + wp_flipped - 1\n",
    "\n",
    "flip_err.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a28a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional mean regret\n",
    "pbp_fourth_test_tuned[pbp_fourth_test_tuned.follow_model == 0].regret_actual.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a593dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute regret stats by play type ---\n",
    "df_disagree = pbp_fourth_test_tuned[pbp_fourth_test_tuned[\"disagreed\"] == True].copy()\n",
    "regret_by_play = df_disagree.groupby('play_type_actual')['regret_actual'].agg(['mean', 'median'])\n",
    "df_disagree['regret_actual'] = pd.to_numeric(df_disagree['regret_actual'], errors='coerce')\n",
    "\n",
    "# Compute stats\n",
    "regret_by_play = df_disagree.groupby('play_type_actual')['regret_actual'].agg(['size', 'mean', 'median'])\n",
    "regret_by_play['95th'] = df_disagree.groupby('play_type_actual')['regret_actual'].quantile(0.95)\n",
    "\n",
    "print(\"Regret by Play Type Conditioned on Coach Disagreement:\")\n",
    "regret_by_play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb03fefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regret vs margin for disagreements\n",
    "disagree_bins = pd.qcut(df_disagree[\"decision_margin\"], q=10, duplicates=\"drop\")\n",
    "regret_by_margin = df_disagree.groupby(disagree_bins)[\"regret_actual\"].agg(\n",
    "    mean=\"mean\",\n",
    "    p95=lambda x: np.percentile(x, 95),\n",
    "    count=\"count\"\n",
    ")\n",
    "print(\"Regret vs Decision Margin (Disagreements)\")\n",
    "display(regret_by_margin)\n",
    "\n",
    "# Bin decision margin\n",
    "pbp_fourth_test_tuned[\"margin_bin\"] = pd.qcut(pbp_fourth_test_tuned[\"decision_margin\"], 10)\n",
    "follow_by_margin = pbp_fourth_test_tuned.groupby(\"margin_bin\").agg(\n",
    "    follow_rate=(\"follow_model\", \"mean\"),\n",
    "    count=(\"follow_model\", \"size\")\n",
    ")\n",
    "print(\"Follow Model Rate vs Decision Margin\")\n",
    "follow_by_margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aa8366",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pbp_fourth_test_tuned[pbp_fourth_test_tuned.season == test_season]\n",
    "\n",
    "labels = [\"punt\", \"field_goal\", \"go\"]\n",
    "\n",
    "cm_df = test[[\"play_type_actual\", \"recommended_play\"]].dropna()\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    cm_df[\"play_type_actual\"].astype(str),\n",
    "    cm_df[\"recommended_play\"].astype(str),\n",
    "    labels=labels\n",
    ")\n",
    "\n",
    "confusion = pd.DataFrame(\n",
    "    cm,\n",
    "    index=pd.Index(labels, name=\"Actual\"),\n",
    "    columns=pd.Index(labels, name=\"Recommended\")\n",
    ")\n",
    "\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac2a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_norm = confusion.div(confusion.sum(axis=1), axis=0)\n",
    "round(confusion_norm,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_go_from_margin(margin, scale):\n",
    "    return 1 / (1 + np.exp(-margin / scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317f1802",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pbp_fourth_test_tuned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722d87cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"p_go_model\"] = p_go_from_margin(\n",
    "    df[\"go_margin\"],\n",
    "    scale=0.0075\n",
    ").clip(.01, .99)\n",
    "\n",
    "df[\"coach_go\"] = (\n",
    "    df[\"play_type_actual\"] == \"go\"\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "df[\"go_diff\"] = (\n",
    "    df[\"coach_go\"]\n",
    "    - df[\"p_go_model\"]\n",
    ")\n",
    "\n",
    "rai_raw = (\n",
    "    df\n",
    "    .groupby(\"possession_coach\")\n",
    "    .agg(\n",
    "        rai=(\"go_diff\", \"mean\"),\n",
    "        n=(\"go_diff\", \"size\")\n",
    "    )\n",
    "    .sort_values(\"rai\")\n",
    ")\n",
    "\n",
    "k = 30  # prior strength\n",
    "rai_raw[\"rai_shrunk\"] = (\n",
    "    rai_raw[\"n\"] / (rai_raw[\"n\"] + k)\n",
    ") * rai_raw[\"rai\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd0726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rai_raw.sort_values(\"rai_shrunk\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd3d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rai_raw.sort_values(\"rai_shrunk\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5b8ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yard_edges  = list(range(1, 101, 10)) + [101]\n",
    "yard_labels = [f\"{start}–{start+9}\" for start in yard_edges[:-1]]\n",
    "\n",
    "df[\"yardline_bin\"] = pd.cut(\n",
    "    df[\"yardline_100\"],\n",
    "    bins=yard_edges,\n",
    "    labels=yard_labels,\n",
    "    right=False,\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "\n",
    "togo_bins   = [0, 1, 3, 6, 9, np.inf]\n",
    "togo_labels = [\"1\", \"2–3\", \"4–6\", \"7–9\", \"10+\"]\n",
    "\n",
    "df[\"ydstogo_bin\"] = pd.cut(\n",
    "    df[\"ydstogo\"],\n",
    "    bins=togo_bins,\n",
    "    labels=togo_labels,\n",
    "    right=True,\n",
    "    include_lowest=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd34579",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat = (\n",
    "    df\n",
    "    .groupby([\"ydstogo_bin\", \"yardline_bin\"], observed=False)[\"go_diff\"]\n",
    "    .mean()\n",
    "    .unstack(\"yardline_bin\")\n",
    ")\n",
    "\n",
    "counts = (\n",
    "    df\n",
    "    .groupby([\"ydstogo_bin\", \"yardline_bin\"], observed=False)[\"go_diff\"]\n",
    "    .size()\n",
    "    .unstack(\"yardline_bin\")\n",
    ")\n",
    "\n",
    "min_n = 10\n",
    "heat = heat.mask(counts < min_n)\n",
    "\n",
    "round(heat,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1c37db",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "pbp_train.to_parquet(f\"exports/pbp_train_{timestamp}.parquet\")\n",
    "raw_pbp.to_parquet(f\"exports/raw_pbp{timestamp}.parquet\")\n",
    "pbp.to_parquet(f\"exports/pbp{timestamp}.parquet\")\n",
    "joblib.dump(wp_model, f\"exports/wp_model_{timestamp}.joblib\")\n",
    "joblib.dump(go_model, f\"exports/go_model_{timestamp}.joblib\")\n",
    "joblib.dump(fg_model, f\"exports/fg_model_{timestamp}.joblib\")\n",
    "joblib.dump(punt_model, f\"exports/punt_model_{timestamp}.joblib\")\n",
    "joblib.dump(best_params, f\"exports/best_params_{timestamp}.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
